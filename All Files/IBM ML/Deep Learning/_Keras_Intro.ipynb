{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML311Coursera747-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "import skillsnetwork\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Muhammad Umer Khan\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "# await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/Module2/L2/diabetes.csv\", overwrite=True)\n",
    "\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('./diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>4</td>\n",
       "      <td>144</td>\n",
       "      <td>82</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.554</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>88</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.905</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>64</td>\n",
       "      <td>36</td>\n",
       "      <td>100</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.600</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6</td>\n",
       "      <td>93</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>28.7</td>\n",
       "      <td>0.356</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "417               4                     144              82              32   \n",
       "767               1                      93              70              31   \n",
       "702               1                     168              88              29   \n",
       "467               0                      97              64              36   \n",
       "98                6                      93              50              30   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "417        0  38.5              0.554   37             1  \n",
       "767        0  30.4              0.315   23             0  \n",
       "702        0  35.0              0.905   52             1  \n",
       "467      100  36.8              0.600   25             0  \n",
       "98        64  28.7              0.356   23             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   times_pregnant          768 non-null    int64  \n",
      " 1   glucose_tolerance_test  768 non-null    int64  \n",
      " 2   blood_pressure          768 non-null    int64  \n",
      " 3   skin_thickness          768 non-null    int64  \n",
      " 4   insulin                 768 non-null    int64  \n",
      " 5   bmi                     768 non-null    float64\n",
      " 6   pedigree_function       768 non-null    float64\n",
      " 7   age                     768 non-null    int64  \n",
      " 8   has_diabetes            768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "diabetes_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=200)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.750\n",
      "roc-auc is 0.826\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAKoCAYAAAChhO3SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABxxklEQVR4nO3dd3QUZeP28Su90HvvIFXEBx4VkAcRqUqxhiAdFARpEZHeBJEqIr0EpIVIEQURCIgUQaWjgFKkkwChBtKTef/gl7yGJJANSWbL93MO55DJ7O61e+/ClfuemTgZhmEIAAAAMImz2QEAAADg2CikAAAAMBWFFAAAAKaikAIAAMBUFFIAAACYikIKAAAAU1FIAQAAYCoKKQAAAExFIQUAAICpKKSweosXL5aTk1PiH1dXVxUpUkRt2rTRqVOnUrxNTEyMZs+erdq1aytXrlzy8vJS5cqVNWjQIN24cSPF28THx2vp0qV65ZVXlD9/frm5ualgwYJ67bXXtH79esXHxz82a1RUlGbMmKEXX3xRefLkkbu7u4oVK6Z33nlHO3bseKLXwUxfffWVypcvL3d3dzk5Oen27duZ9liWjvdLL72UZP9///nzzz8zLWdanTt3LkkmZ2dn5cuXT82bN9fevXuT7Ovk5KQPP/wwxduOGjUqxfvv0qVL4j6p+c9//iMnJydNnjz5iZ/Pzz//LCcnJ/3888+J2zp16qTSpUun6/5eeuklVatW7Ylz/dusWbO0ePHiDL1Pa2TJa/eo9xBgDSiksBmLFi3S3r17tXXrVn344Yf6/vvv9eKLL+rWrVtJ9gsPD1ejRo3Uu3dvPfvsswoICNDGjRvVvn17zZs3T88++6z+/vvvJLeJjIxU8+bN1bFjRxUsWFCzZ8/WTz/9pDlz5qho0aJ6++23tX79+kfmCw0NVd26deXn56dq1app8eLF2rZtm6ZMmSIXFxc1bNhQR44cyfDXJbMdPnxYffr0UYMGDfTTTz9p7969ypEjR6Y/blrHW5LKli2rvXv3JvtTrly5TM+ZVr1799bevXu1a9cujR8/XkeOHFGDBg106NChx942R44cWrx4cbIfiu7du6dVq1YpZ86cqd728OHDiY+xcOHCJ3sSqRg+fLi+/fbbTLnv9HCUQgrYFQOwcosWLTIkGfv27UuyffTo0YYkw9/fP8n2999/35BkrFy5Mtl9/f3330auXLmMqlWrGrGxsYnbP/jgA0OS8fXXX6eY4eTJk8aRI0cembNZs2aGq6ursW3bthS///vvvxvnz59/5H2kVXh4eIbcT1osW7bMkGT89ttvGXaf9+/fT/V7lo53/fr1japVq2ZYtox29uxZQ5IxadKkJNu3bdtmSDK6deuWuE2S0atXr2S37datmyHJ2LJlS5L7WLBggeHl5WW0a9fOSO2f8169ehmSjFdffdWQZPzyyy9P9Hy2b99uSDK2b9/+RPeTIDPGr2rVqkb9+vUz9D6zQnh4uBEfH5/m/S157SQZI0eOTGcyIPMxQwqbVatWLUnS1atXE7eFhITI399fTZo0kY+PT7LbPPXUU/rkk0907NgxrVu3LvE2CxYsUJMmTdShQ4cUH6tChQqqXr16qlkOHDigH3/8UV27dtXLL7+c4j7//e9/VbJkSUnSqFGjUlxiTViuPnfuXOK20qVL67XXXtPatWv17LPPytPTU6NHj9azzz6revXqJbuPuLg4FStWTG+88UbitujoaI0dO1aVKlWSh4eHChQooM6dO+v69eupPifpwZJgu3btJEnPP/+8nJyc1KlTp8Tv+/v765lnnpGnp6fy5s2r119/XSdOnEhyH506dVL27Nn1xx9/qHHjxsqRI4caNmz4yMdNSUrj/aRu3rypnj17qlixYnJ3d1fZsmU1dOhQRUVFJdkvYSl96dKlqly5sry9vfXMM89ow4YN6X7sF154QZJ0/vz5x+5bsWJF1alTR/7+/km2+/v764033lCuXLlSvF1kZKRWrFihmjVr6osvvki8TVr99ddfatq0qby9vZU/f3716NFDYWFhyfZLacl+5syZ+t///qeCBQsqW7ZsevrppzVx4kTFxMSk+Fi7du3SCy+8IC8vLxUrVkzDhw9XXFxckn3S8j4uXbq0jh07ph07diQeyvDvbHfv3tWAAQNUpkyZxENq+vXrp/v37yd5rFWrVun5559Xrly55O3trbJly6pLly6Pfc0S3itz587VU089JQ8PD1WpUkUrV65Msl/CZ33Lli3q0qWLChQoIG9vb0VFRSk+Pl4TJ05MfJ4FCxZUhw4ddOnSpXS/dikJCQlR9+7dVbx4cbm7u6tMmTIaPXq0YmNjE/dJOGxk0qRJmjBhgkqXLi0vLy+99NJLOnnypGJiYjRo0CAVLVpUuXLl0uuvv65r16499rGBh7maHQBIr7Nnz0p6UDITbN++XbGxsWrdunWqt2vdurWGDBmioKAgvfnmm9q+fbtiYmIeeZvH2bJlS+J9Z4aDBw/qxIkTGjZsmMqUKaNs2bKpaNGi6tu3r06dOqUKFSokyXLlyhV17txZ0oNjY1u1aqVdu3Zp4MCBqlOnjs6fP6+RI0fqpZde0v79++Xl5ZXi486aNUsBAQEaO3asFi1apEqVKqlAgQKSpPHjx2vIkCHy9fXV+PHjdePGDY0aNUq1a9fWvn37kmSKjo5Wy5Yt1b17dw0aNCjJf3hpldJ4/9vD9+ns7Cxn59R/5o6MjFSDBg105swZjR49WtWrV09cTj98+LB++OGHJPv/8MMP2rdvn8aMGaPs2bNr4sSJev311/X333+rbNmyFj+f06dPS1Li6/k4Xbt2Va9evXTr1i3lyZNHf//9t/bs2aOxY8dqzZo1Kd5m7dq1unXrlrp06aIKFSroxRdfVGBgoKZNm6bs2bM/8vGuXr2q+vXry83NTbNmzVKhQoW0fPnyJMe4PsqZM2fUtm3bxOJ35MgRjRs3Tn/99VeyUhwSEqI2bdpo0KBBGjNmjH744QeNHTtWt27d0owZMySl/X387bff6q233lKuXLk0a9YsSZKHh4ekB4fz1K9fX5cuXdKQIUNUvXp1HTt2TCNGjNAff/yhrVu3ysnJSXv37pWPj498fHw0atQoeXp66vz58/rpp5/S9Ny///57bd++XWPGjFG2bNk0a9Ys+fr6ytXVVW+99VaSfbt06aJXX31VS5cu1f379+Xm5qYPPvhA8+bN04cffqjXXntN586d0/Dhw/Xzzz/r4MGDyp8/v0WvXUpCQkL03HPPydnZWSNGjFC5cuW0d+9ejR07VufOndOiRYuS7D9z5kxVr15dM2fO1O3bt/XRRx+pRYsWev755+Xm5iZ/f3+dP39eAwYMULdu3fT999+n6bUCEpk9RQs8TsIS7q+//mrExMQYYWFhxqZNm4zChQsb//vf/4yYmJjEfT///HNDkrFp06ZU7y8iIsKQZDRr1izNt3mcHj16GJKMv/76K037jxw5MsUl1oTnevbs2cRtpUqVMlxcXIy///47yb6hoaGGu7u7MWTIkCTb33nnHaNQoUKJr0tAQIAhyVizZk2S/fbt22dIMmbNmvXIrCktod+6dcvw8vIymjdvnmTfCxcuGB4eHkbbtm0Tt3Xs2DHFpfbHPV5axtswHixbSkr25913333k48yZM8eQZHzzzTdJtk+YMCHZ8rgko1ChQsbdu3cTt4WEhBjOzs7G+PHjH/k4CcvuEyZMMGJiYozIyEjjwIEDxn//+19DkvHDDz8keZyUluwnTZpkhIWFGdmzZzdmzJhhGIZhfPzxx0aZMmWM+Pj4xGX5h7388suGp6encevWrSSv7cKFCx+Z2TAM45NPPjGcnJyMw4cPJ9neqFGjZEv2HTt2NEqVKpXqfcXFxRkxMTHGkiVLDBcXF+PmzZuJ30sYv++++y7Jbd577z3D2dk58TAXS97HqS3Zjx8/3nB2dk52OMjq1asNScbGjRsNwzCMyZMnG5KM27dvp/qcUiPJ8PLyMkJCQhK3xcbGGpUqVTLKly+fuC1hLDp06JDk9idOnDAkGT179kyy/bfffjMkJfm8p/W1S8j17yX77t27G9mzZ092GFHCcz927JhhGP//PfjMM88YcXFxiftNmzbNkGS0bNkyye379etnSDLu3LnzyNcJeBhL9rAZL7zwgtzc3JQjRw41bdpUefLk0XfffSdX1/RN9D/qrGRrU7169WQzg/ny5VOLFi309ddfJ57scuvWLX333Xfq0KFD4uuyYcMG5c6dWy1atFBsbGzinxo1aqhw4cJJzpZOq7179yoiIiLJ8r0klShRQi+//LK2bduW7DZvvvmmRY9hyXiXK1dO+/btS/Ln008/feT9//TTT8qWLVuyGauE5/Twc2jQoEGSk7kKFSqkggULpmnJXZI++eQTubm5ydPTUzVr1tSFCxc0d+5cNW/ePE23z549u95++235+/srNjZWS5YsUefOnVN9H589e1bbt2/XG2+8ody5c0uS3n77beXIkSNNy/bbt29X1apV9cwzzyTZ3rZt2zTlPXTokFq2bKl8+fLJxcVFbm5u6tChg+Li4nTy5Mkk++bIkUMtW7ZM9jjx8fHauXOnpIx5H2/YsEHVqlVTjRo1ktxHkyZNklw54L///a8k6Z133tE333yjy5cvp+k5J2jYsKEKFSqU+LWLi4t8fHx0+vTpZMvuD38utm/fLknJPlvPPfecKleunOx9mZbXLiUbNmxQgwYNVLRo0SSvRbNmzSQp2VVBmjdvnmTFoXLlypKkV199Ncl+CdsvXLiQ6mMDKaGQwmYsWbJE+/bt008//aTu3bvrxIkT8vX1TbJPwjGaCcu7KUn4XokSJdJ8m8fJiPt4lCJFiqS4vUuXLrp8+bKCgoIkSQEBAYqKikryn9nVq1d1+/Ztubu7y83NLcmfkJAQhYaGWpwn4dJZKeUqWrRosktreXt7P/JM8JSkZbwTeHp6qlatWkn+lClT5rHPoXDhwskKXcGCBeXq6prsOeTLly/ZfXh4eCgiIiJNz6dv377at2+fDhw4oDNnzig4OFjvv/9+mm6boGvXrjp48KDGjRun69evJyst/+bv7y/DMPTWW2/p9u3bun37tmJiYtSyZUv98ssv+uuvvx75WAmvz8NS2vawCxcuqF69erp8+bK+/PJL7dq1S/v27dPMmTMlKdlr9u/y9vDjJIxDRryPr169qqNHjya7fY4cOWQYRuJ9/O9//9O6desUGxurDh06qHjx4qpWrZoCAgIe+xj/zv6o55Pg4c+QpZ+ttLx2Kbl69arWr1+f7LWoWrWqJCV7PfPmzZvka3d390duj4yMTPWxgZRwDClsRuXKlRNPbGnQoIHi4uK0YMECrV69OnGWq0GDBnJ1ddW6devUo0ePFO8n4WSmRo0aJd7Gzc3tkbd5nCZNmmjIkCFat26dmjZt+tj9PT09JT24bmnC8W1S8v8EEqQ2C9akSRMVLVpUixYtUpMmTbRo0SI9//zzqlKlSuI++fPnV758+bRp06YU7yM9l3BKKGfBwcHJvnflypUkx7g9Kv+jpGW8n0S+fPn022+/yTCMJPmuXbum2NjYZM/hSRUvXjzx+aRX3bp1VbFiRY0ZM0aNGjVK/KHqYfHx8YmXPfr3yW3/5u/vr4kTJ6b6WPny5VNISEiy7Slte9i6det0//59rV27VqVKlUrcfvjw4RT3T+lEtYTHSXivZcT7OH/+/PLy8kp1hvjfY96qVSu1atVKUVFR+vXXXzV+/Hi1bdtWpUuXVu3atR/5OI963R7+webhz8a/P1vFixdP8r2UPltpee1Skj9/flWvXl3jxo1L8ftFixZN9bZAZmCGFDZr4sSJypMnj0aMGJG4ZF24cGF16dJFmzdvVmBgYLLbnDx5UhMmTFDVqlUTT0AqXLiwunXrps2bN2vJkiUpPtaZM2d09OjRVLP85z//UbNmzbRw4cJUT3zYv39/4jJWwlm/D9/n4651+jAXFxe1b99e69at065du7R///5kZwK/9tprunHjhuLi4pLNItaqVUsVK1a06DElqXbt2vLy8tKyZcuSbL906ZJ++umndJ1F/zgpjfeTaNiwoe7du5f4A0qChPdAZjyHjDBs2DC1aNFCH330Uar7bN68WZcuXVKvXr20ffv2ZH+qVq2qJUuWPPLksgYNGujYsWPJrp27YsWKx2ZMKFn//mHLMAzNnz8/xf3DwsKSnQSzYsUKOTs763//+58ky97Hqc1cv/baazpz5ozy5cuX4n2kdHF/Dw8P1a9fXxMmTJCkNF03dtu2bUmKYlxcnAIDA1WuXLlkJfNhCVfpePiztW/fPp04cSLZ+zItr11KXnvtNf35558qV65ciq8FhRRZjRlS2Kw8efJo8ODBGjhwoFasWJF4eaKpU6fq77//Vrt27bRz5061aNFCHh4e+vXXXzV58mTlyJFDa9askYuLS+J9TZ06Vf/88486deqkzZs36/XXX1ehQoUUGhqqoKAgLVq0SCtXrnzkpZ+WLFmipk2bqlmzZurSpYuaNWumPHnyKDg4WOvXr1dAQIAOHDigkiVLqnnz5sqbN6+6du2qMWPGyNXVVYsXL9bFixctfh26dOmiCRMmqG3btvLy8kp2uas2bdpo+fLlat68ufr27avnnntObm5uunTpkrZv365WrVrp9ddft+gxc+fOreHDh2vIkCHq0KGDfH19dePGDY0ePVqenp4aOXKkxc/jcVIb7/Tq0KGDZs6cqY4dO+rcuXN6+umntXv3bn322Wdq3ry5XnnllQxKnrHatWv32Oe+cOFCubq6asiQISkWi+7du6tPnz764Ycf1KpVqxTvo1+/fvL399err76qsWPHJp5l/7ilfunB6oO7u7t8fX01cOBARUZGavbs2Sn+UgPpwUzeBx98oAsXLuipp57Sxo0bNX/+fH3wwQeJh8NY8j5++umntXLlSgUGBqps2bLy9PTU008/rX79+mnNmjX63//+p/79+6t69eqKj4/XhQsXtGXLFn300Ud6/vnnNWLECF26dEkNGzZU8eLFdfv2bX355Zdyc3NT/fr1H/v88+fPr5dfflnDhw9PPMv+r7/+Snbpp5RUrFhR77//vr766is5OzurWbNmiWfZlyhRQv3797f4tUvJmDFjFBQUpDp16qhPnz6qWLGiIiMjde7cOW3cuFFz5sx5bHkGMpS551QBj5fahdIN48EZ8yVLljQqVKiQ5EL30dHRxsyZM43nn3/eyJ49u+Hh4WFUrFjRGDhwoBEaGpri48TGxhpff/218fLLLxt58+Y1XF1djQIFChjNmjUzVqxYkeQM09REREQY06dPN2rXrm3kzJnTcHV1NYoWLWq88cYbSc6mNowHF8qvU6eOkS1bNqNYsWLGyJEjjQULFqR4lv2rr776yMetU6fOI88sj4mJMSZPnmw888wzhqenp5E9e3ajUqVKRvfu3Y1Tp0498r4f9fovWLDAqF69uuHu7m7kypXLaNWqVeLZuQk6duxoZMuW7ZGPkdbHS2m8n+TC6jdu3DB69OhhFClSxHB1dTVKlSplDB482IiMjEyynx46+z1BqVKljI4dOz7yMVK7MH5KHn6ctN7232fZX79+3XB3dzdat26d6v4JV0lo0aLFI+/3+PHjRqNGjQxPT08jb968RteuXY3vvvsuTWfZr1+/PvH9VqxYMePjjz82fvzxx2S3TRi/n3/+2ahVq5bh4eFhFClSxBgyZEiyKyqk9X187tw5o3HjxkaOHDkMSUmy3bt3zxg2bJhRsWLFxPft008/bfTv3z/xzPgNGzYYzZo1M4oVK2a4u7sbBQsWNJo3b27s2rXrka+XYfz/MZw1a5ZRrlw5w83NzahUqZKxfPnyJPs96n0eFxdnTJgwwXjqqacMNzc3I3/+/Ea7du2MixcvJtnPktdOKVwY//r160afPn2MMmXKGG5ubkbevHmNmjVrGkOHDjXu3btnGEbq78GEX5CwatWqND8v4FGcDMMwsrgDAwBgl5ycnNSrV69HXgMUQHIcQwoAAABTUUgBAABgKk5qAgAgg3AUHJA+zJACAADAVBRSAAAAmIpCCgAAAFPZxDGk8fHxunLlinLkyJGuX0EIAACAzGUYhsLCwlS0aFE5O1s252kThfTKlSup/s5mAAAAWI+LFy9a/Ju+bKKQ5siRQ9KDJ5gzZ87E7TExMdqyZYsaN24sNzc3s+IhEzHGjoFxdgyMs/1jjB1DauN89+5dlShRIrG3WcLiQrpz505NmjRJBw4cUHBwsL799lu1bt36kbfZsWOH/Pz8dOzYMRUtWlQDBw5Ujx490vyYCcv0OXPmTFZIvb29lTNnTt74dooxdgyMs2NgnO0fY+wYHjfO6Tm80uKTmu7fv69nnnkmzb8W7ezZs2revLnq1aunQ4cOaciQIerTp4/WrFljcVgAAADYH4tnSJs1a6ZmzZqlef85c+aoZMmSmjZtmiSpcuXK2r9/vyZPnqw333zT0ocHAACAncn0Y0j37t2rxo0bJ9nWpEkTLVy4UDExMSlO9UZFRSkqKirx67t370p6MEUcExOTuD3h7//eBvvCGDsGxtkxMM7W48iRIxo1alSS/2szQnx8vG7cuKHp06dbfJY1bEd8fLzc3d3VqFGjJNuf5LOd6YU0JCREhQoVSrKtUKFCio2NVWhoqIoUKZLsNuPHj9fo0aOTbd+yZYu8vb2TbQ8KCsq4wLBKjLFjYJwdA+Nsvs8//1y//vqr2TFgw8qUKZPssxweHp7u+8uSs+wfPrg14Xf9pnbQ6+DBg+Xn55f4dcJZW40bN052UlNQUJAaNWrEwdN2ijF2DIyzY2CcrUNMTIzat28vSfrss89SnBhKr7i4OP3555+qVq2aXFxcMux+YR3u3LmjuXPnytfXV9HR0ck+ywkr2umR6YW0cOHCCgkJSbLt2rVrcnV1Vb58+VK8jYeHhzw8PJJtd3NzS/EfsdS2w34wxo6BcXYMjLO59uzZo7CwMOXPn1+ffPJJhi6tx8TEaOPGjWrevDljbGcMw9CuXbu0Zs0alS9fXhs3bkz2WX6SMc/0Azxq166dbEp3y5YtqlWrFm9WAACy2KZNmyQ9OJ+D4zyRFsHBwWrVqpXq1KmjypUrZ8pjWPxOvHfvng4fPqzDhw9LenBZp8OHD+vChQuSHiy3d+jQIXH/Hj166Pz58/Lz89OJEyfk7++vhQsXasCAARnzDAAAQJolFNKmTZuanAS2ICIiQu3atdOkSZPk6pp5C+sW3/P+/fvVoEGDxK8TjvXs2LGjFi9erODg4MRyKj046HXjxo3q37+/Zs6cqaJFi2r69Olc8gkAgCwWHBysw4cPy8nJSU2aNDE7DqzclStXFBMTozVr1ih37tyZ+lgWF9KXXnop8aSklCxevDjZtvr16+vgwYOWPhQAAMhAmzdvliTVrFlTBQoUMDkNrNnly5fVvn17zZ07N9PLqJQFx5ACAADrwHI90iowMFBz585VhQoVsuTxsuSyTwAAwFxxcXHasmWLJFn0GxfhWC5duqS5c+fq008/zdLHZYYUAAAH8Pvvv+vWrVvKnTu3nnvuObPjwApdunRJHTp0UKdOnbL8sZkhBQDAASQs1zdq1ChTz5aGbbpx44ayZcsmf39/lS5dOssfnxlSAAAcQEIhZbkeDzt//rzefvttxcbGmlJGJQopAAB2LzQ0VPv27ZMkLveEJAzD0JAhQ+Tv72/qlReYswcAwM5t2bJFhmGoevXqKlq0qNlxYCXOnTunI0eOaNmyZXJycjI1CzOkAADYOZbr8bCzZ8+qS5cuqlGjhullVGKGFAAAuxYfH594QXyuPwrpwXvi7NmzWrx4sUqWLGl2HEkUUgCADTAMQ3/88YfCw8PNjmJzzp49q2vXril79uyqU6eO2XFgsjNnzuijjz7S2rVr5exsPQvlFFIAgNWbMmWKPv74Y7Nj2LRXXnlF7u7uZseAiW7fvq333ntPS5YssaoyKlFIAQA24NSpU5Kk3LlzK2/evCansT3e3t7q37+/2TFgotOnT8vLy0vff/+9smfPbnacZCikAACb4efnp+HDh5sdA7App06dUvfu3bV06VKrLKMShRQAAMCurVu3TsuWLbPqS35RSAEAAOzQ33//rZUrV2rkyJFmR3ksCikAAICdOXnypHr27Klly5aZHSVNKKQAAAB2JCQkRPny5dPy5ctVuHBhs+OkiXWd8w8AAIB0O378uN599125ubnZTBmVmCEFALuyf/9+bd261ewYKYqLi9Pff/+tP//8Uy4uLhbd9tChQ5mUCrAf8fHx+vTTT7VixQrlzJnT7DgWoZACgB1p3bq1Ll++bHaMTOPl5WV2BMAq/fnnnzp//rwCAgLMjpIuFFIAsCO3bt2SJL311lvKkSOHyWmSio+P16VLl1S8ePF0/ZaY3Llzq0OHDpmQDLBtf/75p/r162ezZVSikAKAXZo4caLKlCljdowkYmJitHHjRjVv3lxubm5mxwHsQmxsrEJCQrRy5Urlz5/f7DjpxklNAAAANujIkSPy9fVVw4YNbbqMSsyQAgAA2JyrV69qwIABWrlypZycnMyO88SYIQUAALAhR48elWEY+v7775UvXz6z42QICikAAICNOHjwoAYMGCB3d3e7uuoES/YAAAA2YuvWrQoMDFSePHnMjpKhKKQAAABWbv/+/dqyZYuGDBlidpRMQSEFAACwYocOHdLQoUMVGBhodpRMwzGkAAAAVurixYsqXry4AgMDlTt3brPjZBoKKQAAgBX67bff9N577yl79ux2XUYlCikAAIDViYmJ0VdffaVvvvnGrs6mTw3HkAIAAFiRvXv36t69e1q2bJnZUbIMM6QAAABWYs+ePfr000/1wgsvmB0lS1FIAQAArEB0dLTCw8MVGBioHDlymB0nS1FIAQAATLZ792517dpVr7zyisOVUYlCCgA2y8/PT9myZZO3t3fin/DwcLNjAbDQuXPn9Pnnn2v27NlmRzENJzUBgI1auXJligW0WLFiKlKkiAmJAFhq7969Kl++vNasWSMPDw+z45iGGVIAsHEbN27UuXPnEv+cPn1anp6eZscC8Bg///yzPvvsM3l7ezt0GZWYIQUAm1e0aFGVKlXK7BgALPT7778rMDBQ3t7eZkcxHYUUAAAgC/300086dOiQBg4caHYUq0EhBQAAyCI7d+7U9OnTFRAQYHYUq8IxpAAAAFngn3/+UaVKlRQQEOAQvw7UEhRSAACATLZlyxZ99NFHyps3L2U0BSzZA0AmMAxDf/75pyIiIjLtMaKjozPtvgFknIiICAUEBCggIECurlSvlPCqAEAmmDx5cpadsODk5JQljwPAcps2bVK2bNm0aNEis6NYNQopAGSCkydPSpJy5cql3LlzZ9rjVKlSRVWqVMm0+weQfhs3bpS/v7+WL19udhSrRyEFgEw0cOBADRkyxOwYALJYZGSkPD09tXz5coe/6H1aUEgBAAAy0IYNG7RhwwbNmTPH7Cg2g0IKAACQQY4dO6YlS5Zo2bJlZkexKVz2CQAAIANs3bpVRYoU0YoVK+Tu7m52HJtCIQUAAHhC69at04IFC5QjRw4u7ZQOFFIAAIAnYBiGTp8+raVLl8rNzc3sODaJCg8AAJBOa9as0dWrVzVgwACzo9g0CikAAEA6bNiwQWvXrtXixYvNjmLzKKQAAAAW+uuvv/Tcc8+padOmHDOaATiGFAAAwAKBgYEaN26c8ufPTxnNIBRSAACANLp9+7Z27NihRYsWydmZGpVRqPUAAABpEBAQoAoVKmjWrFlmR7E7VHsAAIDHWL58ubZs2aJnn33W7Ch2iUIKAADwCPfv31fx4sW1YMECubi4mB3HLrFkDwAAkIolS5bo6NGjmjx5stlR7BqFFABScfLkSX366ae6deuWxbc9cuRIJiQCkJV+++037dy5U3PnzjU7it2jkAJACvbs2aMWLVro5s2bT3Q/hQoVyqBEALLSunXr9PLLL2vevHmcTZ8FKKQA8JBvv/1Wbdu2VWRkpJ577jn16NEjXfeTO3duvfrqqxmcDkBm8/f316+//qqWLVtSRrMIhRQA/mXmzJnq3bu3DMPQa6+9ppUrVypbtmxmxwKQReLj43Xv3j3NmTOHMpqFKKQAoAf/CQ0ePFgTJ06UJHXv3l0zZszgt7AADmT+/Plyd3dXnz59zI7icKj+ABxeVFSU2rdvn1hGx44dq9mzZ1NGAQeyfPlyHT58WO3btzc7ikPiX1sADu3OnTt6/fXXtX37drm6umrBggXq2LGj2bEAZKGjR4+qSZMm8vX1ZZneJLzqABzWpUuXVK9ePW3fvl3Zs2fXDz/8QBkFHMysWbM0f/585cuXjzJqImZIATikP//8U82aNdOlS5dUuHBh/fjjj6pRo4bZsQBkoatXr+r8+fOaPn26nJyczI7j0PhRAIDDuXbtml588UVdunRJlSpV0q+//koZBRzMrFmzdOPGDU2YMIEyagUopAAczi+//KI7d+6oVKlS+uWXX1SqVCmzIwHIQtOnT9epU6dUuXJls6Pg/7BkD8BhFS9eXHnz5jU7BoAsdOfOHdWqVUu9e/dmZtSKUEgBAIBD+OKLL3T//n0NGzbM7Ch4CIUUAADYva1bt+rKlSuJ1xuGdaGQAgAAu7Zs2TK98cYbatiwIcv0VoqTmgAAgN2aOHGijh07Ji8vL8qoFWOGFAAA2KWYmBjlyZNHH3/8MWXUylFIAZgqIiJCR48e1enTp3Xw4MEs+f3xZ86cyfTHAGCuzz77TJUqVdJ7771ndhSkAYUUgKlq166tI0eOmPLYzJgA9mnGjBmKiIjQ66+/bnYUpBGFFICp/vrrL0lSnjx5lD179ix7XFdXV3Xp0iXLHg9A1ti3b5/atm2rPHny8EOnDaGQArAKEydOVMeOHeXm5mZ2FAA2asyYMTIMQyNHjjQ7CixEIQUAADbv3LlzcnNz0+DBg82OgnTgsk8AAMBmGYahsWPHShJl1IZRSAEAgM0aNWqUnJycVLp0abOj4AmwZA8AAGyOYRi6efOmWrZsqZo1a5odB0+IQgoAAGyKYRgaOnSoihcvrp49e5odBxmAJXsAAGBTvv32W+XOnZsyakeYIQVgin/++Uf9+/dXVFSUJMnFxcXkRACsnWEYmjt3rrp27col4uwMM6QAslR4eLiGDx+uKlWq6Pvvv5erq6sGDhyoPHnymB0NgBUzDEOffPKJ7t+/Txm1Q8yQAsgShmFozZo18vPz08WLFyVJDRs21PTp01WhQgVt3LjR5IQArJVhGIqIiNCzzz4rX19fs+MgEzBDCiDTHTt2TK+88orefvttXbx4USVLltTq1asVFBSkKlWqmB0PgBUzDEMDBgzQnj17KKN2jEIKINPcuXNH/fv31zPPPKOffvpJHh4eGjFihE6cOKE333yT3zMN4LHGjRunUqVK6ZVXXjE7CjIRS/YAMlx8fLy+/vprDRo0SNeuXZMktW7dWlOnTlWZMmVMTgfAFhiGoT179qhPnz7KmTOn2XGQyZghBZCh9u3bpzp16qhLly66du2aKlasqM2bN+vbb7+ljAJIE8Mw1LdvXx0+fJgy6iAopAAyxPXr1/Xee+/p+eef12+//abs2bNr0qRJOnr0qBo3bmx2PAA25MSJE6pSpYp69epldhRkEZbsAaRq3759mjBhgqKjox+5n2EY2r17t27fvi1Jat++vSZMmKAiRYpkQUoA9sIwDA0cOFADBgxQjx49zI6DLEQhBZCqqVOnas2aNWnev0aNGpoxY4bq1q2biakA2CPDMNS7d29Vr15dhQoVMjsOshiFFECqEmZG27Vrp5deeumR+xYoUECvvvoqv3EJgMXi4+N148YN9ejRQ9WqVTM7DkxAIQXwWHXr1lXXrl3NjgHADsXHx6tnz5763//+p7Zt25odBybhpCYAAGCapUuX6r///S9l1MExQwoAALJcfHy8pk+frj59+sjZmfkxR8c7AAAAZKn4+Hi9//77ypMnD2UUkpghBQAAWSguLk73799Xy5Yt1bJlS7PjwErwYwkAAMgScXFxeu+993TixAnKKJJghhSwMrdu3VL9+vV1/vx5s6Po/v37ZkcAYEcGDRqkhg0b6vnnnzc7CqwMhRSwMvv379cff/xhdoxELi4uevrpp82OAcCGxcXFaefOnRo1apSyZctmdhxYIQopYKUqVaqk9evXmx1DuXPnVv78+c2OAcBGxcbGqmvXrmrWrBllFKmikAJWysPDQ+XLlzc7BgA8kcOHD6t58+by8fExOwqsWLpOapo1a5bKlCkjT09P1axZU7t27Xrk/suXL9czzzwjb29vFSlSRJ07d9aNGzfSFRgAAFi/2NhYffDBBypfvjxlFI9lcSENDAxUv379NHToUB06dEj16tVTs2bNdOHChRT33717tzp06KCuXbvq2LFjWrVqlfbt26du3bo9cXgAAGB94uPj1alTJzVs2FC5c+c2Ow5sgMWFdOrUqeratau6deumypUra9q0aSpRooRmz56d4v6//vqrSpcurT59+qhMmTJ68cUX1b17d+3fv/+JwwMAAOsSGxur69eva/jw4XrrrbfMjgMbYdExpNHR0Tpw4IAGDRqUZHvjxo21Z8+eFG9Tp04dDR06VBs3blSzZs107do1rV69Wq+++mqqjxMVFaWoqKjEr+/evStJiomJUUxMTOL2hL//exvsiyOOcWxsrCTJMAyHed6OOM6OiHG2f+Hh4fryyy/Vr18/tWjRgrG2U6l9lp9kvC0qpKGhoYqLi1OhQoWSbC9UqJBCQkJSvE2dOnW0fPly+fj4KDIyUrGxsWrZsqW++uqrVB9n/PjxGj16dLLtW7Zskbe3d7LtQUFBljwN2CBHGuPDhw9LevCD2MaNG80Nk8UcaZwdGeNsv3788UfVrVtXLi4uDvfvlyN6+LMcHh6e7vtK11n2Tk5OSb42DCPZtgTHjx9Xnz59NGLECDVp0kTBwcH6+OOP1aNHDy1cuDDF2wwePFh+fn6JX9+9e1clSpRQ48aNlTNnzsTtMTExCgoKUqNGjeTm5paepwIr54hj7O7uLknKmTOnmjdvbnKarOGI4+yIGGf7FR0dra+++kpTpkzR1q1bGWM7l9pnOWFFOz0sKqT58+eXi4tLstnQa9euJZs1TTB+/HjVrVtXH3/8sSSpevXqypYtm+rVq6exY8eqSJEiyW7j4eEhDw+PZNvd3NxSfIOnth32w5HG2NX1wcfSycnJYZ5zAkcaZ0fGONuX6Ohode7cWe3bt0/8gZoxdgwPj/OTjLlFJzW5u7urZs2ayaZog4KCVKdOnRRvEx4eLmfnpA/j4uIi6cHMKgAAsE0xMTG6f/++evTooRYtWpgdBzbM4rPs/fz8tGDBAvn7++vEiRPq37+/Lly4oB49ekh6sNzeoUOHxP1btGihtWvXavbs2frnn3/0yy+/qE+fPnruuedUtGjRjHsmAAAgy0RFRcnX11dXrlzRyy+/bHYc2DiLjyH18fHRjRs3NGbMGAUHB6tatWrauHGjSpUqJUkKDg5Ock3STp06KSwsTDNmzNBHH32k3Llz6+WXX9aECRMy7lkAAIAs1bdvX3Xp0kVVq1Y1OwrsQLpOaurZs6d69uyZ4vcWL16cbFvv3r3Vu3fv9DwUAACwIpGRkdq9e7emTZsmT09Ps+PATqTrV4cCAADHExkZqbZt2youLo4yigxFIQUAAGmyb98+de/eXU2aNDE7CuwMhRQAADxSRESEOnXqpFq1alFGkSkopAAAIFWxsbHy9fVV+/bt5eXlZXYc2Kl0ndQEAADsX3h4uMLCwvTFF1+oTJkyZseBHWOGFAAAJBMeHq42bdro1KlTlFFkOgopAABIZs6cOfLz89OLL75odhQ4AJbsAQBAovv372vGjBn65JNPzI4CB8IMKQAAkCTdu3dPPj4+ql27ttlR4GCYIQUAAIqKilJkZKSGDRumF154wew4cDDMkAIA4ODCwsL0+uuv6969e5RRmIIZUiCTTJw4UXv37rX4dteuXcuENACQul69emno0KEqXbq02VHgoCikQCa4cePGE58QULBgwQxKAwApu3v3rn777TctWLBA7u7uZseBA6OQApkgJiYm8e9z5861+PbOzs5q1qxZRkYCgCTu3r0rHx8fjRw5kjIK01FIgUzk7Oys999/3+wYAJDM77//rpEjR3LMKKwChRQAAAdy584dffDBB/r666/l5uZmdhxAEmfZAwDgMCIiIuTj46P+/ftTRmFVmCEFAMAB3Lp1SzExMVqwYIGKFy9udhwgCWZIAQCwc7du3ZKPj4+uXLlCGYVVopACAGDn5syZo88//1w1atQwOwqQIpbsAQCwUzdv3tS8efM0ePBgs6MAj8QMKQAAdujGjRtq06YN1zSGTWCGFAAAOxMeHq6YmBhNmTJFTz/9tNlxgMdihhQAADsSGhqqli1bShJlFDaDQgoAgJ0wDEM9e/bUF198ocKFC5sdB0gzluwBALAD165d05EjR7RixQq5uvLfO2wLM6QAANi4a9euydfXV0WLFqWMwibxrgUAwIYZhqH9+/frq6++UpUqVcyOA6QLM6QAANiokJAQ+fr6qmnTppRR2DRmSAEAsEF3797Vu+++q5kzZ8rZmfkl2DYKKQAANiY4OFhubm5asWKFChUqZHYc4InxIxUAADbkypUrateunW7dukUZhd2gkAIAYEMWLFigOXPmqEKFCmZHATIMS/YAANiAy5cva/ny5RoxYoTZUYAMxwwpAABW7tKlS2rfvr3eeOMNs6MAmYIZUgAArFhYWJicnJw0f/58lStXzuw4QKZghhQAACt14cIFtWzZUtmyZaOMwq4xQwr8n7/++ktbt26VYRhPfF93797NgEQAHFl8fLz69u0rf39/5c6d2+w4QKaikAJ6sCTWoEEDhYSEZOj9enh4ZOj9AXAM58+f1+nTp7VmzRoueg+HQCEFJH3++ecKCQlR0aJFVa9evQy731dffTXD7guAYzh37py6dOmiRYsWUUbhMCikcHjnz5/XlClTJEkzZ85U69atzQ0EwGEZhqGjR49q0aJFKlWqlNlxgCzDj15weIMHD1ZUVJReeukltWrVyuw4ABzUP//8o7Zt26pFixaUUTgcZkjh0H799VcFBATIyclJU6dOlZOTk9mRADig69evq1u3bvr666/5dwgOiRlSOCzDMOTn5ydJ6tSpk5599lmTEwFwRP/8849cXFy0evVqlShRwuw4gCkopHBY33zzjfbu3ats2bJp7NixZscB4IBOnz6tbt26KSIiQnnz5jU7DmAaCikcUmRkpD755BNJ0ieffKKiRYuanAiAI1qyZImWLl2qYsWKmR0FMBXHkMIhTZs2TefPn1fx4sX10UcfmR0HgIM5efKk1q9frzFjxpgdBbAKzJDCIa1du1aSNHz4cHl7e5ucBoAjOXnypD744AO1bdvW7CiA1aCQwiHFxsZKkkqWLGlyEgCO5NatW/L09NSyZctUpEgRs+MAVoNCCgBAFjhx4oTeeust5c+fnzIKPIRCCgBAJouNjdXgwYO1YsUKDhMCUsBJTQAAZKJjx44pNDRU3377LRe9B1LBDCkAAJnkzz//VJ8+fVS5cmXKKPAIzJACAJAJ4uPjdfr0aa1cuVIFChQwOw5g1ZghBQAggx09elSdOnVS69atKaNAGjBDCruyaNEiDRkyRDExMY/c79atW1mUCICjuXDhgj766CMFBASYHQWwGRRS2JWJEycqJCQkTfu6u7vrqaeeyuREABzJsWPHVKxYMa1Zs0Y5c+Y0Ow5gMyiksBvnzp3TX3/9JWdnZ/3++++PvbRKoUKFlDdv3ixKB8DeHTp0SAMHDtTKlSuVO3dus+MANoVCCruxefNmSVLt2rVVs2ZNk9MAcDRr165VYGAgP+gC6UAhhd3YtGmTJKlZs2YmJwHgSA4ePKjdu3fr008/NTsKYLMopLAL0dHR2rp1qySpadOmJqcB4CgOHjyowYMHa+XKlWZHAWwahRR2Yc+ePbp3754KFCigZ5991uw4ABzA9evXlS9fPgUGBnLMKPCEuA4p7ELCcn2TJk3k7MzbGkDm+v3339W+fXsVLVqUMgpkAP7nhl3g+FEAWSUyMlITJkxQYGCg3NzczI4D2AWW7GHzrly5oiNHjsjJyUmNGjUyOw4AO/brr7/KMAytXr2a300PZCBmSGHzEi73VKtWLX5FH4BMs3fvXo0ePVpVq1aljAIZjEIKm8dyPYDMFhcXp5CQEAUGBvIbmIBMwJI9bFpsbKyCgoIkcbknAJlj9+7dWrJkiebNm2d2FMBuUUhh037//XfdunVLefLk0XPPPWd2HAB25q+//tL48eO5ziiQyViyh01LWK5v3LixXFxcTE4DwJ7s379fRYoU0apVq5QjRw6z4wB2jUIKm5ZQSFmuB5CRduzYodGjR8vV1VXe3t5mxwHsHoUUNuv69evav3+/pAcXxAeAjGAYhrZu3aqVK1cqW7ZsZscBHALHkMJUUVFRWrt2rW7evJni9+Pi4nTs2DGdP38+2ZL8n3/+KcMwVKNGDRUpUiQr4gKwc9u3b9fJkyf16aefmh0FcCgUUpgqICBAnTt3fqL7YLkeQEb4+eefNW3aNAUEBJgdBXA4FFKYKjQ0VJJUsmRJPf/888m+Hx8fr+DgYBUpUiTF31GfM2dO9evXL7NjArBzV65cUenSpRUQEMAxo4AJKKSwCi+99JK+/vrrZNtjYmK0ceNGNW/enN8ZDSBTBAUFadasWVqzZk2KP/gCyHx88gAADuvu3btatGiRVqxYQRkFTMQMKQDAIW3evFkFCxbUihUrzI4CODx+HAQAOJxNmzZp3rx5qly5stlRAIgZUgCAg4mNjVVUVJRWrFghDw8Ps+MAEIUUAOBANmzYoK1bt2ratGlmRwHwLxRSAIBDOHDggL7++mstW7bM7CgAHsIxpDDVL7/8IknKkSOHyUkA2LOdO3fqqaee0vLly1mmB6wQhRSm+fnnn7Vu3Tq5uLjogw8+MDsOADv13XffaebMmfLw8JC7u7vZcQCkgEIKU8THx8vPz0+S9P7776tq1aomJwJgj+Lj43X48GEtXbqUMgpYMY4hhSmWLFmiQ4cOKWfOnBo9erTZcQDYoW+//VZhYWEaOXKk2VEAPAYzpMhy9+7d05AhQyRJw4YNU4ECBUxOBMDefPfdd1q1apV8fX3NjgIgDZghRZabNGmSgoODVaZMGfXp08fsOADszIULF1SjRg01b95cbm5uZscBkAbMkCJLXbp0SZMmTZIkTZw4kbNdAWSoVatWadiwYSpZsiRlFLAhFFJkqSFDhigiIkL16tXTm2++aXYcAHbk+vXr2rx5s/z9/eXk5GR2HAAWoJAiyxw5ckRLly6VJE2dOpX/MABkmG+++UahoaFasGCBXF05Gg2wNRRSZJnff/9dktSwYUPVqlXL5DQA7MWKFSu0ceNGVahQwewoANKJHyOR5bJnz252BAB2IioqSrly5dLChQvl4uJidhwA6UQhBQDYpGXLlumvv/7S2LFjzY4C4AlRSAEANmfHjh3avn275s2bZ3YUABmAQgoAsCmbNm3Siy++qBdffJFlesBOcFITAMBmLF68WGvXrpW3tzdlFLAjFFIAgE2IjY1VcHCw5syZI2dn/vsC7AlL9gAAq7dw4ULlypVLgwcPNjsKgEzAj5gAAKu2ZMkS7d+/X2+88YbZUQBkEmZIAQBW6/Tp02rQoIHatWvHMj1gx/h0AwCs0pw5czR9+nSVKFGCMgrYOT7hAACrc+HCBZ08eVJffvml2VEAZAEKKQDAqsybN09xcXGaOnWqnJyczI4DIAtQSAEAVmPGjBk6fvy4SpcubXYUAFmIk5oAAFYhIiJCFSpUUK9evZgZBRwMhRQAYLpp06YpOjpaAwcONDsKABNQSB3AoUOH9Ntvv5kdQ7t37zY7AgArtH79el26dEmTJk0yOwoAk1BI7dzFixdVt25dRUREmB0lkYeHh9kRAFiJtWvXqlmzZnrttddYpgccWLoK6axZszRp0iQFBweratWqmjZtmurVq5fq/lFRURozZoyWLVumkJAQFS9eXEOHDlWXLl3SHRxpM2TIEEVERKhs2bKqUaOG2XHk7u6ujz76yOwYAKzA5MmTdf36db3++uuUUcDBWVxIAwMD1a9fP82aNUt169bV3Llz1axZMx0/flwlS5ZM8TbvvPOOrl69qoULF6p8+fK6du2aYmNjnzg8Hu3333/XsmXLJD0Yt1q1apmcCAAeiIyMlJubmz7//HPKKADLC+nUqVPVtWtXdevWTdKDA9E3b96s2bNna/z48cn237Rpk3bs2KF//vlHefPmlSQu55EFDMOQn5+fJKlDhw6UUQBWY9KkSapZs6b69u1rdhQAVsKi65BGR0frwIEDaty4cZLtjRs31p49e1K8zffff69atWpp4sSJKlasmJ566ikNGDDAqo5ptEerV6/WL7/8Ii8vL40bN87sOAAg6cH/CWFhYcn+HwHg2CyaIQ0NDVVcXJwKFSqUZHuhQoUUEhKS4m3++ecf7d69W56envr2228VGhqqnj176ubNm/L390/xNlFRUYqKikr8+u7du5KkmJgYxcTEJG5P+Pu/t+HBUtgnn3wiSfroo49UqFAhm32NGGPHwDg7hj/++EMvvvii3nnnHQ7bslN8lh1DauP8JOOerpOaHj7exzCMVI8Bio+Pl5OTk5YvX65cuXJJerDs/9Zbb2nmzJny8vJKdpvx48dr9OjRybZv2bJF3t7eybYHBQWl52nYrbVr1+rs2bPKmzevqlWrpo0bN5od6Ykxxo6BcbZf33zzjeLj49WmTRtt3brV7DjIZHyWHcPD4xweHp7u+7KokObPn18uLi7JZkOvXbuWbNY0QZEiRVSsWLHEMipJlStXlmEYunTpkipUqJDsNoMHD048/lF6MENaokQJNW7cWDlz5kzcHhMTo6CgIDVq1Ehubm6WPBW7de3aNXXo0EGSNHHiRL3xxhsmJ3oyjLFjYJzt219//aXy5cvrk08+YZztHJ9lx5DaOCesaKeHRYXU3d1dNWvWVFBQkF5//fXE7UFBQWrVqlWKt6lbt65WrVqle/fuKXv27JKkkydPytnZWcWLF0/xNh4eHileq9LNzS3FN3hq2x3RuHHjdPfuXf3nP/9R586d5exs0WHCVosxdgyMs/2ZOHGiOnTooNGjRycu5zHO9o8xdgwPj/OTjLnFbcXPz08LFiyQv7+/Tpw4of79++vChQvq0aOHpAezmwkzdJLUtm1b5cuXT507d9bx48e1c+dOffzxx+rSpUuKy/V4MqtXr5YkffbZZ3ZTRgHYHsMwNHLkSEVFRalw4cJmxwFg5Sw+htTHx0c3btzQmDFjFBwcnHiMYqlSpSRJwcHBunDhQuL+2bNnV1BQkHr37q1atWopX758eueddzR27NiMexZIlHCiAJfWAmAWwzB0//59vfzyy6pfv77ZcQDYgHSd1NSzZ0/17Nkzxe8tXrw42bZKlSpxgDMAOADDMDR8+HCVLFlS77//vtlxANgI1nQBABlm+fLlyp49O2UUgEXSNUMKAMC/GYahZcuWydfXV66u/NcCwDL8qwEAeCKGYWjQoEEqUKAAZRRAuvAvBwAg3QzDUFhYmCpWrKguXbqYHQeAjeIYUgBAuhiGoYEDB+rYsWOUUQBPhEIKAEiXUaNGqVixYqpdu7bZUQDYOJbsAQAWMQxDR48e1YcffqgCBQqYHQeAHWCGFACQZoZhqH///tq9ezdlFECGoZACANLswIEDqlChgnr16mV2FAB2hEIKAHgswzA0dOhQlS9fnjIKIMNRSAEAj2QYhnr37q0SJUood+7cZscBYIc4qQkAkKr4+HiFhYXp3Xff5Wx6AJmGGVIAQIri4+PVq1cvbdmyhTIKIFNRSAEAKZozZ45q1qypt99+2+woAOwcS/YAgCTi4+Pl7++vHj16yNmZeQsAmY9/aQAAieLj49W9e3e5urpSRgFkGWZIAQCSHpxNf+vWLTVu3JhlegBZih9/AQCKi4tTt27ddOXKFcoogCxHIQUAyM/PTw0aNNDTTz9tdhQADoglewBwYHFxcTp06JBGjx7NRe8BmIYZUgBwULGxserSpYtOnjxJGQVgKmZIAcBB/fLLL2ratKl8fX3NjgLAwVFIAcDBxMbG6uOPP9a4cePk7e1tdhwAYMkeABxJbGysOnfurDp16lBGAVgNZkgBwEHExMTo/v378vPz07PPPmt2HABIxAwpADiAmJgYdezYUb/99htlFIDVoZACgAOYNm2a3nrrLTVp0sTsKACQDEv2AGDHoqOj5e/vrwEDBsjJycnsOACQImZIAcBORUdHq3379ipSpAhlFIBVY4YUAOxQfHy8bty4oU6dOqlZs2ZmxwGAR2KGFADsTFRUlHx8fBQREUEZBWATKKQAYGd69Oihjh07qmzZsmZHAYA0YckeAOxEVFSUDh8+rOnTpytHjhxmxwGANGOGFADsQGRkpNq2batbt25RRgHYHAopANiB7du367333lPTpk3NjgIAFmPJHgBsWGRkpPr3768vv/xS7u7uZscBgHRhhhQAbFRUVJR8fX31xhtvUEYB2DRmSAHABoWHhys6Olrjxo1TlSpVzI4DAE+EGVIAsDHh4eHy9fXViRMnKKMA7AKFFABszOTJk9W3b1/Vrl3b7CgAkCFYsrcjp0+fVmRkpNkxAGSS+/fva/HixRo+fDi/mx6AXWGG1A7cv39fQ4YMUdWqVRUREaFs2bKpYMGCZscCkIHu378vHx8fVatWjTIKwO5QSG2YYRhauXKlKlasqPHjxys6OlpNmjTRgQMHlCdPHrPjAcggsbGxunHjhgYNGqT69eubHQcAMhyF1EYdPXpUDRo0kK+vry5fvqwyZcpo3bp1+vHHH1WxYkWz4wHIIPfu3VOrVq3k5uamF1980ew4AJApKKQ25tatW+rdu7eeffZZ7dixQ56enhozZoyOHTumVq1asZQH2BHDMNSlSxcNGTJERYoUMTsOAGQaTmqyEfHx8fL399fgwYMVGhoqSXrzzTc1ZcoUlSpVyuR0ADJaWFiY/vzzTy1evFje3t5mxwGATMUMqQ347bff9Pzzz+u9995TaGioKleurK1bt2r16tWUUcAO3b17V++8844kUUYBOAQKqRW7evWqOnfurBdeeEH79+9Xzpw5NXXqVB05ckQNGzY0Ox6ATLJt2zaNGDGC64wCcBgs2VuBCxcuKDo6Osm2DRs2aOTIkbp7964kqVOnTho/frwKFy5sRkQAWeDOnTsaMGCA5s6dK2dn5gsAOA4KqclGjBihTz/9NNXv16pVS1999ZVeeOGFLEwFIKvdu3dPPj4+GjNmDGUUgMOhkJrs0KFDkiRPT0+5u7snbs+XL5+GDBmiLl268J8TYOdu374tJycnzZw5U+XKlTM7DgBkOZqOlZgxY4bu3LmT+Oeff/5Rt27dKKOAnbt165Z8fHx0/vx5yigAh0XbAQATTZ48WZ999pmqV69udhQAMA1L9gBggps3byogIEDjxo0zOwoAmI4ZUgDIYjdv3lSbNm1Up04ds6MAgFVghhQAslB0dLRu376tiRMnqkaNGmbHAQCrwAwpAGSR0NBQvfbaa8qTJw9lFAD+hUIKAFnAMAx16dJFkydPVp48ecyOAwBWhSV7AMhk169f15kzZ7Rq1Sp5eHiYHQcArA4zpACQia5duyZfX19lz56dMgoAqWCGFAAy0fbt2/Xll1+qatWqZkcBAKtFIQWATHD16lUNGTJECxYskJOTk9lxAMCqUUgBIIPdvHlT7777rr766ivKKACkAYUUADLQ1atX5eXlpUWLFqlEiRJmxwEAm8BJTQCQQYKDg+Xr66vr169TRgHAAhRSAMggX3zxhWbPnq1y5cqZHQUAbApL9gDwhC5fvqzvvvtOEydONDsKANgkZkgB4AlcvnxZ7du3V+PGjc2OAgA2i0IKAOkUGRmpe/fuad68eSpfvrzZcQDAZlFIASAdLl68qNdee03FixenjALAE6KQAoCFYmNj1b17d82bN0/ZsmUzOw4A2DxOagIAC5w/f15Xr17Vd999Jzc3N7PjAIBdYIYUANLo3Llz6ty5swoWLEgZBYAMRCEFgDT65Zdf5O/vr9KlS5sdBQDsCkv2APAYZ8+e1fjx4zVv3jyzowCAXaKQAsAjXLlyRV27dtXixYvNjgIAdotCCgCpuHDhgvLkyaOAgAAVKlTI7DgAYLc4hhQAUnDmzBl16tRJYWFhlFEAyGQUUgBIwaxZs7RkyRIVLVrU7CgAYPdYsgeAfzl16pS2b9+uKVOmmB0FABwGM6QA8H9OnjypHj166LXXXjM7CgA4FGZIAUDS/fv3FRsbq2XLlqlIkSJmxwEAh8IMKQCH99dff6l169YqX748ZRQATEAhBeDQIiMj1b9/fy1dulTu7u5mxwEAh8SSPQCHdfz4cUVGRmrDhg1ycXExOw4AOCxmSAE4pGPHjql3794qXrw4ZRQATEYhBeBwDMPQwYMHFRAQoIIFC5odBwAcHkv2ABzKn3/+qVmzZmnWrFlmRwEA/B8KKQCHcebMGfXr108BAQFmRwEA/AtL9gAcwsmTJ1WwYEF98803KlCggNlxAAD/QiEFYPeOHDmiXr16KSYmRnnz5jU7DgDgIRRSAHZv8eLFCgwMpIwCgJXiGFIAduvgwYM6cuSIvvjiC7OjAAAegRlSk8XExEiSnJycTE4C2JeDBw9q8ODBat26tdlRAACPQSE12YkTJyRJ5cqVMzkJYD/u3r0rDw8PrVy5Unny5DE7DgDgMSikJrp586YuXLggSapRo4a5YQA7sW/fPvn6+qpSpUqUUQCwERRSEx05ckSSVKZMGeXKlcvkNIDtCwsL05gxY7RixQp+HSgA2BBOajLR4cOHJTE7CmSE3377Td7e3vruu+/k7MzP2gBgS/hX20QUUiBj/Prrrxo1apRKlSpFGQUAG8S/3CaikAJPzjAMnTp1SoGBgcqZM6fZcQAA6cCSvUmioqJ0/PhxSRRSIL327Nmjb775RtOmTTM7CgDgCVBITXLs2DHFxsYqb968KlGihNlxAJvzxx9/aNy4cVq5cqXZUQAAT4gle5P8e7mei+IDljl69KjKlCmjwMBA5ciRw+w4AIAnRCE1CcePAumzc+dODR48WE5OTsqePbvZcQAAGYBCahIKKWA5wzC0bt06ffPNN8qWLZvZcQAAGYRjSE0QHx9PIQUstGPHDl2+fFlTp041OwoAIIMxQ2qCc+fOKSwsTB4eHqpUqZLZcQCr9/PPP2vKlClq3bq12VEAAJmAQmqCQ4cOSZKqVasmNzc3k9MA1u3mzZsqUKCAVq5cKW9vb7PjAAAyAYXUBCzXA2mzdetWvf/++6pSpQplFADsGIXUBBRS4PFCQ0M1Z84cLV26lEujAYCdS1chnTVrlsqUKSNPT0/VrFlTu3btStPtfvnlF7m6ujp8EaOQAo+2detW3bx5U6tWrZKXl5fZcQAAmcziQhoYGKh+/fpp6NChOnTokOrVq6dmzZrpwoULj7zdnTt31KFDBzVs2DDdYe1BaGioLl26JEmqXr26yWkA67N582bNmjVLJUuWZGYUAByExYV06tSp6tq1q7p166bKlStr2rRpKlGihGbPnv3I23Xv3l1t27ZV7dq10x3WHhw5ckSSVK5cOeXMmdPkNIB1iY+P1/Xr17VixQp5enqaHQcAkEUsKqTR0dE6cOCAGjdunGR748aNtWfPnlRvt2jRIp05c0YjR45MX0o7knCGPcv1QFL79+/X8OHD1a5dO8ooADgYiy6MHxoaqri4OBUqVCjJ9kKFCikkJCTF25w6dUqDBg3Srl275OqatoeLiopSVFRU4td3796VJMXExCgmJiZxe8Lf/73N2h08eFDSg+V6W8ptFlscY1hu9+7d2rZtm3744QfG2o7xebZ/jLFjSG2cn2Tc0/Wbmh4+rsswjBSP9YqLi1Pbtm01evRoPfXUU2m+//Hjx2v06NHJtm/ZsiXFS78EBQWl+b7N9ssvv0h6MGgbN240OY3tsKUxhmVOnjypEiVKyM/PTzt37jQ7DrIAn2f7xxg7hofHOTw8PN335WQYhpHWnaOjo+Xt7a1Vq1bp9ddfT9zet29fHT58WDt27Eiy/+3bt5UnTx65uLgkbouPj5dhGHJxcdGWLVv08ssvJ3uclGZIS5QoodDQ0CTHXcbExCgoKEiNGjWyiQvMR0REKG/evIqLi9PZs2dVrFgxsyNZPVsbY1hmw4YNWr58uRYsWKAdO3YwznaOz7P9Y4wdQ2rjfPfuXeXPn1937tyx+DwZi2ZI3d3dVbNmTQUFBSUppEFBQWrVqlWy/XPmzKk//vgjybZZs2bpp59+0urVq1WmTJkUH8fDw0MeHh7Jtru5uaX4Bk9tu7U5cuSI4uLilD9/fpUqVYoziC1gK2OMtIuNjdXevXu1YsWKxM8C4+wYGGf7xxg7hofH+UnG3OIlez8/P7Vv3161atVS7dq1NW/ePF24cEE9evSQJA0ePFiXL1/WkiVL5OzsrGrVqiW5fcGCBeXp6ZlsuyP49/VHKaNwZOvWrVN8fLwmTpwoiePNAMDRWVxIfXx8dOPGDY0ZM0bBwcGqVq2aNm7cqFKlSkmSgoODH3tNUkfFBfGBB2U0MDBQS5YsMTsKAMBKpOukpp49e6pnz54pfm/x4sWPvO2oUaM0atSo9Dyszbt9+7YkqUiRIuYGAUxy7do1PfXUU1qyZAnLeQCARPwuewBZYvXq1frkk09UpUoVyigAIIl0zZACgCUuXryo9evXa+HChWZHAQBYIWZIAWSqNWvWKC4uTosXL07zL8cAADgWCimATLNy5Up99913Kl68OFeWAACkikIKIFPExcXJMAz5+/szMwoAeCT+lwCQ4ZYvX65z585p6NChZkcBANgACimADLVlyxZt27ZN8+fPNzsKAMBGUEgBZJgdO3aoTp06atiwoVxcXMyOAwCwERxDCiBDfP3111q6dKm8vLwoowAAizBDCuCJRUZG6syZM5o3b56cnfk5FwBgGQopgCfi7++vokWLasyYMWZHAQDYKKYyAKTbokWL9Pvvv6tx48ZmRwEA2DBmSAGky5UrV1S3bl117NiRZXoAwBOhkAKw2Lx583T8+HFNmzbN7CgAADtAIQVgkb///lt//PGHvvzyS7OjAADsBIU0k5w7d05TpkzR/fv3E7ft3bvXxETAk1u0aJGaNm2qr776yuwoAAA7QiHNJDNmzNCMGTNS/F6ePHmyOA3w5GbOnKmTJ0+qU6dOZkcBANgZCmkmiYiIkCQ1bNhQr7zySuL2fPnyqU2bNmbFAtIlJiZGhQoVUs+ePeXk5GR2HACAnaGQZrIXX3xRgwYNMjsGkG7Tp0+XJPXp08fkJAAAe8W1WgCkatWqVTp//rx69+5tdhQAgB1jhhRAijZt2qRXX31Vb731Fsv0AIBMxQwpgGSmTJmin376SV5eXpRRAECmo5ACSCIsLEyxsbGaMGECZRQAkCUopAASTZo0SUePHtUnn3xCGQUAZBkKaSYxDMPsCIBFpkyZolu3bqlOnTpmRwEAOBhOasoE4eHhWr9+vSSpaNGiJqcBHu/cuXN6/fXXVaZMGWZGAQBZjhnSTDB16lRdunRJJUuWVPv27c2OAzzSuHHjtGTJEpUtW5YyCgAwBYU0g125ckWff/65JGnChAny8vIyORGQuoMHDyo6OlrDhw83OwoAwIFRSDPY8OHDdf/+fb3wwgvy8fExOw6QqmnTpql06dIaPXo0M6MAAFNxDGkGOnTokBYtWiRJ+uKLL/hPHlYroYTmzZvX7CgAAFBIM4phGProo49kGIbatGmjF154wexIQDKGYSgqKkr/+c9/1KJFC7PjAAAgiUKaYb7//ntt375dHh4eiceQAtbEMAyNGDFC5cuXV8eOHc2OAwBAIgppOty+fVv37t1L/Do+Pl4ff/yxJMnPz0+lSpUyKxqQqgULFsjb25syCgCwOhRSCwUFBal58+aKjY1N9r2CBQtq8ODBJqQCUmcYhtatW6eOHTvK3d3d7DgAACRDIbXQwYMHFRsbKycnJ7m5uSVu9/T01PTp05UjRw4T0wFJGYahIUOGKG/evJRRAIDVopCmU6dOneTv7292DOCRbty4oZIlS+qDDz4wOwoAAKniOqSAHTIMQ5988okuX75MGQUAWD0KKWCHhg0bpsKFC+uZZ54xOwoAAI/Fkj1gRwzD0OnTp9WjRw+VKFHC7DgAAKQJM6SAnTAMQ35+ftq8eTNlFABgUyikgJ3YuXOnypYtqw8//NDsKAAAWIRCCtg4wzA0duxY1apVS7179zY7DgAAFqOQAjbMMAz17dtXefPmVbZs2cyOAwBAunBSE2Cj4uPjFRERoVatWqlhw4ZmxwEAIN2YIQVsUHx8vHr37q2tW7dSRgEANo9CCtigL774QjVq1FCrVq3MjgIAwBNjyR6wIfHx8Vq1apX69u0rV1c+vgAA+8AMKWAj4uPj1aNHD92/f58yCgCwK/yvBtiI4OBg1a9fX++++67ZUQAAyFDMkAJWLi4uTu+//74iIiIoowAAu8QM6SPcvXtXn3/+ua5fv5647ciRIyYmgiPq3bu3XnzxRZUvX97sKAAAZAoK6SOsW7dO48ePT/F7uXPnztowcDhxcXE6deqURowYocKFC5sdBwCATEMhfYTw8HBJUpUqVZIslXp5ealdu3ZmxYIDiIuLU7du3dSoUSO1bdvW7DgAAGQqCmkaVKpUSUOGDDE7BhzIpk2bKKMAAIdBIQWsSGxsrIYPH67Ro0fL3d3d7DgAAGQJzrIHrERsbKw6d+6sGjVqUEYBAA6FGVLACsTGxioyMlI9evRQ3bp1zY4DAECWYoYUMFlMTIw6duyoffv2UUYBAA6JQgqY7LPPPtMbb7yhBg0amB0FAABT2P2S/a1bt/T222/rwoULFt/29u3bGR8I+D8xMTH65ptvNHz4cDk787MhAMBx2X0hHTVqlLZt2/ZE98FvyEFGi46OVocOHdSmTRvKKADA4dl1If377781a9YsSdKCBQtUqVIli+/Dw8ND//nPfzI6GhyYYRi6dOmS3n33XbVo0cLsOAAAmM6uC+nHH3+s2NhYvfbaa+ratavZcQBFR0erY8eOmjJlCmUUAID/Y7drhdu2bdP69evl6uqqSZMmmR0HkCR16dJF7777rooWLWp2FAAArIZdzpDGxcXJz89PkvTBBx+ka6keyEhRUVE6ffq0pk2bpvz585sdBwAAq2KXM6SLFi3S0aNHlTt3bo0cOdLsOHBwUVFRatu2rc6fP08ZBQAgBXY3QxoWFqZhw4ZJkkaMGKF8+fKZnAiObv369erWrZuaNWtmdhQAAKySTRfS6Oho3bx5U1euXJGbm5sk6YsvvtDVq1dVvnx59erVy+SEcGSRkZEaOnSoJk6cKBcXF7PjAABgtWy2kEZFRalatWo6d+5cit+fNGmS3N3dszYU8H8iIyPl6+urDz74gDIKAMBj2GwhvXr1amIZffg//LfeekutWrUyIRUgRUREKC4uTsOHD+catgAApIHNFtIEbm5uun//fuKSPWCm8PBw+fr6atiwYfrvf/9rdhwAAGyCXZ5lD5hl9OjR6tOnD2UUAAAL2PwMKWANwsPDtWbNGn3++edycnIyOw4AADaFGVLgCd2/f18+Pj4qUaIEZRQAgHRghhR4AoZh6OLFixowYIDq169vdhwAAGwSM6RAOt27d0+tW7dWwYIFKaMAADwBCimQDoZhqF27dhowYIDy5s1rdhwAAGwaS/aAhcLCwnT+/HktXrxYuXPnNjsOAAA2jxlSwAJhYWHy8fHRnTt3KKMAAGQQZkgBC6xbt07Dhg1TnTp1zI4CAIDdoJACaXD37l2NGDFCX3zxBZd2AgAgg7FkDzzG3bt35ePjI19fX8ooAACZgBlS4BHu3r0rJycnTZ48WVWrVjU7DgAAdokZUiAVt2/f1ttvv61Lly5RRgEAyEQUUiAVI0eO1Lhx41S5cmWzowAAYNdYsgcecuvWLa1fv17Tpk3jmFEAALIAM6TAv9y8eVM+Pj6qVq0aZRQAgCzCDCnwf+Li4nTp0iVNmDBBzz77rNlxAABwGMyQApJu3LihFi1aqFy5cpRRAACyGDOkcHhxcXFq166dPv/8c2XLls3sOAAAOBwKKRxaaGioQkJCtGrVKmXPnt3sOAAAOCSW7OGwrl+/rjZt2kgSZRQAABNRSOGwEi7tVK1aNbOjAADg0Fiyh8O5du2axo0bpy+//NLsKAAAQMyQwsFcv35dvr6+6t69u9lRAADA/2GGFA4jNDRUnp6emj9/vsqWLWt2HAAA8H+YIYVDCA4O1jvvvKMbN25QRgEAsDIUUjiETz/9VLNnz1bp0qXNjgIAAB7Ckj3s2pUrV7Rt2zbNmjXL7CgAACAVzJDCbl2+fFnt2rXTCy+8YHYUAADwCBRS2KXY2FiFhIRo7ty5qlChgtlxAADAI1BIYXcuXbqk1157TU8//TRlFAAAG8AxpLArUVFR6ty5s+bMmSN3d3ez4wAAgDSgkMJuXLhwQffu3dP3338vLy8vs+MAAIA0YskeduH8+fPq1KmTvLy8KKMAANgYZkhhFzZt2iR/f3+uMwoAgA2ikMKmnTt3TtOnT9fUqVPNjgIAANKJQgqbdfHiRXXp0kWLFi0yOwoAAHgCFFLYpCtXrih37txaunSpihUrZnYcAADwBDipCTbnzJkzateuncLDwymjAADYgXQV0lmzZqlMmTLy9PRUzZo1tWvXrlT3Xbt2rRo1aqQCBQooZ86cql27tjZv3pzuwMCECRO0ZMkSFSpUyOwoAAAgA1hcSAMDA9WvXz8NHTpUhw4dUr169dSsWTNduHAhxf137typRo0aaePGjTpw4IAaNGigFi1a6NChQ08cHo7l9OnTWrFihebNm6fixYubHQcAAGQQiwvp1KlT1bVrV3Xr1k2VK1fWtGnTVKJECc2ePTvF/adNm6aBAwfqv//9rypUqKDPPvtMFSpU0Pr16584PBzHqVOn9P7776t+/fpmRwEAABnMopOaoqOjdeDAAQ0aNCjJ9saNG2vPnj1puo/4+HiFhYUpb968qe4TFRWlqKioxK/v3r0rSYqJiVFMTEzi3xP8+++wLwljHhoaqkWLFqlgwYKMtx1K6XMN+8M42z/G2DGkNs5PMu4WFdLQ0FDFxcUlO3avUKFCCgkJSdN9TJkyRffv39c777yT6j7jx4/X6NGjk23fsmWLvL29JUnXr19P3B4UFJSmx4btuXz5svz9/TVkyBDdunVLhw8fNjsSMhGfZcfAONs/xtgxPDzO4eHh6b6vdF32ycnJKcnXhmEk25aSgIAAjRo1St99950KFiyY6n6DBw+Wn59f4td3795ViRIl1LhxY+XMmVOSkhyz2qhRI7m5uVn6NGDl7t27pzfffFMffvihmjZtyhjbsZiYGAUFBfFZtnOMs/1jjB1DauOcsKKdHhYV0vz588vFxSXZbOi1a9cee8ZzYGCgunbtqlWrVumVV1555L4eHh7y8PBItt3NzS3xif/7Bfj3dtiHEydOyMXFRd9//722bdvGGDsIxtkxMM72jzF2DA+P85OMuUUnNbm7u6tmzZrJpmiDgoJUp06dVG8XEBCgTp06acWKFXr11VfTlxQO4/jx4+rdu7dy5cqV4g8mAADAvli8ZO/n56f27durVq1aql27tubNm6cLFy6oR48ekh4st1++fFlLliyR9KCMdujQQV9++aVeeOGFxNlVLy8v5cqVKwOfCuzFjh07tGLFCk5gAgDAQVhcSH18fHTjxg2NGTNGwcHBqlatmjZu3KhSpUpJkoKDg5Mc3zl37lzFxsaqV69e6tWrV+L2jh07avHixU/+DGA3/vzzTy1ZskQTJ040OwoAAMhC6TqpqWfPnurZs2eK33u4ZP7888/peQg4mL///lv9+vVTQECA2VEAAEAWS1chBTLS2bNnVaRIEa1cuVL58+c3Ow4AAMhi6fpd9kBGOXLkiN577z3Fx8dTRgEAcFAUUpjGMAzNmDFDgYGByp07t9lxAACASViyhykOHz6sU6dOaf78+WZHAQAAJmOGFFnu4MGDGjhwoBo2bGh2FAAAYAWYIUWWioyMVExMjAIDA5UnTx6z4wAAACvADCmyzIEDB9SmTRs999xzlFEAAJCIGVJkiRs3bmjYsGEKCAiQk5OT2XEAAIAVoZAi0+3bt0/58+fX+vXr5erKWw4AACTFkj0y1W+//abhw4crb968lFEAAJAiGgIy1YEDB/TNN98oZ86cZkcBAABWikKKTLF371798MMPGjt2rNlRAACAlaOQIsMdPHhQn376qQIDA82OAgAAbADHkCJD/f333ypXrpwCAwOVI0cOs+MAAAAbQCFFhtm9e7f8/Pzk5uZGGQUAAGlGIUWGiIuL09KlSxUYGChvb2+z4wAAABvCMaR4Yjt27NCdO3c0d+5cs6MAAAAbxAwpnsjPP/+syZMnq2HDhmZHAQAANopCinS7d++evLy8tHLlSmXLls3sOAAAwEZRSJEu27Zt03vvvafnn3+eMgoAAJ4Ix5DCYpcvX9ZXX32lgIAAs6MAAAA7wAwpLLJ9+3YZhqE1a9bIy8vL7DgAAMAOUEiRZlu2bNH06dOVP39+ubi4mB0HAADYCQop0sQwDJ05c0YBAQHy9PQ0Ow4AALAjHEOKx9q0aZP279+vYcOGmR0FAADYIQopHmnnzp1asGCBli9fbnYUAABgp1iyR6qOHj2q6tWra/ny5fLw8DA7DgAAsFMUUqRow4YN+vTTT+Xt7U0ZBQAAmYpCimSioqK0efNmLV++XO7u7mbHAQAAdo5jSJHEd999Jy8vL3311VdmRwEAAA6CGVIkWrdunQICAvTSSy+ZHQUAADgQZkghSbpz546KFSumpUuXys3Nzew4AADAgVBIoTVr1mjTpk2aP3++2VEAAIADopA6uFOnTmnt2rVavHix2VEAAICD4hhSB/b9998rZ86cLNMDAABTUUgdVGBgoFatWqV8+fLJ2Zm3AQAAMA9NxAEZhqE7d+5o0aJFcnXlqA0AAGAu2oiDWbFiha5evar+/fubHQUAAEAShdShbNiwQUFBQVqwYIHZUQAAABJRSB3Evn37VK9ePTVr1kwuLi5mxwEAAEjEMaQOYMmSJZo9e7ayZ89OGQUAAFaHQmrn7t27pz/++EPz58+njAIAAKvEkr0dW7x4scqXL69JkyaZHQUAACBVzJDaqUWLFmnPnj2qU6eO2VEAAAAeiRlSO3Tjxg0988wz6tixIxe9BwAAVo9Camfmz5+vv//+W5MnTzY7CgAAQJpQSO3IoUOHdOjQIc2YMcPsKAAAAGnGeq6dWL58uUqVKqWZM2eyTA8AAGwKzcUOzJo1S7/++qvy5MkjJycns+MAAABYhEJq4+Li4uTl5aXp06dTRgEAgE3iGFIbNmPGDHl4eOi9994zOwoAAEC6MUNqo5YvX64zZ86oW7duZkcBAAB4IsyQ2qBdu3apZcuWatu2Lcv0AADA5lFIbcwXX3yhy5cv68UXX6SMAgAAu8CSvQ25ceOGwsLCNGnSJMooAACwGxRSGzFlyhRdvHhRI0aMoIwCAAC7wpK9DZg8eXLi76cHAACwNxRSK3f16lU1bdpUVatWZWYUAADYJQqpFfvss89kGIaGDh1qdhQAAIBMwzGkVmrnzp2KiIjQkCFDzI4CAACQqZghtUJz5sxRu3btVK9ePZbpAQCA3aOQWpkxY8bIMAxlz57d7CgAAABZgkJqRaKjo1WxYkX5+PiYHQUAACDLUEitgGEYGjVqlKpUqUIZBQAADoeTmqzAzJkz5e7uThkFAAAOiRlSExmGoW3btqlLly7y9vY2Ow4AAIApmCE1iWEYGjZsmPbv308ZBQAADo0ZUpNcuXJFBQsWVN++fc2OAgAAYCpmSLNYwm9eCg8Pp4wCAACIQprlBg8erLx586pChQpmRwEAALAKLNlnEcMwdOXKFXXu3FkVK1Y0Ow4AAIDVYIY0CxiGoQEDBuj777+njAIAADyEQpoFNm7cqJIlS+qDDz4wOwoAAIDVoZBmIsMwNHnyZL3yyiucwAQAAJAKCmkmMQxD/fr1k5eXlzw8PMyOAwAAYLU4qSkTGIahiIgINWzYUC1btjQ7DgAAgFVjhjSDGYah3r17a+fOnZRRAACANKCQZrDPPvtM1atXV9OmTc2OAgAAYBNYss8g8fHx2rRpkz766CN5enqaHQcAAMBmMEOaAeLj49WzZ08FBwdTRgEAACzEDGkGOHv2rGrXrq2OHTuaHQUAAMDmMEP6BOLj49WrVy95enpSRgEAANKJQvoEPvjgAz333HMqVqyY2VEAAABsFkv26RAXF6dLly5p0KBBKlOmjNlxAAAAbBozpBaKi4tTt27dtHfvXsooAABABqCQWmj16tVq2LCh2rRpY3YUAAAAu8CSfRrFxsZq/PjxGjJkiFxcXMyOAwAAYDeYIU2D2NhYdenSRRUqVKCMAgAAZDBmSB8jNjZWkZGR6tixoxo2bGh2HAAAALvDDOkjxMbGqnPnzjpy5AhlFAAAIJNQSB9h2LBhatWqlerWrWt2FAAAALvFkn0KYmJi9OOPP+rTTz+Vm5ub2XEAAADsGjOkD4mJiVGHDh0UFxdHGQUAAMgCzJA+5OTJk/Lx8VHr1q3NjgIAAOAQmCH9P9HR0erYsaMKFy5MGQUAAMhCFFJJhmGoQ4cOeuutt5QvXz6z4wAAADgUh1+yj4qKUnBwsKZMmaJixYqZHQcAAMDhOPQMaVRUlN59912dOHGCMgoAAGAShy6kK1asUJcuXdSsWTOzowAAADgsh1yyj4yM1GeffabRo0fLycnJ7DgAAAAOzeFmSCMjI9W2bVvVrVuXMgoAAGAFHGqGNDIyUtHR0RowYIDq1KljdhwAAADIgWZIIyIi5Ovrq7Nnz1JGAQAArIjDFNKBAweqV69eeuaZZ8yOAgAAgH+x+yX78PBwbd68WV988YVcXe3+6QIAANgcu54hDQ8PV5s2bZQ7d27KKAAAgJWy25ZmGIZOnDghPz8/vfTSS2bHAQAAQCrscob0/v378vHxUcWKFSmjAAAAVs7uCmlcXJx8fX314YcfKnv27GbHAQAAwGPY1ZL9vXv3dP36dc2fP1+FChUyOw4AAADSIF0zpLNmzVKZMmXk6empmjVrateuXY/cf8eOHapZs6Y8PT1VtmxZzZkzJ11hHyUsLEzvvPOOgoODKaMAAAA2xOJCGhgYqH79+mno0KE6dOiQ6tWrp2bNmunChQsp7n/27Fk1b95c9erV06FDhzRkyBD16dNHa9aseeLw/7Z8+XINHTqUi94DAADYGIsL6dSpU9W1a1d169ZNlStX1rRp01SiRAnNnj07xf3nzJmjkiVLatq0aapcubK6deumLl26aPLkyU8cXnpwNv2IESPUo0cP1a1bN0PuEwAAAFnHomNIo6OjdeDAAQ0aNCjJ9saNG2vPnj0p3mbv3r1q3Lhxkm1NmjTRwoULFRMTIzc3t2S3iYqKUlRUVOLXd+/elSTFxMQoJiYm8e/Sg5OYmjRpkvg17MvD4w37xDg7BsbZ/jHGjiG1cX6ScbeokIaGhiouLi7ZMZqFChVSSEhIircJCQlJcf/Y2FiFhoaqSJEiyW4zfvx4jR49Otn2LVu2yNvbW5J0/fp1SZKLi4vu3LmjjRs3WvJUYGOCgoLMjoAswDg7BsbZ/jHGjuHhcQ4PD0/3faXrLHsnJ6ckXxuGkWzb4/ZPaXuCwYMHy8/PL/Hru3fvqkSJEmrcuLFy5swpSYqIiFD+/Pl1+PBhNWrUKMWZVti+mJgYBQUFMcZ2jnF2DIyz/WOMHUNq45ywop0eFhXS/Pnzy8XFJdls6LVr11I9s71w4cIp7u/q6qp8+fKleBsPDw95eHgk2+7m5pb4xN3c3PTqq6/KyckpyXbYJ8bYMTDOjoFxtn+MsWN4eJyfZMwtOqnJ3d1dNWvWTDZFGxQUlOrZ7bVr1062/5YtW1SrVi3erAAAALD8LHs/Pz8tWLBA/v7+OnHihPr3768LFy6oR48ekh4st3fo0CFx/x49euj8+fPy8/PTiRMn5O/vr4ULF2rAgAEZ9ywAAABgsyw+htTHx0c3btzQmDFjFBwcrGrVqmnjxo0qVaqUJCk4ODjJNUnLlCmjjRs3qn///po5c6aKFi2q6dOn680330zzYyYcc/rwsQkxMTEKDw/X3bt3mW21U4yxY2CcHQPjbP8YY8eQ2jgn9LSE3mYJJyM9t8pily5dUokSJcyOAQAAgMe4ePGiihcvbtFtbKKQxsfH68qVK8qRI0eSM/MTzr6/ePFi4tn3sC+MsWNgnB0D42z/GGPHkNo4G4ahsLAwFS1aVM7Olh0Vmq7LPmU1Z2fnRzbtnDlz8sa3c4yxY2CcHQPjbP8YY8eQ0jjnypUrXfdl8UlNAAAAQEaikAIAAMBUNl1IPTw8NHLkyBQvog/7wBg7BsbZMTDO9o8xdgyZMc42cVITAAAA7JdNz5ACAADA9lFIAQAAYCoKKQAAAExFIQUAAICprL6Qzpo1S2XKlJGnp6dq1qypXbt2PXL/HTt2qGbNmvL09FTZsmU1Z86cLEqK9LJkjNeuXatGjRqpQIECypkzp2rXrq3NmzdnYVqkl6Wf5QS//PKLXF1dVaNGjcwNiCdm6RhHRUVp6NChKlWqlDw8PFSuXDn5+/tnUVqkl6XjvHz5cj3zzDPy9vZWkSJF1LlzZ924cSOL0sJSO3fuVIsWLVS0aFE5OTlp3bp1j71NhnQvw4qtXLnScHNzM+bPn28cP37c6Nu3r5EtWzbj/PnzKe7/zz//GN7e3kbfvn2N48ePG/Pnzzfc3NyM1atXZ3FypJWlY9y3b19jwoQJxu+//26cPHnSGDx4sOHm5mYcPHgwi5PDEpaOc4Lbt28bZcuWNRo3bmw888wzWRMW6ZKeMW7ZsqXx/PPPG0FBQcbZs2eN3377zfjll1+yMDUsZek479q1y3B2dja+/PJL459//jF27dplVK1a1WjdunUWJ0dabdy40Rg6dKixZs0aQ5Lx7bffPnL/jOpeVl1In3vuOaNHjx5JtlWqVMkYNGhQivsPHDjQqFSpUpJt3bt3N1544YVMy4gnY+kYp6RKlSrG6NGjMzoaMlB6x9nHx8cYNmyYMXLkSAqplbN0jH/88UcjV65cxo0bN7IiHjKIpeM8adIko2zZskm2TZ8+3ShevHimZUTGSUshzajuZbVL9tHR0Tpw4IAaN26cZHvjxo21Z8+eFG+zd+/eZPs3adJE+/fvV0xMTKZlRfqkZ4wfFh8fr7CwMOXNmzczIiIDpHecFy1apDNnzmjkyJGZHRFPKD1j/P3336tWrVqaOHGiihUrpqeeekoDBgxQREREVkRGOqRnnOvUqaNLly5p48aNMgxDV69e1erVq/Xqq69mRWRkgYzqXq4ZHSyjhIaGKi4uToUKFUqyvVChQgoJCUnxNiEhISnuHxsbq9DQUBUpUiTT8sJy6Rnjh02ZMkX379/XO++8kxkRkQHSM86nTp3SoEGDtGvXLrm6Wu0/U/g/6Rnjf/75R7t375anp6e+/fZbhYaGqmfPnrp58ybHkVqp9IxznTp1tHz5cvn4+CgyMlKxsbFq2bKlvvrqq6yIjCyQUd3LamdIEzg5OSX52jCMZNset39K22E9LB3jBAEBARo1apQCAwNVsGDBzIqHDJLWcY6Li1Pbtm01evRoPfXUU1kVDxnAks9yfHy8nJyctHz5cj333HNq3ry5pk6dqsWLFzNLauUsGefjx4+rT58+GjFihA4cOKBNmzbp7Nmz6tGjR1ZERRbJiO5ltVMP+fPnl4uLS7Kfuq5du5asiScoXLhwivu7uroqX758mZYV6ZOeMU4QGBiorl27atWqVXrllVcyMyaekKXjHBYWpv379+vQoUP68MMPJT0oL4ZhyNXVVVu2bNHLL7+cJdmRNun5LBcpUkTFihVTrly5ErdVrlxZhmHo0qVLqlChQqZmhuXSM87jx49X3bp19fHHH0uSqlevrmzZsqlevXoaO3YsK5d2IKO6l9XOkLq7u6tmzZoKCgpKsj0oKEh16tRJ8Ta1a9dOtv+WLVtUq1Ytubm5ZVpWpE96xlh6MDPaqVMnrVixguOQbICl45wzZ0798ccfOnz4cOKfHj16qGLFijp8+LCef/75rIqONErPZ7lu3bq6cuWK7t27l7jt5MmTcnZ2VvHixTM1L9InPeMcHh4uZ+ekVcPFxUXS/59Fg23LsO5l0SlQWSzh8hILFy40jh8/bvTr18/Ili2bce7cOcMwDGPQoEFG+/btE/dPuPRA//79jePHjxsLFy7ksk9WztIxXrFiheHq6mrMnDnTCA4OTvxz+/Zts54C0sDScX4YZ9lbP0vHOCwszChevLjx1ltvGceOHTN27NhhVKhQwejWrZtZTwFpYOk4L1q0yHB1dTVmzZplnDlzxti9e7dRq1Yt47nnnjPrKeAxwsLCjEOHDhmHDh0yJBlTp041Dh06lHhpr8zqXlZdSA3DMGbOnGmUKlXKcHd3N/7zn/8YO3bsSPxex44djfr16yfZ/+effzaeffZZw93d3ShdurQxe/bsLE4MS1kyxvXr1zckJfvTsWPHrA8Oi1j6Wf43CqltsHSMT5w4YbzyyiuGl5eXUbx4ccPPz88IDw/P4tSwlKXjPH36dKNKlSqGl5eXUaRIEePdd981Ll26lMWpkVbbt29/5P+zmdW9nAyDOXMAAACYx2qPIQUAAIBjoJACAADAVBRSAAAAmIpCCgAAAFNRSAEAAGAqCikAAABMRSEFAACAqSikAAAAMBWFFAAAAKaikAIAAMBUFFIAAACYikIKAAAAU/0/0MYuX4/xCFoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Muhammad Umer Khan\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121 (484.00 Byte)\n",
      "Trainable params: 121 (484.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:From C:\\Users\\Muhammad Umer Khan\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Muhammad Umer Khan\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Muhammad Umer Khan\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Muhammad Umer Khan\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 6s 97ms/step - loss: 0.7333 - accuracy: 0.3733 - val_loss: 0.7244 - val_accuracy: 0.4271\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.7101 - accuracy: 0.4653 - val_loss: 0.7059 - val_accuracy: 0.5156\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6934 - accuracy: 0.5764 - val_loss: 0.6925 - val_accuracy: 0.5833\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6810 - accuracy: 0.6215 - val_loss: 0.6825 - val_accuracy: 0.6458\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6715 - accuracy: 0.6424 - val_loss: 0.6749 - val_accuracy: 0.6615\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6644 - accuracy: 0.6372 - val_loss: 0.6690 - val_accuracy: 0.6719\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6586 - accuracy: 0.6545 - val_loss: 0.6642 - val_accuracy: 0.6667\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6538 - accuracy: 0.6545 - val_loss: 0.6602 - val_accuracy: 0.6562\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6498 - accuracy: 0.6562 - val_loss: 0.6567 - val_accuracy: 0.6562\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6463 - accuracy: 0.6528 - val_loss: 0.6536 - val_accuracy: 0.6667\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6432 - accuracy: 0.6528 - val_loss: 0.6508 - val_accuracy: 0.6615\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.6404 - accuracy: 0.6528 - val_loss: 0.6483 - val_accuracy: 0.6615\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.6377 - accuracy: 0.6562 - val_loss: 0.6458 - val_accuracy: 0.6615\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 1s 78ms/step - loss: 0.6352 - accuracy: 0.6545 - val_loss: 0.6435 - val_accuracy: 0.6615\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.6328 - accuracy: 0.6562 - val_loss: 0.6413 - val_accuracy: 0.6562\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.6307 - accuracy: 0.6562 - val_loss: 0.6392 - val_accuracy: 0.6562\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6284 - accuracy: 0.6562 - val_loss: 0.6371 - val_accuracy: 0.6562\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.6263 - accuracy: 0.6562 - val_loss: 0.6351 - val_accuracy: 0.6562\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.6244 - accuracy: 0.6562 - val_loss: 0.6331 - val_accuracy: 0.6562\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.6223 - accuracy: 0.6562 - val_loss: 0.6311 - val_accuracy: 0.6562\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.6203 - accuracy: 0.6562 - val_loss: 0.6292 - val_accuracy: 0.6562\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6184 - accuracy: 0.6562 - val_loss: 0.6273 - val_accuracy: 0.6562\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.6165 - accuracy: 0.6580 - val_loss: 0.6254 - val_accuracy: 0.6562\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6146 - accuracy: 0.6562 - val_loss: 0.6236 - val_accuracy: 0.6562\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.6126 - accuracy: 0.6562 - val_loss: 0.6217 - val_accuracy: 0.6562\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.6108 - accuracy: 0.6580 - val_loss: 0.6199 - val_accuracy: 0.6562\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.6091 - accuracy: 0.6580 - val_loss: 0.6182 - val_accuracy: 0.6562\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.6072 - accuracy: 0.6615 - val_loss: 0.6164 - val_accuracy: 0.6562\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6054 - accuracy: 0.6615 - val_loss: 0.6147 - val_accuracy: 0.6510\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6037 - accuracy: 0.6632 - val_loss: 0.6130 - val_accuracy: 0.6510\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.6020 - accuracy: 0.6649 - val_loss: 0.6113 - val_accuracy: 0.6510\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6003 - accuracy: 0.6649 - val_loss: 0.6096 - val_accuracy: 0.6510\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5987 - accuracy: 0.6632 - val_loss: 0.6080 - val_accuracy: 0.6510\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5970 - accuracy: 0.6632 - val_loss: 0.6063 - val_accuracy: 0.6510\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.5954 - accuracy: 0.6667 - val_loss: 0.6047 - val_accuracy: 0.6510\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5937 - accuracy: 0.6649 - val_loss: 0.6031 - val_accuracy: 0.6510\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5921 - accuracy: 0.6632 - val_loss: 0.6015 - val_accuracy: 0.6562\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5905 - accuracy: 0.6615 - val_loss: 0.6000 - val_accuracy: 0.6615\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.5889 - accuracy: 0.6615 - val_loss: 0.5984 - val_accuracy: 0.6615\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.5874 - accuracy: 0.6615 - val_loss: 0.5969 - val_accuracy: 0.6667\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5859 - accuracy: 0.6615 - val_loss: 0.5954 - val_accuracy: 0.6667\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5843 - accuracy: 0.6649 - val_loss: 0.5939 - val_accuracy: 0.6667\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5828 - accuracy: 0.6667 - val_loss: 0.5924 - val_accuracy: 0.6667\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5814 - accuracy: 0.6667 - val_loss: 0.5910 - val_accuracy: 0.6615\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5799 - accuracy: 0.6667 - val_loss: 0.5895 - val_accuracy: 0.6719\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5784 - accuracy: 0.6649 - val_loss: 0.5881 - val_accuracy: 0.6771\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5770 - accuracy: 0.6649 - val_loss: 0.5867 - val_accuracy: 0.6823\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5755 - accuracy: 0.6632 - val_loss: 0.5853 - val_accuracy: 0.6823\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5741 - accuracy: 0.6649 - val_loss: 0.5839 - val_accuracy: 0.6823\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.5727 - accuracy: 0.6649 - val_loss: 0.5826 - val_accuracy: 0.6875\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5712 - accuracy: 0.6667 - val_loss: 0.5812 - val_accuracy: 0.6875\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5699 - accuracy: 0.6684 - val_loss: 0.5799 - val_accuracy: 0.6927\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5686 - accuracy: 0.6684 - val_loss: 0.5786 - val_accuracy: 0.6979\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5672 - accuracy: 0.6719 - val_loss: 0.5772 - val_accuracy: 0.6979\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5658 - accuracy: 0.6753 - val_loss: 0.5760 - val_accuracy: 0.7083\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5645 - accuracy: 0.6771 - val_loss: 0.5747 - val_accuracy: 0.7083\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5632 - accuracy: 0.6788 - val_loss: 0.5734 - val_accuracy: 0.7083\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5619 - accuracy: 0.6788 - val_loss: 0.5722 - val_accuracy: 0.7083\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5606 - accuracy: 0.6840 - val_loss: 0.5709 - val_accuracy: 0.7031\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.5593 - accuracy: 0.6823 - val_loss: 0.5697 - val_accuracy: 0.7083\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.5581 - accuracy: 0.6823 - val_loss: 0.5685 - val_accuracy: 0.7083\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.5568 - accuracy: 0.6806 - val_loss: 0.5673 - val_accuracy: 0.7135\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5556 - accuracy: 0.6840 - val_loss: 0.5661 - val_accuracy: 0.7188\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5544 - accuracy: 0.6823 - val_loss: 0.5649 - val_accuracy: 0.7188\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5532 - accuracy: 0.6840 - val_loss: 0.5638 - val_accuracy: 0.7188\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5520 - accuracy: 0.6910 - val_loss: 0.5627 - val_accuracy: 0.7188\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.5507 - accuracy: 0.6962 - val_loss: 0.5615 - val_accuracy: 0.7188\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.5496 - accuracy: 0.6979 - val_loss: 0.5604 - val_accuracy: 0.7240\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.5484 - accuracy: 0.6997 - val_loss: 0.5593 - val_accuracy: 0.7292\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5473 - accuracy: 0.7049 - val_loss: 0.5582 - val_accuracy: 0.7344\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5461 - accuracy: 0.7049 - val_loss: 0.5572 - val_accuracy: 0.7344\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5450 - accuracy: 0.7083 - val_loss: 0.5561 - val_accuracy: 0.7344\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5439 - accuracy: 0.7118 - val_loss: 0.5550 - val_accuracy: 0.7396\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5429 - accuracy: 0.7153 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5418 - accuracy: 0.7170 - val_loss: 0.5530 - val_accuracy: 0.7448\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5407 - accuracy: 0.7205 - val_loss: 0.5520 - val_accuracy: 0.7448\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5396 - accuracy: 0.7205 - val_loss: 0.5510 - val_accuracy: 0.7448\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5386 - accuracy: 0.7240 - val_loss: 0.5500 - val_accuracy: 0.7396\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5375 - accuracy: 0.7205 - val_loss: 0.5490 - val_accuracy: 0.7448\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5365 - accuracy: 0.7222 - val_loss: 0.5481 - val_accuracy: 0.7448\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5354 - accuracy: 0.7274 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5344 - accuracy: 0.7257 - val_loss: 0.5462 - val_accuracy: 0.7604\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5335 - accuracy: 0.7274 - val_loss: 0.5453 - val_accuracy: 0.7604\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5326 - accuracy: 0.7309 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5316 - accuracy: 0.7309 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5306 - accuracy: 0.7413 - val_loss: 0.5426 - val_accuracy: 0.7656\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5296 - accuracy: 0.7396 - val_loss: 0.5417 - val_accuracy: 0.7708\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5287 - accuracy: 0.7413 - val_loss: 0.5408 - val_accuracy: 0.7708\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.5277 - accuracy: 0.7396 - val_loss: 0.5400 - val_accuracy: 0.7708\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.5268 - accuracy: 0.7413 - val_loss: 0.5392 - val_accuracy: 0.7708\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5259 - accuracy: 0.7448 - val_loss: 0.5383 - val_accuracy: 0.7760\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5251 - accuracy: 0.7413 - val_loss: 0.5375 - val_accuracy: 0.7760\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5241 - accuracy: 0.7465 - val_loss: 0.5367 - val_accuracy: 0.7708\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5233 - accuracy: 0.7431 - val_loss: 0.5359 - val_accuracy: 0.7760\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5224 - accuracy: 0.7465 - val_loss: 0.5351 - val_accuracy: 0.7760\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.5216 - accuracy: 0.7465 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.5207 - accuracy: 0.7448 - val_loss: 0.5336 - val_accuracy: 0.7760\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.5199 - accuracy: 0.7483 - val_loss: 0.5328 - val_accuracy: 0.7760\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5190 - accuracy: 0.7517 - val_loss: 0.5321 - val_accuracy: 0.7760\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5183 - accuracy: 0.7517 - val_loss: 0.5314 - val_accuracy: 0.7760\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5175 - accuracy: 0.7517 - val_loss: 0.5307 - val_accuracy: 0.7760\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5167 - accuracy: 0.7517 - val_loss: 0.5300 - val_accuracy: 0.7760\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5159 - accuracy: 0.7535 - val_loss: 0.5293 - val_accuracy: 0.7760\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5151 - accuracy: 0.7517 - val_loss: 0.5286 - val_accuracy: 0.7708\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5143 - accuracy: 0.7535 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5136 - accuracy: 0.7552 - val_loss: 0.5272 - val_accuracy: 0.7656\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5129 - accuracy: 0.7552 - val_loss: 0.5266 - val_accuracy: 0.7656\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5122 - accuracy: 0.7552 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5115 - accuracy: 0.7604 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5107 - accuracy: 0.7587 - val_loss: 0.5247 - val_accuracy: 0.7656\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5100 - accuracy: 0.7604 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5094 - accuracy: 0.7604 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5086 - accuracy: 0.7604 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5079 - accuracy: 0.7569 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5073 - accuracy: 0.7569 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5066 - accuracy: 0.7569 - val_loss: 0.5211 - val_accuracy: 0.7708\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5060 - accuracy: 0.7569 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5054 - accuracy: 0.7552 - val_loss: 0.5200 - val_accuracy: 0.7708\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5047 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5041 - accuracy: 0.7569 - val_loss: 0.5189 - val_accuracy: 0.7708\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.5034 - accuracy: 0.7569 - val_loss: 0.5184 - val_accuracy: 0.7708\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.5028 - accuracy: 0.7569 - val_loss: 0.5179 - val_accuracy: 0.7708\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5022 - accuracy: 0.7569 - val_loss: 0.5174 - val_accuracy: 0.7708\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5017 - accuracy: 0.7569 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5011 - accuracy: 0.7587 - val_loss: 0.5164 - val_accuracy: 0.7708\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5006 - accuracy: 0.7587 - val_loss: 0.5159 - val_accuracy: 0.7708\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4999 - accuracy: 0.7604 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4994 - accuracy: 0.7604 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4989 - accuracy: 0.7622 - val_loss: 0.5145 - val_accuracy: 0.7760\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4982 - accuracy: 0.7604 - val_loss: 0.5140 - val_accuracy: 0.7760\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4977 - accuracy: 0.7639 - val_loss: 0.5136 - val_accuracy: 0.7760\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4973 - accuracy: 0.7622 - val_loss: 0.5131 - val_accuracy: 0.7760\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4966 - accuracy: 0.7656 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4962 - accuracy: 0.7656 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4956 - accuracy: 0.7656 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4952 - accuracy: 0.7656 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4947 - accuracy: 0.7656 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4941 - accuracy: 0.7656 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4936 - accuracy: 0.7656 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4932 - accuracy: 0.7656 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4927 - accuracy: 0.7656 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4923 - accuracy: 0.7639 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4917 - accuracy: 0.7639 - val_loss: 0.5087 - val_accuracy: 0.7760\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4914 - accuracy: 0.7639 - val_loss: 0.5084 - val_accuracy: 0.7760\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4909 - accuracy: 0.7622 - val_loss: 0.5080 - val_accuracy: 0.7760\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4904 - accuracy: 0.7639 - val_loss: 0.5077 - val_accuracy: 0.7760\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.4900 - accuracy: 0.7622 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4896 - accuracy: 0.7622 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4892 - accuracy: 0.7622 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4888 - accuracy: 0.7622 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4883 - accuracy: 0.7622 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4880 - accuracy: 0.7639 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4876 - accuracy: 0.7604 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4872 - accuracy: 0.7622 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4868 - accuracy: 0.7622 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4864 - accuracy: 0.7622 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4860 - accuracy: 0.7622 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4858 - accuracy: 0.7639 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4852 - accuracy: 0.7656 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4849 - accuracy: 0.7639 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4845 - accuracy: 0.7656 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4842 - accuracy: 0.7639 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4838 - accuracy: 0.7656 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4835 - accuracy: 0.7656 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4832 - accuracy: 0.7639 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4829 - accuracy: 0.7639 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4825 - accuracy: 0.7639 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4822 - accuracy: 0.7639 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4818 - accuracy: 0.7639 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4815 - accuracy: 0.7639 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.4813 - accuracy: 0.7656 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4809 - accuracy: 0.7674 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4806 - accuracy: 0.7674 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4803 - accuracy: 0.7656 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4801 - accuracy: 0.7656 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4797 - accuracy: 0.7656 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4794 - accuracy: 0.7674 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.4791 - accuracy: 0.7656 - val_loss: 0.4991 - val_accuracy: 0.7604\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4789 - accuracy: 0.7674 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4786 - accuracy: 0.7674 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4784 - accuracy: 0.7691 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4780 - accuracy: 0.7691 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4777 - accuracy: 0.7691 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4775 - accuracy: 0.7691 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4773 - accuracy: 0.7691 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4770 - accuracy: 0.7691 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4767 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4765 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4763 - accuracy: 0.7708 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4760 - accuracy: 0.7708 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4758 - accuracy: 0.7708 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4755 - accuracy: 0.7708 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4752 - accuracy: 0.7708 - val_loss: 0.4964 - val_accuracy: 0.7604\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4751 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.4749 - accuracy: 0.7708 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.4747 - accuracy: 0.7708 - val_loss: 0.4960 - val_accuracy: 0.7552\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4744 - accuracy: 0.7708 - val_loss: 0.4958 - val_accuracy: 0.7552\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4741 - accuracy: 0.7691 - val_loss: 0.4957 - val_accuracy: 0.7552\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4740 - accuracy: 0.7691 - val_loss: 0.4955 - val_accuracy: 0.7552\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4738 - accuracy: 0.7691 - val_loss: 0.4954 - val_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Like we did for the Random Forest, we generate two kinds of predictions\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#  One is a hard decision, the other is a probabilitistic score.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m y_pred_class_nn_1 \u001b[38;5;241m=\u001b[39m model_1\u001b[38;5;241m.\u001b[39mpredict_classes(X_test_norm)\n\u001b[0;32m      5\u001b[0m y_pred_prob_nn_1 \u001b[38;5;241m=\u001b[39m model_1\u001b[38;5;241m.\u001b[39mpredict(X_test_norm)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "# \n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "# y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4333624 ],\n",
       "       [0.6848541 ],\n",
       "       [0.31633824],\n",
       "       [0.28831708],\n",
       "       [0.1997018 ],\n",
       "       [0.49742565],\n",
       "       [0.08884338],\n",
       "       [0.29599124],\n",
       "       [0.8000802 ],\n",
       "       [0.21105202]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27d75b61a90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFzUlEQVR4nO3deXiU1d3/8c9kJIQtYRMSSAjIvokQdiogUhCrQqkSrGWpUbSCFdGKPIhb9cG6IK0KhRrEVouoiPVXcYmyKqBUgSpQDBIIgcQ8UE1AJIHk/P4YZswkk9kyk1nyfl3XXJJ77rnnDHfofHrO95xjMcYYAQAAhLGYUDcAAADAEwILAAAIewQWAAAQ9ggsAAAg7BFYAABA2COwAACAsEdgAQAAYY/AAgAAwt4FoW5AoJSXl+vYsWNq0qSJLBZLqJsDAAC8YIzRyZMn1aZNG8XEVN+PEjWB5dixY0pJSQl1MwAAgB+OHDmi5OTkap+PmsDSpEkTSbYPHB8fH+LWAAAAbxQXFyslJcXxPV6dqAks9mGg+Ph4AgsAABHGUzkHRbcAACDsEVgAAEDYI7AAAICwFzU1LAAA/xljdO7cOZWVlYW6KYgyVqtVF1xwQY2XHCGwAEAdV1paqvz8fJ0+fTrUTUGUatiwoZKSkhQbG+v3NQgsAFCHlZeXKycnR1arVW3atFFsbCyLbyJgjDEqLS3V//3f/yknJ0edO3d2uzicOwQWAKjDSktLVV5erpSUFDVs2DDUzUEUatCggerVq6fDhw+rtLRUcXFxfl2HolsAgN//rxfwRiB+v/gNBQAAYY/AAgAAwh6BxZO8PGnDBtt/AQBRbeTIkZo9e3aomwEXCCzuZGZKqanSqFG2/2ZmhrpFAADZ9p1x95g+fbpf133jjTf0+9//vkZtmz59uiZMmFCja6AqZglVJy9PmjFDKi+3/VxeLt1yizR2rORm+2sAqNPy8qTsbKlz56D+b2V+fr7jz6tXr9b999+v/fv3O441aNDA6fyzZ8+qXr16Hq/bvHnzwDUSAUUPS3Wys38MK3ZlZdKBA6FpDwDUFmOk77/3/bFkiXOv9JIlvl/DGK+amJiY6HgkJCTIYrE4fj5z5oyaNm2qV199VSNHjlRcXJxeeuklnThxQtdff72Sk5PVsGFD9e7dW6tWrXK6buUhofbt2+t///d/deONN6pJkyZq166dli9fXqO/3k2bNmngwIGqX7++kpKSdO+99+rcuXOO519//XX17t1bDRo0UIsWLTR69Gh9//33kqSNGzdq4MCBatSokZo2baphw4bp8OHDNWpPpCCwVKdzZ6nyNCyrVerUKTTtAYDacvq01Lix74+ZM517pWfO9P0aAVxtd+7cufrtb3+rffv2aezYsTpz5ozS0tL0z3/+U19++aVmzJihKVOm6JNPPnF7naeeekr9+/fXzp07ddttt+k3v/mN/vOf//jVpqNHj+rKK6/UgAEDtHv3bi1dulSZmZl65JFHJNl6jq6//nrdeOON2rdvnzZu3KiJEyc6tk6YMGGCRowYoX//+9/atm2bZsyYUWcW+mNIqDrJydLy5dLNN9sSv8UiLVvGcBAARIjZs2dr4sSJTsfuvvtux59vv/12vfvuu3rttdc0aNCgaq9z5ZVX6rbbbpNkC0FPP/20Nm7cqG7duvncpiVLliglJUXPPvusLBaLunXrpmPHjmnu3Lm6//77lZ+fr3PnzmnixIlKTU2VJPXu3VuS9N///ldFRUW66qqr1LFjR0lS9+7dfW5DpCKwuJORIX3yifSXv9jqVzIyQt0iAAi+hg2lU6d8e83Ro1L37s5D6VartHev1Latb+8dIP3793f6uaysTI899phWr16to0ePqqSkRCUlJWrUqJHb61x88cWOP9uHngoLC/1q0759+zRkyBCnXpFhw4bp1KlTysvLU58+fXT55Zerd+/eGjt2rMaMGaNrr71WzZo1U/PmzTV9+nSNHTtWP/3pTzV69GhNmjRJSUlJfrUl0jAk5En79rb/lpaGtBkAUGssFqlRI98eXbrYeqWtVts1rFZbr3SXLr5dJ4DDG5WDyFNPPaWnn35a99xzj9avX69du3Zp7NixKvXwv++Vi3UtFovKK9c4eskYU2UIx5yv27FYLLJarcrKytI777yjHj166JlnnlHXrl2Vk5MjSXrhhRe0bds2DR06VKtXr1aXLl20fft2v9oSaQgsnrRsafvviROhbQcAhLuMDOnQIdvaVYcOhV2v9JYtWzR+/Hj96le/Up8+fXTRRRcpOzu7VtvQo0cPbd261RFSJGnr1q1q0qSJ2p7vibJYLBo2bJgeeugh7dy5U7GxsVq7dq3j/L59+2revHnaunWrevXqpb///e+1+hlChSEhT1q0sP33+PHQtgMAIkFyctjW+nXq1Elr1qzR1q1b1axZMy1atEgFBQVBqQMpKirSrl27nI41b95ct912mxYvXqzbb79ds2bN0v79+/XAAw9ozpw5iomJ0SeffKIPP/xQY8aMUatWrfTJJ5/o//7v/9S9e3fl5ORo+fLluuaaa9SmTRvt379fX331laZOnRrw9ocjAosn9sBCDwsARLQFCxYoJydHY8eOVcOGDTVjxgxNmDBBRUVFAX+vjRs3qm/fvk7Hpk2bppUrV2rdunX63e9+pz59+qh58+bKyMjQfffdJ0mKj4/X5s2btXjxYhUXFys1NVVPPfWUxo0bp2+++Ub/+c9/9OKLL+rEiRNKSkrSrFmzdMsttwS8/eHIYoyXk97DXHFxsRISElRUVKT4+PjAXfiLL6SLL5YuvFDys8gKAMLVmTNnlJOTow4dOiguLi7UzUGUcvd75u33NzUsHuSVttIGjVTe8biqC8kBAIBaQWBxIzNTSh3YSqO0QakmR5nP/hDqJgEAUCcRWKrx41ZCtuln5bLqljsbsmkzAAAhQGCphsuthMotbCUEAEAIEFiq4XIroZhythICACAECCzVsG8lZF+Q0KJyLZu+PVyXFwAAIKoRWNzIyJD+539sf56gN5XRy/2OngAAIDgILB7YN+MsVjyr3QIAECIEFg/sm2DmK4nVbgEgyowcOVKzZ892/Ny+fXstXrzY7WssFovefPPNGr93oK5TVxBYPEhMtP23QIkEFgAIE1dffbVGjx7t8rlt27bJYrHo888/9/m6O3bs0IwZM2raPCcPPvigLrnkkirH8/PzNW7cuIC+V2UrV65U06ZNg/oetYXA4oE9sPxXLVRSGPj9JgAAvsvIyND69et1+PDhKs+tWLFCl1xyifr16+fzdS+88EI1bNgwEE30KDExUfXr16+V94oGBBYPmjeX6l1gW5Cl8Juo2HYJAIImL0/asEFBX2TzqquuUqtWrbRy5Uqn46dPn9bq1auVkZGhEydO6Prrr1dycrIaNmyo3r17a9WqVW6vW3lIKDs7W8OHD1dcXJx69OihrKysKq+ZO3euunTpooYNG+qiiy7SggULdPbsWUm2Ho6HHnpIu3fvlsVikcVicbS58pDQF198oVGjRqlBgwZq0aKFZsyYoVOnTjmenz59uiZMmKAnn3xSSUlJatGihWbOnOl4L3/k5uZq/Pjxaty4seLj4zVp0iR98803jud3796tyy67TE2aNFF8fLzS0tL0r3/9S5J0+PBhXX311WrWrJkaNWqknj17at26dX63xRN2a/bAYpESW5zTkW9iVXCinlJC3SAACDJjpNOnfX/diy9Kt99uW3QzJkZ65hlp2jTfrtGw4Y/LSbhzwQUXaOrUqVq5cqXuv/9+Wc6/6LXXXlNpaaluuOEGnT59WmlpaZo7d67i4+P19ttva8qUKbrooos0aNAgj+9RXl6uiRMnqmXLltq+fbuKi4ud6l3smjRpopUrV6pNmzb64osvdPPNN6tJkya65557lJ6eri+//FLvvvuuPvjgA0lSQkJClWucPn1aV1xxhQYPHqwdO3aosLBQN910k2bNmuUUyjZs2KCkpCRt2LBBBw4cUHp6ui655BLdfPPNnv/SKjHGaMKECWrUqJE2bdqkc+fO6bbbblN6ero2btwoSbrhhhvUt29fLV26VFarVbt27VK9evUkSTNnzlRpaak2b96sRo0aae/evWrcuLHP7fClwVGhqKjISDJFRUUBv/aAPmeMZMw/LphoTHl5wK8PAKHyww8/mL1795offvjBcezUKWNssaX2H6dOed/2ffv2GUlm/fr1jmPDhw83119/fbWvufLKK81dd93l+HnEiBHmjjvucPycmppqnn76aWOMMe+9956xWq3myJEjjuffeecdI8msXbu22vd4/PHHTVpamuPnBx54wPTp06fKeRWvs3z5ctOsWTNzqsJfwNtvv21iYmJMQUGBMcaYadOmmdTUVHPu3DnHOdddd51JT0+vti0vvPCCSUhIcPnc+++/b6xWq8nNzXUc27Nnj5FkPv30U2OMMU2aNDErV650+frevXubBx98sNr3rsjV75mdt9/fDAl5IbGtVZJUcK6F9P33IW4NAECSunXrpqFDh2rFihWSpK+//lpbtmzRjTfeKEkqKyvTo48+qosvvlgtWrRQ48aN9f777ys3N9er6+/bt0/t2rVTcoUVQ4cMGVLlvNdff10/+clPlJiYqMaNG2vBggVev0fF9+rTp48aNWrkODZs2DCVl5dr//79jmM9e/aU1Wp1/JyUlKTCwkKf3qvie6akpCgl5cexgx49eqhp06bat2+fJGnOnDm66aabNHr0aD322GP6+uuvHef+9re/1SOPPKJhw4bpgQce0L///W+/2uEtAosXEtucDyzMFAJQBzRsKJ065dtj/34X25lYbcd9uY6v9a4ZGRlas2aNiouL9cILLyg1NVWXX365JOmpp57S008/rXvuuUfr16/Xrl27NHbsWJWWlnp1bWOq1i1aKo1Xbd++XZMnT9a4ceP0z3/+Uzt37tT8+fO9fo+K71X52q7e0z4cU/G58sob39XwPSsef/DBB7Vnzx797Gc/0/r169WjRw+tXbtWknTTTTfp4MGDmjJlir744gv1799fzzzzjF9t8QaBxQuJSbYbR2ABUBdYLFKjRr49unSxbWdi/z//Vqu0bJntuC/X8aZ+paJJkybJarXq73//u1588UX9+te/dnzZbtmyRePHj9evfvUr9enTRxdddJGys7O9vnaPHj2Um5urY8eOOY5t27bN6ZyPP/5Yqampmj9/vvr376/OnTtXmbkUGxursrIyj++1a9cufV+hF//jjz9WTEyMunTp4nWbfWH/fEeOHHEc27t3r4qKitS9e3fHsS5duujOO+/U+++/r4kTJ+qFF15wPJeSkqJbb71Vb7zxhu666y795S9/CUpbJQKLV5wWj2O1WwBwKSNDOnTINkvo0CHbz8HWuHFjpaen63/+53907NgxTZ8+3fFcp06dlJWVpa1bt2rfvn265ZZbVFBQ4PW1R48era5du2rq1KnavXu3tmzZovnz5zud06lTJ+Xm5uqVV17R119/rT/96U+OHgi79u3bKycnR7t27dLx48dVUlJS5b1uuOEGxcXFadq0afryyy+1YcMG3X777ZoyZYpat27t219KJWVlZdq1a5fTY+/evRo9erQuvvhi3XDDDfr888/16aefaurUqRoxYoT69++vH374QbNmzdLGjRt1+PBhffzxx9qxY4cjzMyePVvvvfeecnJy9Pnnn2v9+vVOQSfQCCxeYPE4APBOcrI0cqRqdaPYjIwMffvttxo9erTatWvnOL5gwQL169dPY8eO1ciRI5WYmKgJEyZ4fd2YmBitXbtWJSUlGjhwoG666SY9+uijTueMHz9ed955p2bNmqVLLrlEW7du1YIFC5zO+cUvfqErrrhCl112mS688EKXU6sbNmyo9957T//97381YMAAXXvttbr88sv17LPP+vaX4cKpU6fUt29fp8eVV17pmFbdrFkzDR8+XKNHj9ZFF12k1atXS5KsVqtOnDihqVOnqkuXLpo0aZLGjRunhx56SJItCM2cOVPdu3fXFVdcoa5du2rJkiU1bm91LMbVIF0EKi4uVkJCgoqKihQfHx/Qa2/bJg0dKrVXjnJuf1q6557a/dcIAEFy5swZ5eTkqEOHDoqLiwt1cxCl3P2eefv9TQ+LFyr2sJhnnpFSU6XMzNA2CgCAOoTA4oXEc7YlG8+ogW3X5vJy6ZZbgr+UIwAAkERg8UqDvGwl6DtJ5wtvJamsTDpwIHSNAgCgDiGweKNzZyXKVlleoPPjQ1ar1KlTCBsFAEDdQWDxRnKyEtvZdtT8UKOUF9POtsAAhbcAANQKAouXTjdvI0l6RPcrVYeUqVpYYAAAakmUTBhFmArE7xeBxQt5edK/dsc6fi4vt1BzCyAq2Jd6P+3P9syAl+y/X5W3FvDFBYFqTDTLzpaMcV4v2l5zy6gQgEhmtVrVtGlTxwZ6DRs2rHZPG8BXxhidPn1ahYWFatq0qdPGjb4isHihc2fb/hYVe7SouQUQLRLPLzbl766/gCdNmzZ1/J75i8DiheRkacEC6eGHbT9bY8q1bFkMvSsAooLFYlFSUpJatWqls2fPhro5iDL16tWrUc+Kg/HDc889Z9q3b2/q169v+vXrZzZv3lztudOmTTOSqjx69OjhdN7rr79uunfvbmJjY0337t3NG2+84VObioqKjCRTVFTkz0fy6LvvjLH1sRjzn1ueCsp7AABQ13j7/e1z0e3q1as1e/ZszZ8/Xzt37tSll16qcePGKTc31+X5f/zjH5Wfn+94HDlyRM2bN9d1113nOGfbtm1KT0/XlClTtHv3bk2ZMkWTJk3SJ5984kcEC46EBKlZgx8kSaUF34a4NQAA1C0+b344aNAg9evXT0uXLnUc6969uyZMmKCFCxd6fP2bb76piRMnKicnR6mpqZKk9PR0FRcX65133nGcd8UVV6hZs2Yud7V0JZibH9r173Bcnx1qqX/0uV/X7Ho4KO8BAEBdEpTND0tLS/XZZ59pzJgxTsfHjBmjrVu3enWNzMxMjR492hFWJFsPS+Vrjh071utr1pYOKWWSpJyCBiFuCQAAdYtPRbfHjx9XWVmZWrdu7XS8devWKigo8Pj6/Px8vfPOO/r73//udLygoMDna5aUlKikpMTxc3FxsTcfoUYu6mKVtkgHv20W9PcCAAA/8mvhuMpz9I0xXs3bX7lypZo2baoJEybU+JoLFy5UQkKC45GSkuJd42ugQ89GkqSc0jbS998H/f0AAICNT4GlZcuWslqtVXo+CgsLq/SQVGaM0YoVKzRlyhTFxsY6PZeYmOjzNefNm6eioiLH48iRI758FL9c1NM2FHRQF0nHjgX9/QAAgI1PgSU2NlZpaWnKyspyOp6VlaWhQ4e6fe2mTZt04MABZWRU3YNnyJAhVa75/vvvu71m/fr1FR8f7/QItg4dbP/NUQeZvKNBfz8AAGDj88Jxc+bM0ZQpU9S/f38NGTJEy5cvV25urm699VZJtp6Po0eP6q9//avT6zIzMzVo0CD16tWryjXvuOMODR8+XH/4wx80fvx4/eMf/9AHH3ygjz76yM+PFRzt2kkWleu0Gqlw3wm1vizULQIAoG7wObCkp6frxIkTevjhh5Wfn69evXpp3bp1jlk/+fn5VdZkKSoq0po1a/THP/7R5TWHDh2qV155Rffdd58WLFigjh07avXq1Ro0aJAfHyl46teXkhv+V0dOt1TOntNyPwgGAAACxed1WMJVbazDIkkj2h3U5iMX6eX+T+uXa69j90MAAGogKOuwQLroAltx74f/aqK8dkOlzMwQtwgAgOhHYPFFXp7+m/OdJGmFblKqyVHmzdulvLzQtgsAgChHYPFB3tZc/T9d7fi5XFbdYpYqb1vwp1QDAFCXEVh8kK3OMpX+ysp0gQ6oU4haBABA3UBg8UHnoRcqxlLudMwaU65OQy4MUYsAAKgbCCw+SE6Wlv8lRpJtYlWMpVzLlscwUQgAgCAjsPgoI0O6PPFLSdJDP/1ILhbuBQAAAUZg8cPATt9JkvJyo2IJGwAAwh6BxQ+9L7btIv3FsRYhbgkAAHUDgcUPvYfZVuL78mQ7Rcc6wQAAhDcCix+6jmqreipVsYlX7v4fQt0cAACiHoHFD/VaN1e3mGxJ0hcfFoa4NQAARD8Ciz8sFvVualvd9t9bT4W4MQAARD8Ci596p3wrSfrgk8ZsJQQAQJARWPyUH9tekrTh61SlprJpMwAAwURg8UNenvTsvwY7fi4vl265hU2bAQAIFgKLH7KzpXJjcTpWViYdOBCiBgEAEOUILH7o3DhfMSpzOmbVOXVqlB+iFgEAEN0ILH5IPvUfLdcMWWTbudmici3TLUr+fn+IWwYAQHQisPijc2dlxKzUq7pOknShCnVjzItSp04hbhgAANGJwOKP5GRp+XL9TO+onkpVqEQdevRl23EAABBwBBZ/ZWSowZO/Vz99Lkn6ODk9xA0CACB6EVhq4rLLNEwfS5I+/ohdEAEACBYCS0306KFhMdslSe+tO8c6LAAABAmBpSbi4nS41QBJUs6Reqx4CwBAkBBYaiAvT7q74G7Hz6x4CwBAcBBYaiA7Wyqv9FfIircAAAQegaUGOneWYmKci22tVpZjAQAg0AgsNZCcLC2/NktWnXMc+/01O1iOBQCAACOw1ERenjJeH6dDaq+++kyS1PDNv1PEAgBAgBFYaiI7WyovV7KO6ld6WZL0thlHEQsAAAFGYKkJWxGLJOlKrZMkbdQIrTvck04WAAACiMBSE+f3FFJMjLpqv1qqUGdVXz+bfiFrsgAAEEAElprKyJC++kpHL2ivE2rpOMyaLAAABA6BJRA6dlR2r5/LsCYLAABBQWAJkM6XJStGZU7HWJMFAIDAILAESPLVfbVcM2RRuSTJYpGWLRNrsgAAEAAElkAZPFgZsS9pg0aeP2DUrBk1LAAABAKBJVAaNJDatdMIbVF7HZQxFv3iF2K2EAAAAUBgCZS8POnrr5Wntjqs9o7DzBYCAKDmCCyBkp0tGaNsdWa2EAAAAUZgCZTzq952VjazhQAACDACS6CcX/U22XJMyzXDKbRkZISwXQAARAECSyBlZEjPPKMMrdDh9iPVrp3t8PLlFN8CAFATBJZAu+EG2xjQoRwdOWIchym+BQDAfwSWQGvaVOrUyVZ8ayxOT1F8CwCAfy4IdQOiTl6e9NVX6qxTilGZymV1PEXxLQAA/qGHJdDOT29O1lEt1wxZdc7x1ODBIWwXAAARjMASaOenN0tShlbokNrrZ/qnJOnjjym+BQDAHwSWQDs/vdkeWiTpHcuVjj9TfAsAgO8ILMGQkSHt3ClZrcpWZ5UbVr4FAKAmCCzBcvHFUu/eLle+laTCQnpZAADwFoElWPLypN27XRTf2tZmSU+nngUAAG8RWILl/Gwh6cfi21d1ndMp1LMAAOAdvwLLkiVL1KFDB8XFxSktLU1btmxxe35JSYnmz5+v1NRU1a9fXx07dtSKFSscz69cuVIWi6XK48yZM/40LzxUmC0kSck6qpYx30qqupjctm213DYAACKMzwvHrV69WrNnz9aSJUs0bNgwLVu2TOPGjdPevXvVzr55TiWTJk3SN998o8zMTHXq1EmFhYU6d+6c0znx8fHav3+/07G4uDhfmxc+7LOFbrnFlkokdb79CsU8Y+tZqWjyZKm4mE0SAQCojsUYYzyf9qNBgwapX79+Wrp0qeNY9+7dNWHCBC1cuLDK+e+++64mT56sgwcPqnnz5i6vuXLlSs2ePVvfffedb62voLi4WAkJCSoqKlJ8fLzf1wm4vDxp+nTpww+l0aOVOXa1ZsxtXiW0WK3SoUO2nAMAQF3h7fe3T0NCpaWl+uyzzzRmzBin42PGjNHWrVtdvuatt95S//799fjjj6tt27bq0qWL7r77bv3www9O5506dUqpqalKTk7WVVddpZ07d7ptS0lJiYqLi50eYSk5WRoyxPbnDz5QxtwLteqmD6ucxlRnAACq51NgOX78uMrKytS6dWun461bt1ZBQYHL1xw8eFAfffSRvvzyS61du1aLFy/W66+/rpkzZzrO6datm1auXKm33npLq1atUlxcnIYNG6bs7Oxq27Jw4UIlJCQ4HikpKb58lNqTlyf97//++HN5uYY+f6NiYpw7tiwWqVGjWm4bAAARwq+iW4vFuXDUGFPlmF15ebksFotefvllDRw4UFdeeaUWLVqklStXOnpZBg8erF/96lfq06ePLr30Ur366qvq0qWLnnnmmWrbMG/ePBUVFTkeR44c8eejBF92dpWileTyXC2fs1/WH/dFlDG2vYaY5gwAQFU+BZaWLVvKarVW6U0pLCys0util5SUpLZt2yohIcFxrHv37jLGKK+a+bwxMTEaMGCA2x6W+vXrKz4+3ukRlirNFrLLGPBvbXvzG1XMeUxzBgDANZ8CS2xsrNLS0pSVleV0PCsrS0OHDnX5mmHDhunYsWM6deqU49hXX32lmJgYJVdTYWqM0a5du5SUlORL88KTfbZQxe4USUpP16lrfqnKJc9McwYAoCqfh4TmzJmj559/XitWrNC+fft05513Kjc3V7feeqsk21DN1KlTHef/8pe/VIsWLfTrX/9ae/fu1ebNm/W73/1ON954oxo0aCBJeuihh/Tee+/p4MGD2rVrlzIyMrRr1y7HNSNeRoZtCtDq1U6HO5v9LpftnzyZoSEAACryeR2W9PR0nThxQg8//LDy8/PVq1cvrVu3TqmpqZKk/Px85ebmOs5v3LixsrKydPvtt6t///5q0aKFJk2apEceecRxznfffacZM2aooKBACQkJ6tu3rzZv3qyBAwcG4COGieRk6cILnQ+dX7Z/huV5lZsfx4bsQ0NjxzLNGQAAyY91WMJV2K7DUlFenm0DoYpFuDExevX3+5U+v1OV0xctkq67jtACAIheQVmHBTVkr2epWIRbXq6h941SjKW8yulz5rBBIgAAEoGl9mVkSNu3Ox1KNke0XLfIaq3a2cXMIQAACCyhUWHGlF2GeV6HVm3XokVVT2fmEACgriOwhIKrtVliYpTc/gJdd53LZVuYOQQAqNMILKHgam2W8nJp8GAlv5dZpczF/vSMGdKOHbXbVAAAwgGBJVQyMmzjPC6Wus0Ym6dVq6q+5HymoacFAFDnEFhC6dQpVbfU7dChroeGKMIFANRFBJZQqmafIU2eXO3QkGTLNK+9RmgBANQdBJZQcrUui+Q0NLR9u+vQwhotAIC6hMASahkZclmwcr4bZUBSnsu9EyWGhwAAdQeBJRxUV7ByvhslQ5k6dEis0QIAqLMILOHA1TRnu/PdKMnKY40WAECdRWAJFxkZctuNcuCA25IX1mgBAEQzAks4SU6Wy26UmBipUSNJ1Ze8sEYLACCaEVjCjZtVcO1phDVaAAB1DYElHFW3Cu75cZ/qhoYkinABANGJwBKuXK2CW6GnJSND1a7RQhEuACDaEFjCVXWr4FYY9xkwwH0R7quvMjwEAIgOBJZw5Wnc5/za/O6KcNPTWQ0XABAdLMZUHneITMXFxUpISFBRUZHi4+ND3ZzA2bHDNgxUXl71uZgYafly5Y3NUGqq61MkW/3uoUO2DAQAQDjx9vubHpZwZx/38bCoXHWnSBTiAgAiH4ElEnhaVG7bNscpr75KIS4AIPoQWCJFdYvKSY40Yj+F1XABANGGwBJJ3K3NX2HFOFbDBQBEGwJLpKkujVQqVGE1XABANCGwRKLq0kiFQhVWwwUARBMCSyTycttmVsMFAEQLAkuk8rJQhdVwAQDRgMASybwsVGE1XABApCOwRDIvl++Xqs82ElOeAQDhj8AS6dwVqsyZ4+g+sWeb6lbDZcozACCcEViigafl+893n3haDZcpzwCAcEVgiRbulu+v0H3ibjVciSnPAIDwRGCJJu6W73dRiMuUZwBApCCwRBsfVozzNOWZIlwAQLggsEQjH7pP2HcIABAJCCzRyofuE3fLubC4HAAgHBBYopmX3SfuRpFYXA4AEA4ILNHOh9VwqxtFsp9OXQsAIFQILNHOh9Vw3S3nIlHXAgAIHYsxxoS6EYFQXFyshIQEFRUVKT4+PtTNCT87dtjSRnl51ediYmxJJSNDki2/bNtmq8+t7vTt220BBwCAmvD2+5selrrCy9VwJXlcXI6eFgBAbSOw1CVeroZb8fTq6lpYxh8AUJsILHWNp9VwK1XWVjc7WqpSAgMAQNAQWOoiT/OYfehpqbAhNAAAQUNgqat8HO/xoQQGAICAI7DUZZ7Geypt2+xjCQwAAAFDYKnrfNy22ccSGAAAAoLAAs/7DlXaTMjHEhgAAGqMwAIbd/sOudhMyFMJDD0tAIBAIrDgR9XtOyT5POWZnhYAQCARWPAj+1iPD5sJedPTUmlECQAAnxFY4Mw+FejVVwOyuFw1I0oAAPiEwIKq/NhMyF1Pi/0l1LUAAPzlV2BZsmSJOnTooLi4OKWlpWnLli1uzy8pKdH8+fOVmpqq+vXrq2PHjlqxYoXTOWvWrFGPHj1Uv3599ejRQ2vXrvWnaQikAC4uZ38JdS0AAH/4HFhWr16t2bNna/78+dq5c6cuvfRSjRs3Trm5udW+ZtKkSfrwww+VmZmp/fv3a9WqVerWrZvj+W3btik9PV1TpkzR7t27NWXKFE2aNEmffPKJf58KgePjZkJ+jCgBAOCRxRhjfHnBoEGD1K9fPy1dutRxrHv37powYYIWLlxY5fx3331XkydP1sGDB9W8eXOX10xPT1dxcbHeeecdx7ErrrhCzZo10ypXU21dKC4uVkJCgoqKihQfH+/LR4I3duywdY+Ul1d9LibGFmoyMpwOZ2bawokPLwEA1DHefn/71MNSWlqqzz77TGPGjHE6PmbMGG3dutXla9566y31799fjz/+uNq2basuXbro7rvv1g8//OA4Z9u2bVWuOXbs2GqvKdmGmYqLi50eCCI/NhNirRYAQKD4FFiOHz+usrIytW7d2ul469atVVBQ4PI1Bw8e1EcffaQvv/xSa9eu1eLFi/X6669r5syZjnMKCgp8uqYkLVy4UAkJCY5HSkqKLx8F/vBjMyHWagEABIJfRbcWi8XpZ2NMlWN25eXlslgsevnllzVw4EBdeeWVWrRokVauXOnUy+LLNSVp3rx5KioqcjyOHDniz0eBr/zYTIi1WgAANeVTYGnZsqWsVmuVno/CwsIqPSR2SUlJatu2rRISEhzHunfvLmOM8s5/QyUmJvp0TUmqX7++4uPjnR6oJX5sJsRaLQCAmvApsMTGxiotLU1ZWVlOx7OysjR06FCXrxk2bJiOHTumU6dOOY599dVXiomJUXJysiRpyJAhVa75/vvvV3tNhAE/ClRYqwUA4Dfjo1deecXUq1fPZGZmmr1795rZs2ebRo0amUOHDhljjLn33nvNlClTHOefPHnSJCcnm2uvvdbs2bPHbNq0yXTu3NncdNNNjnM+/vhjY7VazWOPPWb27dtnHnvsMXPBBReY7du3e92uoqIiI8kUFRX5+pFQE88/b0xMjDFS1UdMjO15Fy+xWl2/xM3LAABRyNvvb58DizHGPPfccyY1NdXExsaafv36mU2bNjmemzZtmhkxYoTT+fv27TOjR482DRo0MMnJyWbOnDnm9OnTTue89tprpmvXrqZevXqmW7duZs2aNT61icASQp9+6j60rF5tzJEjTi85csSYV191/7JPPw3R5wEA1Bpvv799XoclXLEOS4i5W3RFYq0WAIBL3n5/E1gQOO4Wl5NsCWT7dlsFrpcvq+YlAIAoEZSF4wC3/NxMiLVaAACe0MOCwMvLk7ZtkyZP9qnbxFNPy6pV0tChtlnVAIDoQA8LQse+uBxrtQAAAoQeFgSXHwUqfpbCAAAiED0sCA9+FKh4UwozaJD0u9+xnD8A1BUEFgSfH5sJ2fdZfPVV1y8zRnrySYaIAKCuILCgdvhRoOKpFMb+UpbzB4DoR2BB7fFzMyFvXsbUZwCIbgQW1K4grNVif5mLkSUAQJQgsKD2eSpQcdPTcviwdPfdTH0GgLqGwILQ8HOtluRk6Ykn/BpZAgBEMAILQsubGUQukoefI0sAgAhFYEHo+bmZkJ8jSwCACERgQXjwY60WyfuRpSeekDZsoCAXACIVgQXhowabCXnKO/fcI40aRUEuAEQqAgvCi59rtUiepz57eDkAIIwRWBB+alBR6ynveHg5ACBMEVgQnmpQUesp73h4OQAgDBFYEL78XKtF+jHvbNhgK7j18eUAgDBjMcaYUDciEIqLi5WQkKCioiLFx8eHujkItB07bOmivLzqczExtnGgAQOC9XIAQJB4+/1NDwsig59rtXj78kGDmPoMAOGMHhZEFk9dJatWSUOH2oaTfHx5xcssX24bVgIABBc9LIhONVirxdPLK16GglwACC8EFkSeGqzV4s3L7ZcYNEj63e8YIgKAcEBgQWTyZq0WN4nDm6nPxkhPPsnquAAQDqhhQWTLy5O2bZMmT66+MMVNUUpennTggPSvf0lz57q/BDOJACDwqGFB3eBprRbJ4+aJI0dKd9/teZSJNVsAIHQILIgO3tS11LAg103uAQAEGYEF0SMAU4AyMqTDh209Lu4mIrVrR0EuANQmAguiS8XE4cfmiZJtmOiJJ9x32FCQCwC1i8CC6GNPHH5unmjHJooAED4ILIheNdg80c7TptH2y7BmCwAEF4EF0c9dQa4XXSTeTERiiAgAgovAgrohALsfeirItV+KmUQAEHgsHIe6JUC7H3pzGYtFuusu6Y47qt2LEQDqPBaOA1wJ0O6H3lyGYSIACBwCC+oeb3c/9KIg19MMavulmEkEADVDYEHdFKA5y97MoLZfavBgj2UyAIBqEFhQd9nnLG/YYEsS7gpyPcxZ9nZLo3vukUaNYpgIAHxF0S1g56mS1otiXMmWa/74R2nRIs+1vewADaCuo+gW8FWAdj/0Zml/++VYcA4AvENgASoKwK7Pdt6UyTCTCAC8Q2ABKgvQ1GfJuzIZHy4HAHUWgQVwxdtdn70syB050nYpT503zCQCANcougU8ycuTtm2TJk+ucUGuZBv6mTHDfUGuj5cEgIhF0S0QKN7OWfZyTMebPYl8vCQARD0CC+AtbwpyPayOa8dMIgDwDYEF8EWApj5Xvpw3M4natSO4AKi7CCyArzyN6dinPnuZMLydScQUaAB1GUW3QE14Wh1X8rl61ttLrlolDR1qG14CgEhF0S1QGwK0iaKrS3qqbfGhEwcAIh6BBagp+5hOALdr9nYmEfUtAOoKhoSAQArCIiv2zRSffloqKwvYZQEgLAR1SGjJkiXq0KGD4uLilJaWpi1btlR77saNG2WxWKo8/vOf/zjOWblypctzzpw540/zgNAJwiIr9inQnjpxfLwsAEQUnwPL6tWrNXv2bM2fP187d+7UpZdeqnHjxik3N9ft6/bv36/8/HzHo3Pnzk7Px8fHOz2fn5+vuLg4X5sHhF6QFlnxZv26ipdliX8A0cTnwLJo0SJlZGTopptuUvfu3bV48WKlpKRo6dKlbl/XqlUrJSYmOh7WSkWKFovF6fnExERfmwaElyBt1+xNJ44x0j33SKNGUd8CIDr4FFhKS0v12WefacyYMU7Hx4wZo61bt7p9bd++fZWUlKTLL79cGzZsqPL8qVOnlJqaquTkZF111VXauXOn2+uVlJSouLjY6QGEnSBt12zvxKEwF0Bd4VNgOX78uMrKytS6dWun461bt1ZBQYHL1yQlJWn58uVas2aN3njjDXXt2lWXX365Nm/e7DinW7duWrlypd566y2tWrVKcXFxGjZsmLKzs6tty8KFC5WQkOB4pKSk+PJRgNoTxO2avR19klh4DkBk82mW0LFjx9S2bVtt3bpVQ4YMcRx/9NFH9be//c2pkNadq6++WhaLRW+99ZbL58vLy9WvXz8NHz5cf/rTn1yeU1JSopKSEsfPxcXFSklJYZYQwl+QtmvOzJRuucXzTCL7pVl4DkA4CMosoZYtW8pqtVbpTSksLKzS6+LO4MGD3faexMTEaMCAAW7PqV+/vuLj450eQEQI0nbN3o4+2S/NwnMAIolPgSU2NlZpaWnKyspyOp6VlaWhQ4d6fZ2dO3cqKSmp2ueNMdq1a5fbc4CIFsSZRPbRJ+pbAEQTn2cJzZkzR88//7xWrFihffv26c4771Rubq5uvfVWSdK8efM0depUx/mLFy/Wm2++qezsbO3Zs0fz5s3TmjVrNGvWLMc5Dz30kN577z0dPHhQu3btUkZGhnbt2uW4JhC1gjSTSKpamMuO0AAi2QW+viA9PV0nTpzQww8/rPz8fPXq1Uvr1q1TamqqJCk/P99pTZbS0lLdfffdOnr0qBo0aKCePXvq7bff1pVXXuk457vvvtOMGTNUUFCghIQE9e3bV5s3b9bAgQMD8BGBMJeRIY0dKx04IP3rX9Lcua7rW+xDRBdfbAs6XrIHlzvukLZtkyZPrr58xh5cFi2SHntM6t9f6tyZOhcAocfS/EC48bRdc0xMjdKEtzW/dhaLdNddtsBDcAEQaOzWDEQqT9s1l5fXaFU4b2t+7ZgODSAcEFiAcOTrds01rG/xJriwTxGAUCKwAOHKl1Xh/EwTvhTm2t9m4EAKcwHUPgILEO68mUkk+TwFuqKKO0J7s46LvVOHDRYB1BaKboFIkZfneSaRnY+r5Fb3dn/8o23GkKcCXQpzAfjL2+9vAgsQibxJEwFaf9/TpKWKCC4AfMUsISCaeVPfEqD19z1NWqqIBegABAuBBYhk3qSJAKSIipOWPJXSVHxL6lwABApDQkA0sA8RPf205+2aa1jf4kspTUUMFwFwhRoWoC7Ky/O8/r4UsPoWXwpz7QguACoisAB1mbfr7wcoPfgTXGq4wwCAKEHRLVCX+bpSbg2rZH1dgE6q8Q4DAOoYeliAaOdLfUsAe1yocwHgDYaEADjztr5FCsjCcxXfljoXANUhsABwzdv6lgAV5tr50tFTsQnUuQDRjcACoHohXHef4SIAFRFYAHgW4g2DGC4CwCwhAJ75Mr0nCOvuV357lv8HUB16WAD8KESFuRXfviZ1Lo0bS6dOUe8CRBKGhAD4L0SFuXb+1rnYMWwERA6GhAD4z9uF5wK0I3RlycnSyJG2t/dluMiOYSMg+tDDAsC9EBfm+tOMypgeDYQvhoQABFYIVsytaTNquWkA/EBgARAcvhbmBqlro2Kdy733+h5eKgYXScrOpvcFCAUCC4Dg8rYw1y7IvS4HDkiNGkmvvur7ui6Sre6F3heg9hFYAASfP4UlQZgOXV2zGDYCwh+BBUDt8TW4xMRI27dLAwYEvVmBmh4tMWwEBAOBBUDt87Uw9w9/qLWpOzWZZcSwERA8BBYAoeNr10YtpoDKmapiGPEFwQUIDAILgPAQJuu4uGrWgQNSp062n2vS+8KwEeA/AguA8LJjhzR4sHeJIETdFwwbAbWPwAIg/GRmSrfc4t/OhrXYbRHoYaNJk9iUEagOgQVAePJ36k4Iui0CNWxkxxYBQFUEFgDhz58xmBCPt9Rk2Kgiel8AGwILgMgRwcGlpsNGdvS+oK4isACIPP4sURvib/pADxtJ9L6gbiGwAIhcEVTn4kpNtwaojKnTiGYEFgDRIQKHi+wqbsr4/ff+bxFgx9RpRCMCC4DoEsHBpaJg9b4wfIRIRWABEJ0isM7FlUD3vthV/KiNGxNiEP4ILACiW4TXubgS6N4XO3phEM4ILADqjigZLrKr2Pvy6quBmzptRy8MwgmBBUDd409wiYBv72BMna6MXhiECoEFQN1V07GVMO59sQvW8JFdBOQ4RAkCCwD4W+diFyHBpXLx7r33BifEsB4MgoHAAgAV1WQToDCcZeROdTUwgeJqPRj7UBK9MfAVgQUAXKkDw0WV1WYvjB1DSvAWgQUA3Kk4XOTPt3cEBpeKgt0L4wqFvXCFwAIA3qr87e3v9GgpYgs7wqUXht6YuofAAgD+8mfYKAo3+gn2ejDuuMqBhJnoRGABgJqqA7OMfOFqPZhgDyW5CkdR0qmF8wgsABBINZllFGXBpaLKQ0m1OaTEbKXoQGABgGAI1PToOvCNGorC3sqokwl/QQ0sS5Ys0RNPPKH8/Hz17NlTixcv1qWXXury3I0bN+qyyy6rcnzfvn3q1q2b4+c1a9ZowYIF+vrrr9WxY0c9+uij+vnPf+51mwgsAGpV5ToXfws7orj3pbJQFPa6465OhlBTe4IWWFavXq0pU6ZoyZIlGjZsmJYtW6bnn39ee/fuVbt27aqcbw8s+/fvd2rIhRdeKKvVKknatm2bLr30Uv3+97/Xz3/+c61du1b333+/PvroIw0aNCigHxgAAipQG/1E2OJ0geJqSKlyga/FEth9k1yxWFxnTYp/gy9ogWXQoEHq16+fli5d6jjWvXt3TZgwQQsXLqxyvj2wfPvtt2ratKnLa6anp6u4uFjvvPOO49gVV1yhZs2aadWqVV61i8ACIGzUZNhIYsESVc2BoZqtZOdt8S89NL4LSmApLS1Vw4YN9dprrzkN19xxxx3atWuXNm3aVOU19sDSvn17nTlzRj169NB9993nNEzUrl073Xnnnbrzzjsdx55++mktXrxYhw8f9qptBBYAYSdQOxTWoWEjb4RitpIn/vTQEGpsvP3+vsCXix4/flxlZWVq3bq10/HWrVuroKDA5WuSkpK0fPlypaWlqaSkRH/72990+eWXa+PGjRo+fLgkqaCgwKdrSlJJSYlKSkocPxcXF/vyUQAg+JKTpSeesH1b1WRVXWOkJ5+09djUoaLd6iQnO3/kin/FoZitJFXfy2O/dU8+SaipKZ8Ci53F3jd2njGmyjG7rl27qmvXro6fhwwZoiNHjujJJ590BBZfrylJCxcu1EMPPeRP8wGgdtm/YUeOlCZP9n/qTHm5dM89zsfofZFUNcTYVf4rD2WdDKGmZnwKLC1btpTVaq3S81FYWFilh8SdwYMH66WXXnL8nJiY6PM1582bpzlz5jh+Li4uVkpKitdtAICQqPjNOmCAc++LP4vT2b/tnnqK1dSq4SrMVPyrr1wnE6mhxt0U7oqhRorMXw+/im7T0tK0ZMkSx7EePXpo/PjxLotuXbn22mv13//+V+vXr5dkK7o9efKk1q1b5zhn3Lhxatq0KUW3AOqOQNS8ROEWAaHkbfFvbYSZQPB2sT2p9npxgj6t+c9//rOGDBmi5cuX6y9/+Yv27Nmj1NRUzZs3T0ePHtVf//pXSdLixYvVvn179ezZU6WlpXrppZf02GOPac2aNZo4caIkaevWrRo+fLgeffRRjR8/Xv/4xz903333Ma0ZQN0U6BXXmHUUFNWFmVD20ASCu9lXMTHS8uVSRkbg3s/r72/jh+eee86kpqaa2NhY069fP7Np0ybHc9OmTTMjRoxw/PyHP/zBdOzY0cTFxZlmzZqZn/zkJ+btt9+ucs3XXnvNdO3a1dSrV89069bNrFmzxqc2FRUVGUmmqKjIn48EAOHryBFjNmww5oknjLFajbF9l/j/iIkx5vHHjVm/3nZtBI391h058uOfP/30x//effePt9Risd2amt7eYD+s1sD+2nj7/c3S/AAQSSr3vvi71osdvS8hF4k9NRs22AqaA4G9hACgLgjUFgF21L2EJU+hxtsp3IFYbM9qlQ4dCtyvB4EFAOqSQG0RYFfHNmqMFtXtnm3/rzeL7bnrxbFapWXLQlPDQmABgGgVqJV27VwtBkKIiVjVhRt3vTidOkXQLKFwRWABgGq42ibZnzVf7NzNjSXAwEcEFgBA9QLd+2JHDQx8RGABAHgW6DVf7KiBgZcILAAA39kDTDB2DWT4CC4QWAAANVNd70sg5sZK9MJAEoEl1M0BgOjjaup0sGpg6IWpMwgsAIDgC1YNjB29MFGPwAIAqH3BrIGxYz2YqEJgAQCEVrB7X1gPJioQWAAA4cXVAna12QvDkFJYIrAAAMJfsHthJFt4qfhVR29MWCGwAAAiT232wthR2BtSBBYAQHQI9nowrrjqhZEo8A0CAgsAIDrVxnowlXkq8JUIM34isAAA6g53vTAWi/87U3uD2Uo1QmABANRdlXthgl3YWx1mK3lEYAEAwJVQFPZK3s1Wkurc0BKBBQAAb3maXh3MAl9X71E5zERxrwyBBQAAf1XuhXFX4FsbYcbO1RTsCA8zBBYAAILBlzBTmyI0zBBYAACobaGcreSOu+LfEIcaAgsAAKHmy2yl2hpaqlz8W/F4CEINgQUAgHAWrkNLUvWhJiZGWr5cysgI2FsRWAAAiFSVw0xtT8F2x2qVDh0KWE+Lt9/fFwTk3QAAQOAkJ7sOBCNHSpMnhzbMlJXZ3r+W610ILAAARBJfw0ygi3+t1h+Hr2oRgQUAgGjhKswMGGArpHVV/OtrqLFapWXLQjKbiBoWAABQ/YymisNOnTqFbJYQPSwAAKBq70yYLTQXE+oGAAAAeEJgAQAAYY/AAgAAwh6BBQAAhD0CCwAACHsEFgAAEPYILAAAIOwRWAAAQNgjsAAAgLBHYAEAAGGPwAIAAMJe1OwlZN/Dsbi4OMQtAQAA3rJ/b3vaizlqAsvJkyclSSkpKSFuCQAA8NXJkyeVkJBQ7fMW4ynSRIjy8nIdO3ZMTZo0kcViCdh1i4uLlZKSoiNHjrjd9jqS8RkjX7R/PonPGA2i/fNJ0f8Zg/H5jDE6efKk2rRpo5iY6itVoqaHJSYmRslB3Ao7Pj4+Kn/5KuIzRr5o/3wSnzEaRPvnk6L/Mwb687nrWbGj6BYAAIQ9AgsAAAh7BBYP6tevrwceeED169cPdVOChs8Y+aL980l8xmgQ7Z9Piv7PGMrPFzVFtwAAIHrRwwIAAMIegQUAAIQ9AgsAAAh7BBYAABD2CCweLFmyRB06dFBcXJzS0tK0ZcuWUDfJLwsXLtSAAQPUpEkTtWrVShMmTND+/fudzpk+fbosFovTY/DgwSFqse8efPDBKu1PTEx0PG+M0YMPPqg2bdqoQYMGGjlypPbs2RPCFvumffv2VT6fxWLRzJkzJUXm/du8ebOuvvpqtWnTRhaLRW+++abT897cs5KSEt1+++1q2bKlGjVqpGuuuUZ5eXm1+Cncc/cZz549q7lz56p3795q1KiR2rRpo6lTp+rYsWNO1xg5cmSVezt58uRa/iSuebqH3vxeRvI9lOTy36XFYtETTzzhOCec76E33w/h8G+RwOLG6tWrNXv2bM2fP187d+7UpZdeqnHjxik3NzfUTfPZpk2bNHPmTG3fvl1ZWVk6d+6cxowZo++//97pvCuuuEL5+fmOx7p160LUYv/07NnTqf1ffPGF47nHH39cixYt0rPPPqsdO3YoMTFRP/3pTx37UIW7HTt2OH22rKwsSdJ1113nOCfS7t/333+vPn366Nlnn3X5vDf3bPbs2Vq7dq1eeeUVffTRRzp16pSuuuoqlZWV1dbHcMvdZzx9+rQ+//xzLViwQJ9//rneeOMNffXVV7rmmmuqnHvzzTc73dtly5bVRvM98nQPJc+/l5F8DyU5fbb8/HytWLFCFotFv/jFL5zOC9d76M33Q1j8WzSo1sCBA82tt97qdKxbt27m3nvvDVGLAqewsNBIMps2bXIcmzZtmhk/fnzoGlVDDzzwgOnTp4/L58rLy01iYqJ57LHHHMfOnDljEhISzJ///OdaamFg3XHHHaZjx46mvLzcGBP590+SWbt2reNnb+7Zd999Z+rVq2deeeUVxzlHjx41MTEx5t133621tnur8md05dNPPzWSzOHDhx3HRowYYe64447gNi4AXH0+T7+X0XgPx48fb0aNGuV0LFLuoTFVvx/C5d8iPSzVKC0t1WeffaYxY8Y4HR8zZoy2bt0aolYFTlFRkSSpefPmTsc3btyoVq1aqUuXLrr55ptVWFgYiub5LTs7W23atFGHDh00efJkHTx4UJKUk5OjgoICp/tZv359jRgxIiLvZ2lpqV566SXdeOONTpt9Rvr9q8ibe/bZZ5/p7NmzTue0adNGvXr1isj7Ktn+bVosFjVt2tTp+Msvv6yWLVuqZ8+euvvuuyOmZ1By/3sZbffwm2++0dtvv62MjIwqz0XKPaz8/RAu/xajZvPDQDt+/LjKysrUunVrp+OtW7dWQUFBiFoVGMYYzZkzRz/5yU/Uq1cvx/Fx48bpuuuuU2pqqnJycrRgwQKNGjVKn332WUSs2jho0CD99a9/VZcuXfTNN9/okUce0dChQ7Vnzx7HPXN1Pw8fPhyK5tbIm2++qe+++07Tp093HIv0+1eZN/esoKBAsbGxatasWZVzIvHf6ZkzZ3Tvvffql7/8pdPGcjfccIM6dOigxMREffnll5o3b552797tGBYMZ55+L6PtHr744otq0qSJJk6c6HQ8Uu6hq++HcPm3SGDxoOL/e5VsN7PysUgza9Ys/fvf/9ZHH33kdDw9Pd3x5169eql///5KTU3V22+/XeUfXzgaN26c48+9e/fWkCFD1LFjR7344ouOIr9ouZ+ZmZkaN26c2rRp4zgW6fevOv7cs0i8r2fPntXkyZNVXl6uJUuWOD138803O/7cq1cvde7cWf3799fnn3+ufv361XZTfeLv72Uk3kNJWrFihW644QbFxcU5HY+Ue1jd94MU+n+LDAlVo2XLlrJarVWSYWFhYZWUGUluv/12vfXWW9qwYYOSk5PdnpuUlKTU1FRlZ2fXUusCq1GjRurdu7eys7Mds4Wi4X4ePnxYH3zwgW666Sa350X6/fPmniUmJqq0tFTffvtttedEgrNnz2rSpEnKyclRVlaWU++KK/369VO9evUi8t5W/r2MlnsoSVu2bNH+/fs9/tuUwvMeVvf9EC7/Fgks1YiNjVVaWlqV7rqsrCwNHTo0RK3ynzFGs2bN0htvvKH169erQ4cOHl9z4sQJHTlyRElJSbXQwsArKSnRvn37lJSU5OiKrXg/S0tLtWnTpoi7ny+88IJatWqln/3sZ27Pi/T75809S0tLU7169ZzOyc/P15dffhkx99UeVrKzs/XBBx+oRYsWHl+zZ88enT17NiLvbeXfy2i4h3aZmZlKS0tTnz59PJ4bTvfQ0/dD2PxbDEjpbpR65ZVXTL169UxmZqbZu3evmT17tmnUqJE5dOhQqJvms9/85jcmISHBbNy40eTn5zsep0+fNsYYc/LkSXPXXXeZrVu3mpycHLNhwwYzZMgQ07ZtW1NcXBzi1nvnrrvuMhs3bjQHDx4027dvN1dddZVp0qSJ43499thjJiEhwbzxxhvmiy++MNdff71JSkqKmM9njDFlZWWmXbt2Zu7cuU7HI/X+nTx50uzcudPs3LnTSDKLFi0yO3fudMyQ8eae3XrrrSY5Odl88MEH5vPPPzejRo0yffr0MefOnQvVx3Li7jOePXvWXHPNNSY5Odns2rXL6d9mSUmJMcaYAwcOmIceesjs2LHD5OTkmLffftt069bN9O3bNyw+o7vP5+3vZSTfQ7uioiLTsGFDs3Tp0iqvD/d76On7wZjw+LdIYPHgueeeM6mpqSY2Ntb069fPaRpwJJHk8vHCCy8YY4w5ffq0GTNmjLnwwgtNvXr1TLt27cy0adNMbm5uaBvug/T0dJOUlGTq1atn2rRpYyZOnGj27NnjeL68vNw88MADJjEx0dSvX98MHz7cfPHFFyFsse/ee+89I8ns37/f6Xik3r8NGza4/L2cNm2aMca7e/bDDz+YWbNmmebNm5sGDRqYq666Kqw+t7vPmJOTU+2/zQ0bNhhjjMnNzTXDhw83zZs3N7GxsaZjx47mt7/9rTlx4kRoP9h57j6ft7+XkXwP7ZYtW2YaNGhgvvvuuyqvD/d76On7wZjw+LdoOd9YAACAsEUNCwAACHsEFgAAEPYILAAAIOwRWAAAQNgjsAAAgLBHYAEAAGGPwAIAAMIegQUAAIQ9AgsAAAh7BBYAABD2CCwAACDsEVgAAEDY+//0+Wn+Qh8jRQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4735 - accuracy: 0.7691 - val_loss: 0.4953 - val_accuracy: 0.7552\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4734 - accuracy: 0.7674 - val_loss: 0.4951 - val_accuracy: 0.7552\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7552\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4730 - accuracy: 0.7691 - val_loss: 0.4949 - val_accuracy: 0.7552\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4728 - accuracy: 0.7691 - val_loss: 0.4948 - val_accuracy: 0.7552\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4726 - accuracy: 0.7708 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4724 - accuracy: 0.7708 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4721 - accuracy: 0.7708 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4720 - accuracy: 0.7708 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4718 - accuracy: 0.7708 - val_loss: 0.4942 - val_accuracy: 0.7552\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4716 - accuracy: 0.7708 - val_loss: 0.4940 - val_accuracy: 0.7552\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4714 - accuracy: 0.7708 - val_loss: 0.4939 - val_accuracy: 0.7552\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4713 - accuracy: 0.7708 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4710 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4709 - accuracy: 0.7708 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4707 - accuracy: 0.7726 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4705 - accuracy: 0.7726 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4704 - accuracy: 0.7726 - val_loss: 0.4933 - val_accuracy: 0.7500\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4703 - accuracy: 0.7726 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4701 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4699 - accuracy: 0.7743 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4697 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4696 - accuracy: 0.7760 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4695 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4693 - accuracy: 0.7760 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4692 - accuracy: 0.7760 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4690 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4688 - accuracy: 0.7760 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4687 - accuracy: 0.7760 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.4685 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4684 - accuracy: 0.7760 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4683 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4681 - accuracy: 0.7760 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4679 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4678 - accuracy: 0.7760 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4677 - accuracy: 0.7760 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4675 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4674 - accuracy: 0.7760 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4673 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4672 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4670 - accuracy: 0.7795 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4669 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4668 - accuracy: 0.7795 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4665 - accuracy: 0.7795 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4666 - accuracy: 0.7795 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4664 - accuracy: 0.7812 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4662 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7500\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4661 - accuracy: 0.7795 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4647 - accuracy: 0.7830 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4645 - accuracy: 0.7847 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.4642 - accuracy: 0.7830 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4641 - accuracy: 0.7830 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4640 - accuracy: 0.7812 - val_loss: 0.4898 - val_accuracy: 0.7604\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.4898 - val_accuracy: 0.7604\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.4638 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7604\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7604\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7604\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7604\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7604\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7604\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7604\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7604\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7604\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7552\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7552\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7552\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4624 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7552\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7552\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4618 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4617 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4617 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4616 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4615 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 1s 55ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.4585 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4584 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4583 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4583 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4580 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4580 - accuracy: 0.7812 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4580 - accuracy: 0.7812 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.4579 - accuracy: 0.7812 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.4579 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4578 - accuracy: 0.7812 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4578 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4577 - accuracy: 0.7812 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4576 - accuracy: 0.7812 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4576 - accuracy: 0.7812 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4575 - accuracy: 0.7812 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4574 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4572 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4572 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4571 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4567 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4563 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4561 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4561 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4560 - accuracy: 0.7778 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4559 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4559 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4559 - accuracy: 0.7778 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4559 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4558 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4558 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4557 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4556 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4556 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4556 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4554 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4554 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4554 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4553 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4553 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4553 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4553 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4552 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4552 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4552 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4551 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.4551 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4551 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4550 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4550 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4550 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4550 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4549 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4549 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4549 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4549 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4549 - accuracy: 0.7812 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4548 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4547 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4546 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4546 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4545 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4545 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.4546 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4545 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4545 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4544 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4544 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4543 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4542 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4542 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4542 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4541 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4542 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4541 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4541 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4541 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4540 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4540 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4540 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4540 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4539 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4537 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4537 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4537 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4536 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4536 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4536 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4536 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4535 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4535 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4535 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4533 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4533 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4533 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4533 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4532 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4532 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4532 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4532 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4532 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4531 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4531 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4531 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4530 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4528 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.4527 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4527 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4527 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4526 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4526 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4526 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4525 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4525 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4525 - accuracy: 0.7899 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4524 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4524 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4523 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4523 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4523 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4523 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4522 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4522 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4523 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4522 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4522 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4521 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4521 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4522 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4521 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4520 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4520 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4520 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4520 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4520 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4520 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4519 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4519 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4519 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4518 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4518 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4518 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4518 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4517 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4517 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4517 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.4517 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4517 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4516 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4516 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4516 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4516 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4515 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4515 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4515 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4515 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4514 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4514 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4514 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4514 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4514 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4513 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4513 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4513 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4513 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4512 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4512 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4512 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4512 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4511 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4511 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4510 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4511 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4511 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4510 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4510 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4509 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4509 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4509 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4510 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4508 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4509 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4508 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4508 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4508 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4507 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4507 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4507 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4506 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4507 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4505 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4505 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4505 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4505 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4504 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4504 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4504 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4504 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4503 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4503 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4503 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4502 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4503 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4503 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4502 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4502 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4501 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4501 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.4501 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4501 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4501 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4500 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4500 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4500 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4499 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4500 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4499 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4500 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4499 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4499 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4498 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4498 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4499 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4498 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4498 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4497 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4497 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4496 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4496 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.4496 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4496 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4496 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4496 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4494 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4494 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4494 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4493 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4493 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4493 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4493 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4493 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4492 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4492 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4492 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4491 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4491 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4491 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4491 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4490 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4491 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4490 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4491 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4490 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4490 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4490 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4489 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4489 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4489 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4488 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4488 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4488 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4488 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4488 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4487 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4487 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 0.4487 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4487 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4487 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4487 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4487 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4486 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4486 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4485 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4485 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4485 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4484 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4485 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4484 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4484 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4484 - accuracy: 0.7899 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4483 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4483 - accuracy: 0.7899 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4483 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4483 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4483 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4482 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4482 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4482 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4481 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4481 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4481 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4481 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4481 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4480 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4480 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4480 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4480 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4479 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4480 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4479 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4479 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4478 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4479 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4478 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4478 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4478 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4477 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4478 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4477 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4478 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4477 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4475 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4475 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4475 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4475 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4469 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4469 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4467 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4466 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4467 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4466 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4466 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4466 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4466 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4464 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4464 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4464 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4462 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4462 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4462 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4462 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4460 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4460 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4460 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4460 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4455 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4455 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4455 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4453 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4453 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.4453 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4451 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4451 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4451 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4451 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4450 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4450 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4450 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4450 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4449 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4449 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4449 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4449 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4447 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4446 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4446 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4447 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4446 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4446 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4446 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4445 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4445 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.4445 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4445 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4444 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4445 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4444 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4444 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4444 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4444 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4443 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4443 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4442 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4443 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4442 - accuracy: 0.7917 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4442 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4442 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4442 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4442 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4442 - accuracy: 0.7917 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4441 - accuracy: 0.7917 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4440 - accuracy: 0.7917 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4438 - accuracy: 0.7917 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4438 - accuracy: 0.7917 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4438 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4436 - accuracy: 0.7934 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4436 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4433 - accuracy: 0.7934 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4433 - accuracy: 0.7934 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4433 - accuracy: 0.7934 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4433 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4432 - accuracy: 0.7934 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.4432 - accuracy: 0.7934 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4431 - accuracy: 0.7934 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4431 - accuracy: 0.7934 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4430 - accuracy: 0.7934 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4430 - accuracy: 0.7934 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4429 - accuracy: 0.7934 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4430 - accuracy: 0.7934 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4429 - accuracy: 0.7934 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4428 - accuracy: 0.7951 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4428 - accuracy: 0.7934 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4428 - accuracy: 0.7951 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4428 - accuracy: 0.7951 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4426 - accuracy: 0.7934 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4426 - accuracy: 0.7951 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4426 - accuracy: 0.7899 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4426 - accuracy: 0.7934 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4425 - accuracy: 0.7934 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4425 - accuracy: 0.7934 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4424 - accuracy: 0.7934 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4423 - accuracy: 0.7934 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4423 - accuracy: 0.7934 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4419 - accuracy: 0.7934 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4419 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4419 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4419 - accuracy: 0.7951 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4415 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4415 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4415 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4414 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4415 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4414 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4414 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4413 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4413 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4414 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4413 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4413 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4413 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4413 - accuracy: 0.7934 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4412 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4412 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4412 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4412 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4411 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4411 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4411 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4411 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4411 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4410 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4411 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4410 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4410 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4409 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4410 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4409 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4409 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4409 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4409 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4408 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4408 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4408 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4408 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4407 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4408 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4407 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4407 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4407 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4407 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4405 - accuracy: 0.7899 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4405 - accuracy: 0.7899 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4405 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4405 - accuracy: 0.7899 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4404 - accuracy: 0.7899 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4405 - accuracy: 0.7899 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4404 - accuracy: 0.7899 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4404 - accuracy: 0.7899 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4404 - accuracy: 0.7899 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.4404 - accuracy: 0.7899 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4403 - accuracy: 0.7899 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4403 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4403 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4403 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4403 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4402 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4402 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4402 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4401 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4402 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4402 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4401 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4399 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4399 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4399 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4398 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4398 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4398 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4398 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4398 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4397 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4397 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4397 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.4884 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27d7071d150>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 3s 54ms/step - loss: 0.8648 - accuracy: 0.4236 - val_loss: 0.8525 - val_accuracy: 0.4167\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.8079 - accuracy: 0.4444 - val_loss: 0.8078 - val_accuracy: 0.4323\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.7691 - accuracy: 0.4618 - val_loss: 0.7766 - val_accuracy: 0.4688\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.7414 - accuracy: 0.5000 - val_loss: 0.7537 - val_accuracy: 0.4740\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.7208 - accuracy: 0.5174 - val_loss: 0.7360 - val_accuracy: 0.5052\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.7050 - accuracy: 0.5434 - val_loss: 0.7221 - val_accuracy: 0.5260\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6925 - accuracy: 0.5556 - val_loss: 0.7107 - val_accuracy: 0.5312\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.6823 - accuracy: 0.5764 - val_loss: 0.7013 - val_accuracy: 0.5365\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.6739 - accuracy: 0.5781 - val_loss: 0.6934 - val_accuracy: 0.5365\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.6667 - accuracy: 0.5781 - val_loss: 0.6866 - val_accuracy: 0.5469\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6605 - accuracy: 0.5833 - val_loss: 0.6805 - val_accuracy: 0.5677\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.6551 - accuracy: 0.5920 - val_loss: 0.6752 - val_accuracy: 0.5677\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.6502 - accuracy: 0.6094 - val_loss: 0.6705 - val_accuracy: 0.5833\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.6458 - accuracy: 0.6181 - val_loss: 0.6662 - val_accuracy: 0.5625\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.6417 - accuracy: 0.6163 - val_loss: 0.6622 - val_accuracy: 0.5833\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6376 - accuracy: 0.6302 - val_loss: 0.6583 - val_accuracy: 0.6094\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6335 - accuracy: 0.6354 - val_loss: 0.6545 - val_accuracy: 0.6302\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6295 - accuracy: 0.6458 - val_loss: 0.6510 - val_accuracy: 0.6302\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.6256 - accuracy: 0.6476 - val_loss: 0.6475 - val_accuracy: 0.6354\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.6218 - accuracy: 0.6493 - val_loss: 0.6440 - val_accuracy: 0.6302\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6183 - accuracy: 0.6476 - val_loss: 0.6406 - val_accuracy: 0.6354\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.6149 - accuracy: 0.6493 - val_loss: 0.6375 - val_accuracy: 0.6354\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6116 - accuracy: 0.6493 - val_loss: 0.6346 - val_accuracy: 0.6354\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.6084 - accuracy: 0.6510 - val_loss: 0.6317 - val_accuracy: 0.6354\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.6052 - accuracy: 0.6528 - val_loss: 0.6289 - val_accuracy: 0.6354\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6022 - accuracy: 0.6528 - val_loss: 0.6263 - val_accuracy: 0.6406\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5992 - accuracy: 0.6528 - val_loss: 0.6237 - val_accuracy: 0.6406\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5965 - accuracy: 0.6545 - val_loss: 0.6213 - val_accuracy: 0.6458\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5936 - accuracy: 0.6562 - val_loss: 0.6188 - val_accuracy: 0.6458\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5909 - accuracy: 0.6562 - val_loss: 0.6163 - val_accuracy: 0.6458\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.5882 - accuracy: 0.6562 - val_loss: 0.6138 - val_accuracy: 0.6458\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5853 - accuracy: 0.6562 - val_loss: 0.6112 - val_accuracy: 0.6458\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5825 - accuracy: 0.6562 - val_loss: 0.6086 - val_accuracy: 0.6458\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5796 - accuracy: 0.6562 - val_loss: 0.6060 - val_accuracy: 0.6510\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5766 - accuracy: 0.6562 - val_loss: 0.6033 - val_accuracy: 0.6510\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5738 - accuracy: 0.6562 - val_loss: 0.6009 - val_accuracy: 0.6458\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5710 - accuracy: 0.6545 - val_loss: 0.5986 - val_accuracy: 0.6458\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5682 - accuracy: 0.6545 - val_loss: 0.5963 - val_accuracy: 0.6458\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5657 - accuracy: 0.6545 - val_loss: 0.5942 - val_accuracy: 0.6458\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.5631 - accuracy: 0.6545 - val_loss: 0.5922 - val_accuracy: 0.6458\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5606 - accuracy: 0.6562 - val_loss: 0.5902 - val_accuracy: 0.6406\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5580 - accuracy: 0.6562 - val_loss: 0.5882 - val_accuracy: 0.6406\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5554 - accuracy: 0.6597 - val_loss: 0.5862 - val_accuracy: 0.6406\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5530 - accuracy: 0.6615 - val_loss: 0.5843 - val_accuracy: 0.6458\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5505 - accuracy: 0.6632 - val_loss: 0.5824 - val_accuracy: 0.6510\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5478 - accuracy: 0.6667 - val_loss: 0.5805 - val_accuracy: 0.6510\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5452 - accuracy: 0.6667 - val_loss: 0.5786 - val_accuracy: 0.6510\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5427 - accuracy: 0.6701 - val_loss: 0.5768 - val_accuracy: 0.6562\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5403 - accuracy: 0.6736 - val_loss: 0.5751 - val_accuracy: 0.6562\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5380 - accuracy: 0.6736 - val_loss: 0.5733 - val_accuracy: 0.6615\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5358 - accuracy: 0.6736 - val_loss: 0.5717 - val_accuracy: 0.6667\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5336 - accuracy: 0.6753 - val_loss: 0.5702 - val_accuracy: 0.6667\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5315 - accuracy: 0.6771 - val_loss: 0.5688 - val_accuracy: 0.6615\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5295 - accuracy: 0.6788 - val_loss: 0.5673 - val_accuracy: 0.6667\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5274 - accuracy: 0.6806 - val_loss: 0.5658 - val_accuracy: 0.6667\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5256 - accuracy: 0.6788 - val_loss: 0.5644 - val_accuracy: 0.6667\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5235 - accuracy: 0.6840 - val_loss: 0.5629 - val_accuracy: 0.6667\n",
      "Epoch 58/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5215 - accuracy: 0.6823 - val_loss: 0.5615 - val_accuracy: 0.6667\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5196 - accuracy: 0.6806 - val_loss: 0.5601 - val_accuracy: 0.6667\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5177 - accuracy: 0.6788 - val_loss: 0.5589 - val_accuracy: 0.6823\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5159 - accuracy: 0.6823 - val_loss: 0.5576 - val_accuracy: 0.6979\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5141 - accuracy: 0.6806 - val_loss: 0.5564 - val_accuracy: 0.7031\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5122 - accuracy: 0.6858 - val_loss: 0.5551 - val_accuracy: 0.7135\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5104 - accuracy: 0.6979 - val_loss: 0.5540 - val_accuracy: 0.7188\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5087 - accuracy: 0.7031 - val_loss: 0.5528 - val_accuracy: 0.7188\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5069 - accuracy: 0.7066 - val_loss: 0.5517 - val_accuracy: 0.7188\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5053 - accuracy: 0.7101 - val_loss: 0.5507 - val_accuracy: 0.7188\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5037 - accuracy: 0.7066 - val_loss: 0.5497 - val_accuracy: 0.7135\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5023 - accuracy: 0.7101 - val_loss: 0.5488 - val_accuracy: 0.7135\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5008 - accuracy: 0.7153 - val_loss: 0.5479 - val_accuracy: 0.7292\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4994 - accuracy: 0.7188 - val_loss: 0.5470 - val_accuracy: 0.7604\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4981 - accuracy: 0.7240 - val_loss: 0.5461 - val_accuracy: 0.7552\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4969 - accuracy: 0.7309 - val_loss: 0.5454 - val_accuracy: 0.7552\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4956 - accuracy: 0.7344 - val_loss: 0.5446 - val_accuracy: 0.7500\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.4943 - accuracy: 0.7361 - val_loss: 0.5438 - val_accuracy: 0.7552\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4931 - accuracy: 0.7396 - val_loss: 0.5431 - val_accuracy: 0.7448\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4919 - accuracy: 0.7413 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4907 - accuracy: 0.7448 - val_loss: 0.5416 - val_accuracy: 0.7500\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4896 - accuracy: 0.7500 - val_loss: 0.5408 - val_accuracy: 0.7396\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4886 - accuracy: 0.7517 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4875 - accuracy: 0.7483 - val_loss: 0.5394 - val_accuracy: 0.7344\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4865 - accuracy: 0.7569 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4856 - accuracy: 0.7604 - val_loss: 0.5381 - val_accuracy: 0.7396\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4847 - accuracy: 0.7604 - val_loss: 0.5375 - val_accuracy: 0.7396\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4839 - accuracy: 0.7639 - val_loss: 0.5369 - val_accuracy: 0.7448\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4830 - accuracy: 0.7691 - val_loss: 0.5362 - val_accuracy: 0.7448\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4822 - accuracy: 0.7674 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4816 - accuracy: 0.7708 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4807 - accuracy: 0.7708 - val_loss: 0.5349 - val_accuracy: 0.7448\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4800 - accuracy: 0.7708 - val_loss: 0.5345 - val_accuracy: 0.7448\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4794 - accuracy: 0.7708 - val_loss: 0.5341 - val_accuracy: 0.7448\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4788 - accuracy: 0.7743 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4781 - accuracy: 0.7743 - val_loss: 0.5333 - val_accuracy: 0.7292\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4774 - accuracy: 0.7743 - val_loss: 0.5328 - val_accuracy: 0.7344\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4768 - accuracy: 0.7743 - val_loss: 0.5324 - val_accuracy: 0.7344\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4761 - accuracy: 0.7743 - val_loss: 0.5321 - val_accuracy: 0.7344\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4755 - accuracy: 0.7708 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4750 - accuracy: 0.7726 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4743 - accuracy: 0.7708 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4738 - accuracy: 0.7708 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4729 - accuracy: 0.7674 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4723 - accuracy: 0.7674 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.4717 - accuracy: 0.7708 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4714 - accuracy: 0.7691 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4709 - accuracy: 0.7674 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4704 - accuracy: 0.7726 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4700 - accuracy: 0.7691 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4697 - accuracy: 0.7708 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4692 - accuracy: 0.7708 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4688 - accuracy: 0.7708 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4684 - accuracy: 0.7708 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4680 - accuracy: 0.7708 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4676 - accuracy: 0.7691 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
      "Epoch 115/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4673 - accuracy: 0.7691 - val_loss: 0.5278 - val_accuracy: 0.7396\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4669 - accuracy: 0.7674 - val_loss: 0.5276 - val_accuracy: 0.7396\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4665 - accuracy: 0.7691 - val_loss: 0.5275 - val_accuracy: 0.7396\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4662 - accuracy: 0.7708 - val_loss: 0.5274 - val_accuracy: 0.7396\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4658 - accuracy: 0.7691 - val_loss: 0.5272 - val_accuracy: 0.7396\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4655 - accuracy: 0.7691 - val_loss: 0.5271 - val_accuracy: 0.7396\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4652 - accuracy: 0.7691 - val_loss: 0.5270 - val_accuracy: 0.7396\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.5269 - val_accuracy: 0.7448\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4647 - accuracy: 0.7691 - val_loss: 0.5268 - val_accuracy: 0.7448\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4643 - accuracy: 0.7726 - val_loss: 0.5267 - val_accuracy: 0.7448\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4641 - accuracy: 0.7726 - val_loss: 0.5266 - val_accuracy: 0.7396\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.5265 - val_accuracy: 0.7396\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4634 - accuracy: 0.7760 - val_loss: 0.5264 - val_accuracy: 0.7396\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4632 - accuracy: 0.7778 - val_loss: 0.5262 - val_accuracy: 0.7396\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.4630 - accuracy: 0.7726 - val_loss: 0.5262 - val_accuracy: 0.7344\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4627 - accuracy: 0.7726 - val_loss: 0.5261 - val_accuracy: 0.7344\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.5260 - val_accuracy: 0.7344\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.5259 - val_accuracy: 0.7344\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.5259 - val_accuracy: 0.7396\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.5258 - val_accuracy: 0.7396\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.5257 - val_accuracy: 0.7396\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.5254 - val_accuracy: 0.7396\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.5251 - val_accuracy: 0.7396\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.5249 - val_accuracy: 0.7396\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.5248 - val_accuracy: 0.7396\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.5246 - val_accuracy: 0.7448\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.5246 - val_accuracy: 0.7448\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.5245 - val_accuracy: 0.7448\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4575 - accuracy: 0.7830 - val_loss: 0.5244 - val_accuracy: 0.7500\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.5243 - val_accuracy: 0.7500\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4565 - accuracy: 0.7830 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.5239 - val_accuracy: 0.7500\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4560 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7500\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4557 - accuracy: 0.7795 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4555 - accuracy: 0.7795 - val_loss: 0.5235 - val_accuracy: 0.7500\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4552 - accuracy: 0.7795 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4549 - accuracy: 0.7795 - val_loss: 0.5233 - val_accuracy: 0.7500\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4546 - accuracy: 0.7795 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4545 - accuracy: 0.7812 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4542 - accuracy: 0.7778 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4539 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4536 - accuracy: 0.7795 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4533 - accuracy: 0.7778 - val_loss: 0.5227 - val_accuracy: 0.7552\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4531 - accuracy: 0.7795 - val_loss: 0.5226 - val_accuracy: 0.7552\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4529 - accuracy: 0.7795 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4527 - accuracy: 0.7795 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4524 - accuracy: 0.7795 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4522 - accuracy: 0.7795 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4520 - accuracy: 0.7795 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4518 - accuracy: 0.7795 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4515 - accuracy: 0.7795 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4513 - accuracy: 0.7795 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4511 - accuracy: 0.7795 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4509 - accuracy: 0.7795 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4507 - accuracy: 0.7795 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4506 - accuracy: 0.7795 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4504 - accuracy: 0.7795 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4502 - accuracy: 0.7795 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4499 - accuracy: 0.7778 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4498 - accuracy: 0.7778 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4497 - accuracy: 0.7778 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4495 - accuracy: 0.7795 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4493 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4490 - accuracy: 0.7795 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4488 - accuracy: 0.7795 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4487 - accuracy: 0.7760 - val_loss: 0.5202 - val_accuracy: 0.7552\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4484 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4481 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4480 - accuracy: 0.7760 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4479 - accuracy: 0.7778 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4475 - accuracy: 0.7760 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4473 - accuracy: 0.7760 - val_loss: 0.5193 - val_accuracy: 0.7552\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4472 - accuracy: 0.7760 - val_loss: 0.5192 - val_accuracy: 0.7552\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4470 - accuracy: 0.7760 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4470 - accuracy: 0.7760 - val_loss: 0.5190 - val_accuracy: 0.7552\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4467 - accuracy: 0.7760 - val_loss: 0.5189 - val_accuracy: 0.7552\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4466 - accuracy: 0.7778 - val_loss: 0.5188 - val_accuracy: 0.7552\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4466 - accuracy: 0.7760 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4462 - accuracy: 0.7760 - val_loss: 0.5186 - val_accuracy: 0.7552\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4460 - accuracy: 0.7760 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4459 - accuracy: 0.7760 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4458 - accuracy: 0.7726 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4456 - accuracy: 0.7743 - val_loss: 0.5182 - val_accuracy: 0.7552\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4455 - accuracy: 0.7760 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4453 - accuracy: 0.7743 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4451 - accuracy: 0.7760 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4449 - accuracy: 0.7778 - val_loss: 0.5178 - val_accuracy: 0.7552\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4448 - accuracy: 0.7760 - val_loss: 0.5177 - val_accuracy: 0.7552\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4447 - accuracy: 0.7743 - val_loss: 0.5176 - val_accuracy: 0.7552\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4445 - accuracy: 0.7778 - val_loss: 0.5175 - val_accuracy: 0.7552\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4444 - accuracy: 0.7778 - val_loss: 0.5174 - val_accuracy: 0.7552\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4443 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7552\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4442 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4438 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4438 - accuracy: 0.7778 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4436 - accuracy: 0.7778 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4437 - accuracy: 0.7778 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4434 - accuracy: 0.7795 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4432 - accuracy: 0.7778 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4430 - accuracy: 0.7778 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4428 - accuracy: 0.7795 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4427 - accuracy: 0.7778 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4425 - accuracy: 0.7795 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4424 - accuracy: 0.7778 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4421 - accuracy: 0.7812 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4419 - accuracy: 0.7795 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4419 - accuracy: 0.7778 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4417 - accuracy: 0.7812 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4415 - accuracy: 0.7812 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4412 - accuracy: 0.7812 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.4411 - accuracy: 0.7795 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4410 - accuracy: 0.7778 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4407 - accuracy: 0.7812 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4408 - accuracy: 0.7795 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4406 - accuracy: 0.7778 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4405 - accuracy: 0.7778 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4403 - accuracy: 0.7795 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4401 - accuracy: 0.7778 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4400 - accuracy: 0.7778 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4397 - accuracy: 0.7778 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4397 - accuracy: 0.7778 - val_loss: 0.5134 - val_accuracy: 0.7604\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4396 - accuracy: 0.7760 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4395 - accuracy: 0.7778 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4393 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4393 - accuracy: 0.7760 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4392 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4391 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4388 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4387 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4386 - accuracy: 0.7778 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4385 - accuracy: 0.7760 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4385 - accuracy: 0.7760 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4383 - accuracy: 0.7778 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4384 - accuracy: 0.7743 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4382 - accuracy: 0.7760 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4379 - accuracy: 0.7743 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4380 - accuracy: 0.7743 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4377 - accuracy: 0.7743 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4376 - accuracy: 0.7760 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4375 - accuracy: 0.7760 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4374 - accuracy: 0.7743 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4373 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4371 - accuracy: 0.7743 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4370 - accuracy: 0.7726 - val_loss: 0.5108 - val_accuracy: 0.7656\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4369 - accuracy: 0.7778 - val_loss: 0.5108 - val_accuracy: 0.7656\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4369 - accuracy: 0.7726 - val_loss: 0.5107 - val_accuracy: 0.7656\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4367 - accuracy: 0.7760 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4366 - accuracy: 0.7760 - val_loss: 0.5105 - val_accuracy: 0.7656\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4366 - accuracy: 0.7760 - val_loss: 0.5104 - val_accuracy: 0.7656\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4365 - accuracy: 0.7760 - val_loss: 0.5104 - val_accuracy: 0.7656\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4363 - accuracy: 0.7760 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4363 - accuracy: 0.7778 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4361 - accuracy: 0.7760 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4360 - accuracy: 0.7760 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4360 - accuracy: 0.7743 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4360 - accuracy: 0.7760 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4358 - accuracy: 0.7743 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4355 - accuracy: 0.7760 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4355 - accuracy: 0.7743 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4354 - accuracy: 0.7743 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4352 - accuracy: 0.7743 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4351 - accuracy: 0.7743 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4350 - accuracy: 0.7743 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4349 - accuracy: 0.7743 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4349 - accuracy: 0.7743 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4347 - accuracy: 0.7760 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4345 - accuracy: 0.7760 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4344 - accuracy: 0.7778 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4344 - accuracy: 0.7743 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4343 - accuracy: 0.7795 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4340 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4340 - accuracy: 0.7778 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4338 - accuracy: 0.7778 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4335 - accuracy: 0.7760 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4334 - accuracy: 0.7760 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4334 - accuracy: 0.7760 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4333 - accuracy: 0.7795 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4332 - accuracy: 0.7760 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4330 - accuracy: 0.7778 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4328 - accuracy: 0.7778 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4328 - accuracy: 0.7795 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4327 - accuracy: 0.7743 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4325 - accuracy: 0.7743 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4325 - accuracy: 0.7795 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4325 - accuracy: 0.7795 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4322 - accuracy: 0.7778 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4321 - accuracy: 0.7795 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4321 - accuracy: 0.7778 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4321 - accuracy: 0.7778 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4317 - accuracy: 0.7778 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4317 - accuracy: 0.7778 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4318 - accuracy: 0.7778 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4315 - accuracy: 0.7778 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4315 - accuracy: 0.7795 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4314 - accuracy: 0.7795 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4313 - accuracy: 0.7812 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4312 - accuracy: 0.7795 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4311 - accuracy: 0.7830 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4310 - accuracy: 0.7812 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4309 - accuracy: 0.7812 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4308 - accuracy: 0.7812 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4310 - accuracy: 0.7812 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4308 - accuracy: 0.7812 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4306 - accuracy: 0.7812 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4305 - accuracy: 0.7830 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4306 - accuracy: 0.7812 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4304 - accuracy: 0.7830 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4303 - accuracy: 0.7812 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4302 - accuracy: 0.7812 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4301 - accuracy: 0.7812 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4301 - accuracy: 0.7812 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4297 - accuracy: 0.7830 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4297 - accuracy: 0.7812 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4295 - accuracy: 0.7830 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4297 - accuracy: 0.7812 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4293 - accuracy: 0.7795 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4292 - accuracy: 0.7795 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.4292 - accuracy: 0.7795 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4289 - accuracy: 0.7795 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4289 - accuracy: 0.7795 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4288 - accuracy: 0.7812 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4288 - accuracy: 0.7812 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4286 - accuracy: 0.7795 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4284 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4286 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7708\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4285 - accuracy: 0.7830 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4283 - accuracy: 0.7812 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4283 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4281 - accuracy: 0.7812 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4278 - accuracy: 0.7812 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4277 - accuracy: 0.7830 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4278 - accuracy: 0.7812 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4276 - accuracy: 0.7847 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4275 - accuracy: 0.7847 - val_loss: 0.5104 - val_accuracy: 0.7708\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4275 - accuracy: 0.7847 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4274 - accuracy: 0.7830 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4273 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4272 - accuracy: 0.7830 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4271 - accuracy: 0.7830 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4270 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7656\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4268 - accuracy: 0.7847 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4267 - accuracy: 0.7830 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4265 - accuracy: 0.7847 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4266 - accuracy: 0.7865 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4264 - accuracy: 0.7830 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4261 - accuracy: 0.7847 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4263 - accuracy: 0.7847 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4259 - accuracy: 0.7847 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4259 - accuracy: 0.7847 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4259 - accuracy: 0.7847 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4258 - accuracy: 0.7847 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4257 - accuracy: 0.7847 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4256 - accuracy: 0.7830 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4254 - accuracy: 0.7882 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4252 - accuracy: 0.7847 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.4253 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4251 - accuracy: 0.7812 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4250 - accuracy: 0.7847 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4249 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4247 - accuracy: 0.7865 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4246 - accuracy: 0.7830 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4245 - accuracy: 0.7865 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4244 - accuracy: 0.7865 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4244 - accuracy: 0.7847 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4243 - accuracy: 0.7865 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4242 - accuracy: 0.7830 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4240 - accuracy: 0.7865 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4240 - accuracy: 0.7882 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4239 - accuracy: 0.7865 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4241 - accuracy: 0.7882 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4238 - accuracy: 0.7865 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4240 - accuracy: 0.7847 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4237 - accuracy: 0.7865 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4237 - accuracy: 0.7847 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4236 - accuracy: 0.7847 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4234 - accuracy: 0.7865 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4235 - accuracy: 0.7865 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4233 - accuracy: 0.7882 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4232 - accuracy: 0.7882 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4231 - accuracy: 0.7882 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4233 - accuracy: 0.7882 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4231 - accuracy: 0.7865 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4229 - accuracy: 0.7847 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4230 - accuracy: 0.7847 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4228 - accuracy: 0.7882 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4229 - accuracy: 0.7865 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4227 - accuracy: 0.7882 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4227 - accuracy: 0.7865 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4227 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4226 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4227 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4225 - accuracy: 0.7865 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4224 - accuracy: 0.7882 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4225 - accuracy: 0.7865 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4223 - accuracy: 0.7847 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4222 - accuracy: 0.7882 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4222 - accuracy: 0.7865 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.4222 - accuracy: 0.7882 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4220 - accuracy: 0.7865 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4221 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4221 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4219 - accuracy: 0.7882 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4219 - accuracy: 0.7865 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4217 - accuracy: 0.7882 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4218 - accuracy: 0.7882 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4218 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4217 - accuracy: 0.7882 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4218 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4216 - accuracy: 0.7865 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4216 - accuracy: 0.7882 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4215 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4215 - accuracy: 0.7882 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4214 - accuracy: 0.7882 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4215 - accuracy: 0.7899 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4215 - accuracy: 0.7865 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4213 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4211 - accuracy: 0.7882 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4210 - accuracy: 0.7882 - val_loss: 0.5148 - val_accuracy: 0.7656\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4209 - accuracy: 0.7899 - val_loss: 0.5148 - val_accuracy: 0.7656\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4210 - accuracy: 0.7917 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4210 - accuracy: 0.7882 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4209 - accuracy: 0.7865 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.5148 - val_accuracy: 0.7656\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4207 - accuracy: 0.7899 - val_loss: 0.5148 - val_accuracy: 0.7656\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4206 - accuracy: 0.7899 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4208 - accuracy: 0.7882 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4206 - accuracy: 0.7882 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4206 - accuracy: 0.7917 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4206 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4206 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4203 - accuracy: 0.7917 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.4203 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4202 - accuracy: 0.7882 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4203 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4202 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4204 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4202 - accuracy: 0.7899 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4201 - accuracy: 0.7899 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4201 - accuracy: 0.7917 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4201 - accuracy: 0.7934 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4201 - accuracy: 0.7934 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4200 - accuracy: 0.7917 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4198 - accuracy: 0.7917 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4198 - accuracy: 0.7917 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4200 - accuracy: 0.7917 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4198 - accuracy: 0.7917 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4198 - accuracy: 0.7899 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4198 - accuracy: 0.7917 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4197 - accuracy: 0.7917 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4197 - accuracy: 0.7917 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4192 - accuracy: 0.7917 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4190 - accuracy: 0.7986 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4190 - accuracy: 0.7917 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4186 - accuracy: 0.7934 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4185 - accuracy: 0.7934 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4184 - accuracy: 0.7969 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4183 - accuracy: 0.8003 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4177 - accuracy: 0.8021 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4178 - accuracy: 0.8021 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4176 - accuracy: 0.7986 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4176 - accuracy: 0.8021 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4176 - accuracy: 0.8021 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4174 - accuracy: 0.7986 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4175 - accuracy: 0.8021 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.4173 - accuracy: 0.8021 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4174 - accuracy: 0.8021 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4172 - accuracy: 0.7986 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4172 - accuracy: 0.7986 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4171 - accuracy: 0.8038 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4170 - accuracy: 0.8021 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4171 - accuracy: 0.7986 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4170 - accuracy: 0.8021 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4170 - accuracy: 0.7986 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4169 - accuracy: 0.8003 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4169 - accuracy: 0.7986 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4168 - accuracy: 0.8021 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4166 - accuracy: 0.7986 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.5161 - val_accuracy: 0.7604\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4166 - accuracy: 0.7986 - val_loss: 0.5161 - val_accuracy: 0.7604\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4168 - accuracy: 0.8003 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4165 - accuracy: 0.8003 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4165 - accuracy: 0.7986 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4165 - accuracy: 0.7986 - val_loss: 0.5161 - val_accuracy: 0.7604\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4165 - accuracy: 0.7986 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4165 - accuracy: 0.8003 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4164 - accuracy: 0.8021 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4164 - accuracy: 0.8003 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4165 - accuracy: 0.8003 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4162 - accuracy: 0.8003 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4162 - accuracy: 0.8021 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4162 - accuracy: 0.8021 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4162 - accuracy: 0.8003 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4162 - accuracy: 0.8003 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.4162 - accuracy: 0.8038 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4161 - accuracy: 0.8003 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4162 - accuracy: 0.8003 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4160 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4160 - accuracy: 0.8003 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4161 - accuracy: 0.8003 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4161 - accuracy: 0.8003 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4161 - accuracy: 0.8003 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4159 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4158 - accuracy: 0.8003 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4158 - accuracy: 0.8003 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4157 - accuracy: 0.8003 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4157 - accuracy: 0.8021 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4158 - accuracy: 0.8003 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4155 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4154 - accuracy: 0.8003 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4154 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4155 - accuracy: 0.8021 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4154 - accuracy: 0.8003 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4155 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4153 - accuracy: 0.8003 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4153 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4154 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4154 - accuracy: 0.7986 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4153 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4153 - accuracy: 0.8038 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4153 - accuracy: 0.8003 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4152 - accuracy: 0.8003 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4151 - accuracy: 0.8003 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4153 - accuracy: 0.8038 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4152 - accuracy: 0.8003 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4150 - accuracy: 0.8003 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4150 - accuracy: 0.8003 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4150 - accuracy: 0.8003 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4153 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4151 - accuracy: 0.8003 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4149 - accuracy: 0.8003 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4150 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4149 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4150 - accuracy: 0.8003 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4149 - accuracy: 0.8003 - val_loss: 0.5148 - val_accuracy: 0.7604\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4147 - accuracy: 0.8003 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4148 - accuracy: 0.8003 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4145 - accuracy: 0.8003 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4147 - accuracy: 0.8003 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4146 - accuracy: 0.8003 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4146 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4146 - accuracy: 0.8003 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4148 - accuracy: 0.8003 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4146 - accuracy: 0.8003 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4147 - accuracy: 0.8003 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4145 - accuracy: 0.8003 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4145 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4146 - accuracy: 0.8003 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4144 - accuracy: 0.8003 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4145 - accuracy: 0.8003 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4143 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4143 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4144 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4143 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4143 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4143 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4142 - accuracy: 0.8003 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4141 - accuracy: 0.8003 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4140 - accuracy: 0.8003 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4141 - accuracy: 0.8003 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4141 - accuracy: 0.8021 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4139 - accuracy: 0.8021 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4140 - accuracy: 0.8003 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4141 - accuracy: 0.8003 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.4139 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4141 - accuracy: 0.8021 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4138 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4139 - accuracy: 0.8021 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4138 - accuracy: 0.8021 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4139 - accuracy: 0.8021 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4137 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4136 - accuracy: 0.8021 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4136 - accuracy: 0.8021 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4134 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4135 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4135 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4134 - accuracy: 0.8021 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4136 - accuracy: 0.8021 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4133 - accuracy: 0.8038 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4135 - accuracy: 0.8021 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4133 - accuracy: 0.8021 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4132 - accuracy: 0.8021 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4133 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4133 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4132 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4132 - accuracy: 0.8038 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4131 - accuracy: 0.8021 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4132 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4129 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4132 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4130 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4130 - accuracy: 0.8038 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4130 - accuracy: 0.8021 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4129 - accuracy: 0.8038 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4128 - accuracy: 0.8038 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4128 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4129 - accuracy: 0.8021 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4127 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4126 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4127 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4127 - accuracy: 0.8038 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4126 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4126 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 0.4127 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4125 - accuracy: 0.8073 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4125 - accuracy: 0.8056 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4125 - accuracy: 0.8056 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4124 - accuracy: 0.8056 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4125 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4125 - accuracy: 0.8021 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4123 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4124 - accuracy: 0.8056 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4123 - accuracy: 0.8021 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4123 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4121 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4124 - accuracy: 0.8073 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4123 - accuracy: 0.8056 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4121 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4122 - accuracy: 0.8056 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4122 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4121 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4119 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4122 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.4119 - accuracy: 0.8056 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4119 - accuracy: 0.8056 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4120 - accuracy: 0.8056 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4119 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4120 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4119 - accuracy: 0.8056 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4120 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4117 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4116 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4116 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4118 - accuracy: 0.8021 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4115 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4116 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4115 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4115 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4115 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4114 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4115 - accuracy: 0.8073 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4115 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4113 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4115 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4113 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4113 - accuracy: 0.8073 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4114 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4113 - accuracy: 0.8038 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4113 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4113 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4113 - accuracy: 0.8073 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4112 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4111 - accuracy: 0.8073 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4113 - accuracy: 0.8021 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4111 - accuracy: 0.8038 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4113 - accuracy: 0.8073 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4111 - accuracy: 0.8056 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4111 - accuracy: 0.8056 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4111 - accuracy: 0.8056 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4112 - accuracy: 0.8056 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4110 - accuracy: 0.8056 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4110 - accuracy: 0.8038 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4112 - accuracy: 0.8056 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4109 - accuracy: 0.8056 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4107 - accuracy: 0.8056 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4108 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4107 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4109 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4107 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4107 - accuracy: 0.8073 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4109 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4107 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4106 - accuracy: 0.8073 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4105 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4107 - accuracy: 0.8056 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4105 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4106 - accuracy: 0.8056 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4106 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4102 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4104 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4103 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4104 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4104 - accuracy: 0.8073 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4104 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4103 - accuracy: 0.8073 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4103 - accuracy: 0.8073 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4100 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4102 - accuracy: 0.8073 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4101 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4101 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4102 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4099 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4099 - accuracy: 0.8073 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4099 - accuracy: 0.8090 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4099 - accuracy: 0.8073 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4098 - accuracy: 0.8073 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4098 - accuracy: 0.8073 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4098 - accuracy: 0.8073 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4097 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4098 - accuracy: 0.8073 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4096 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4099 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4098 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4096 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4097 - accuracy: 0.8073 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4097 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4094 - accuracy: 0.8073 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4093 - accuracy: 0.8073 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4093 - accuracy: 0.8056 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4094 - accuracy: 0.8056 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4093 - accuracy: 0.8090 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4093 - accuracy: 0.8073 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4093 - accuracy: 0.8056 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4093 - accuracy: 0.8090 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4092 - accuracy: 0.8056 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4092 - accuracy: 0.8073 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4092 - accuracy: 0.8073 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4092 - accuracy: 0.8073 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4093 - accuracy: 0.8056 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4092 - accuracy: 0.8073 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4090 - accuracy: 0.8090 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4090 - accuracy: 0.8073 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4090 - accuracy: 0.8073 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4089 - accuracy: 0.8073 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4089 - accuracy: 0.8073 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4089 - accuracy: 0.8056 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4088 - accuracy: 0.8073 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4090 - accuracy: 0.8090 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4087 - accuracy: 0.8073 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4088 - accuracy: 0.8073 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4090 - accuracy: 0.8090 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4089 - accuracy: 0.8073 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4085 - accuracy: 0.8090 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4087 - accuracy: 0.8090 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4086 - accuracy: 0.8073 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4089 - accuracy: 0.8108 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4088 - accuracy: 0.8090 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4085 - accuracy: 0.8056 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4085 - accuracy: 0.8090 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4085 - accuracy: 0.8073 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4085 - accuracy: 0.8073 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4086 - accuracy: 0.8090 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4085 - accuracy: 0.8073 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4086 - accuracy: 0.8090 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4085 - accuracy: 0.8073 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4084 - accuracy: 0.8073 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4084 - accuracy: 0.8073 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4083 - accuracy: 0.8073 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4085 - accuracy: 0.8056 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4082 - accuracy: 0.8073 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4083 - accuracy: 0.8090 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4081 - accuracy: 0.8090 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4083 - accuracy: 0.8090 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4082 - accuracy: 0.8090 - val_loss: 0.5090 - val_accuracy: 0.7552\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4085 - accuracy: 0.8073 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4083 - accuracy: 0.8056 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4081 - accuracy: 0.8073 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4082 - accuracy: 0.8073 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4082 - accuracy: 0.8073 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4080 - accuracy: 0.8056 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4081 - accuracy: 0.8056 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4081 - accuracy: 0.8090 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4082 - accuracy: 0.8073 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4080 - accuracy: 0.8073 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4080 - accuracy: 0.8073 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4082 - accuracy: 0.8073 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4082 - accuracy: 0.8073 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4080 - accuracy: 0.8073 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4081 - accuracy: 0.8056 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4079 - accuracy: 0.8073 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4081 - accuracy: 0.8073 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4079 - accuracy: 0.8073 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4080 - accuracy: 0.8073 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4079 - accuracy: 0.8073 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 0.4079 - accuracy: 0.8056 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4078 - accuracy: 0.8090 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4078 - accuracy: 0.8056 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4077 - accuracy: 0.8073 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4079 - accuracy: 0.8073 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4078 - accuracy: 0.8038 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4078 - accuracy: 0.8056 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4077 - accuracy: 0.8056 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4076 - accuracy: 0.8073 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4078 - accuracy: 0.8073 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4078 - accuracy: 0.8056 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4077 - accuracy: 0.8073 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4079 - accuracy: 0.8056 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4075 - accuracy: 0.8056 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4076 - accuracy: 0.8056 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4077 - accuracy: 0.8073 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4076 - accuracy: 0.8073 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4075 - accuracy: 0.8073 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4074 - accuracy: 0.8038 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4074 - accuracy: 0.8073 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.4076 - accuracy: 0.8090 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4074 - accuracy: 0.8073 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4076 - accuracy: 0.8090 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4076 - accuracy: 0.8056 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4076 - accuracy: 0.8056 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4075 - accuracy: 0.8073 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4074 - accuracy: 0.8056 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4073 - accuracy: 0.8038 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4074 - accuracy: 0.8090 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4073 - accuracy: 0.8073 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4073 - accuracy: 0.8073 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4074 - accuracy: 0.8073 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4074 - accuracy: 0.8056 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4074 - accuracy: 0.8056 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4073 - accuracy: 0.8090 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4073 - accuracy: 0.8073 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4074 - accuracy: 0.8090 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4075 - accuracy: 0.8073 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.4072 - accuracy: 0.8073 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4073 - accuracy: 0.8073 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4071 - accuracy: 0.8073 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4074 - accuracy: 0.8073 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4071 - accuracy: 0.8073 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4071 - accuracy: 0.8073 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4072 - accuracy: 0.8073 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4073 - accuracy: 0.8073 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4071 - accuracy: 0.8073 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4072 - accuracy: 0.8056 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4071 - accuracy: 0.8056 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4072 - accuracy: 0.8073 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4071 - accuracy: 0.8056 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4072 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4070 - accuracy: 0.8056 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4072 - accuracy: 0.8056 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4071 - accuracy: 0.8073 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4070 - accuracy: 0.8056 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4069 - accuracy: 0.8090 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4070 - accuracy: 0.8056 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4067 - accuracy: 0.8056 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4070 - accuracy: 0.8038 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4068 - accuracy: 0.8056 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4067 - accuracy: 0.8090 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4067 - accuracy: 0.8038 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4068 - accuracy: 0.8073 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4067 - accuracy: 0.8056 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4068 - accuracy: 0.8038 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4070 - accuracy: 0.8090 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4067 - accuracy: 0.8090 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4067 - accuracy: 0.8056 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4065 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4066 - accuracy: 0.8038 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4066 - accuracy: 0.8038 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4065 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4065 - accuracy: 0.8056 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4065 - accuracy: 0.8056 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4066 - accuracy: 0.8038 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.4068 - accuracy: 0.8073 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4066 - accuracy: 0.8038 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4064 - accuracy: 0.8108 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4064 - accuracy: 0.8038 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4065 - accuracy: 0.8073 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4065 - accuracy: 0.8056 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4063 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4065 - accuracy: 0.8056 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4064 - accuracy: 0.8038 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4063 - accuracy: 0.8038 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4064 - accuracy: 0.8038 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4065 - accuracy: 0.8056 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4063 - accuracy: 0.8038 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4060 - accuracy: 0.8073 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4061 - accuracy: 0.8021 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4061 - accuracy: 0.8038 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4062 - accuracy: 0.8073 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4064 - accuracy: 0.8073 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4061 - accuracy: 0.8038 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4060 - accuracy: 0.8056 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4060 - accuracy: 0.8073 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4061 - accuracy: 0.8038 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4061 - accuracy: 0.8038 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4061 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4060 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4060 - accuracy: 0.8056 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4060 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4059 - accuracy: 0.8038 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.4059 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4059 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4059 - accuracy: 0.8038 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4059 - accuracy: 0.8056 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4060 - accuracy: 0.8021 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4058 - accuracy: 0.8038 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4058 - accuracy: 0.8038 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4057 - accuracy: 0.8056 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4057 - accuracy: 0.8038 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4058 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4058 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4057 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4058 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4057 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4056 - accuracy: 0.8021 - val_loss: 0.5087 - val_accuracy: 0.7500\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4056 - accuracy: 0.8021 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4059 - accuracy: 0.8003 - val_loss: 0.5087 - val_accuracy: 0.7500\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4056 - accuracy: 0.8021 - val_loss: 0.5087 - val_accuracy: 0.7500\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4056 - accuracy: 0.8021 - val_loss: 0.5088 - val_accuracy: 0.7500\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4057 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4058 - accuracy: 0.8021 - val_loss: 0.5087 - val_accuracy: 0.7500\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4055 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4055 - accuracy: 0.8003 - val_loss: 0.5089 - val_accuracy: 0.7500\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4058 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7500\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4056 - accuracy: 0.8038 - val_loss: 0.5089 - val_accuracy: 0.7500\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4056 - accuracy: 0.8021 - val_loss: 0.5090 - val_accuracy: 0.7500\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4054 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7500\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4054 - accuracy: 0.8038 - val_loss: 0.5088 - val_accuracy: 0.7500\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4055 - accuracy: 0.8021 - val_loss: 0.5088 - val_accuracy: 0.7500\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4055 - accuracy: 0.8038 - val_loss: 0.5089 - val_accuracy: 0.7500\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4052 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7500\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4054 - accuracy: 0.8021 - val_loss: 0.5090 - val_accuracy: 0.7500\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4055 - accuracy: 0.8003 - val_loss: 0.5090 - val_accuracy: 0.7500\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4053 - accuracy: 0.8003 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4054 - accuracy: 0.8003 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4053 - accuracy: 0.8021 - val_loss: 0.5091 - val_accuracy: 0.7500\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4054 - accuracy: 0.8003 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4052 - accuracy: 0.8021 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4052 - accuracy: 0.8003 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 0.4051 - accuracy: 0.8056 - val_loss: 0.5091 - val_accuracy: 0.7500\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4052 - accuracy: 0.8021 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4052 - accuracy: 0.8021 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4050 - accuracy: 0.8021 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4051 - accuracy: 0.8021 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4051 - accuracy: 0.8003 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4051 - accuracy: 0.8003 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4051 - accuracy: 0.8003 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4052 - accuracy: 0.8021 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4050 - accuracy: 0.8003 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4049 - accuracy: 0.8003 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4049 - accuracy: 0.8003 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4049 - accuracy: 0.8021 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4051 - accuracy: 0.8003 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4050 - accuracy: 0.8021 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4050 - accuracy: 0.8021 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4049 - accuracy: 0.8003 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4050 - accuracy: 0.7986 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.4048 - accuracy: 0.8003 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4047 - accuracy: 0.8021 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4047 - accuracy: 0.8021 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4049 - accuracy: 0.7986 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4048 - accuracy: 0.7986 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4049 - accuracy: 0.8003 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4048 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4048 - accuracy: 0.8003 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4046 - accuracy: 0.8038 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4047 - accuracy: 0.8003 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4046 - accuracy: 0.8003 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4047 - accuracy: 0.7986 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4045 - accuracy: 0.8021 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4046 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4047 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4046 - accuracy: 0.8021 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4046 - accuracy: 0.8021 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4047 - accuracy: 0.7986 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4047 - accuracy: 0.8021 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4044 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4046 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4045 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4045 - accuracy: 0.8021 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4044 - accuracy: 0.8038 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4043 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4043 - accuracy: 0.8021 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4044 - accuracy: 0.8021 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4043 - accuracy: 0.8003 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4043 - accuracy: 0.8038 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4043 - accuracy: 0.8003 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4043 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4043 - accuracy: 0.8003 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4044 - accuracy: 0.8003 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4043 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4044 - accuracy: 0.8021 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.4042 - accuracy: 0.7986 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4041 - accuracy: 0.8003 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4041 - accuracy: 0.8021 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4041 - accuracy: 0.8021 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4041 - accuracy: 0.8021 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4040 - accuracy: 0.8003 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4041 - accuracy: 0.8003 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4040 - accuracy: 0.8003 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4042 - accuracy: 0.8021 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4041 - accuracy: 0.8003 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4041 - accuracy: 0.8003 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4040 - accuracy: 0.8003 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4044 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4040 - accuracy: 0.8038 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4039 - accuracy: 0.8021 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4039 - accuracy: 0.7986 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.4037 - accuracy: 0.8003 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4038 - accuracy: 0.7986 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4038 - accuracy: 0.8021 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.4039 - accuracy: 0.7986 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4039 - accuracy: 0.7986 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4039 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4037 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4037 - accuracy: 0.8021 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4037 - accuracy: 0.7986 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4038 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4037 - accuracy: 0.8003 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4035 - accuracy: 0.7986 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4036 - accuracy: 0.8003 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4036 - accuracy: 0.7986 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4036 - accuracy: 0.8021 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4036 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4036 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4034 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4034 - accuracy: 0.7986 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4037 - accuracy: 0.7986 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4034 - accuracy: 0.7986 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4035 - accuracy: 0.8003 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4033 - accuracy: 0.7986 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4033 - accuracy: 0.7986 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4032 - accuracy: 0.7986 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4035 - accuracy: 0.8021 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4034 - accuracy: 0.8003 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4033 - accuracy: 0.7986 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4035 - accuracy: 0.8003 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4033 - accuracy: 0.8003 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4032 - accuracy: 0.8003 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4031 - accuracy: 0.8003 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4033 - accuracy: 0.8003 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4031 - accuracy: 0.7986 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4033 - accuracy: 0.7986 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4034 - accuracy: 0.7986 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4030 - accuracy: 0.8003 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4033 - accuracy: 0.8003 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4030 - accuracy: 0.8021 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4030 - accuracy: 0.7986 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.4029 - accuracy: 0.8003 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4031 - accuracy: 0.7969 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4031 - accuracy: 0.7986 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4030 - accuracy: 0.8003 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4028 - accuracy: 0.8003 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4028 - accuracy: 0.8003 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4028 - accuracy: 0.7986 - val_loss: 0.5109 - val_accuracy: 0.7396\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4031 - accuracy: 0.8003 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4028 - accuracy: 0.7986 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4030 - accuracy: 0.8021 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4030 - accuracy: 0.7986 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4027 - accuracy: 0.8038 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4027 - accuracy: 0.8003 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4028 - accuracy: 0.8003 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4027 - accuracy: 0.8021 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4029 - accuracy: 0.7986 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4025 - accuracy: 0.8021 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4026 - accuracy: 0.8003 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4025 - accuracy: 0.8003 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4026 - accuracy: 0.8003 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4025 - accuracy: 0.8021 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4028 - accuracy: 0.8003 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4027 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4024 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4024 - accuracy: 0.8021 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4025 - accuracy: 0.8021 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4026 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4024 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4024 - accuracy: 0.8003 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4025 - accuracy: 0.8003 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4023 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4023 - accuracy: 0.8003 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4024 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4025 - accuracy: 0.8003 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4022 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4023 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7448\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4023 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4023 - accuracy: 0.8021 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4022 - accuracy: 0.8038 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4022 - accuracy: 0.8021 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4020 - accuracy: 0.8021 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4021 - accuracy: 0.8003 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4021 - accuracy: 0.8003 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4021 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4019 - accuracy: 0.8003 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4022 - accuracy: 0.7986 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4018 - accuracy: 0.8003 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4018 - accuracy: 0.8003 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4019 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4018 - accuracy: 0.8021 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4018 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4019 - accuracy: 0.8021 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4017 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7448\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4018 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4017 - accuracy: 0.8021 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4017 - accuracy: 0.8021 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4016 - accuracy: 0.8021 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4018 - accuracy: 0.8003 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4017 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4018 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4015 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4016 - accuracy: 0.8056 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4018 - accuracy: 0.8021 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4014 - accuracy: 0.8021 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4016 - accuracy: 0.8073 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4015 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4014 - accuracy: 0.8056 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4014 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4013 - accuracy: 0.8021 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4012 - accuracy: 0.8003 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4012 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4012 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4012 - accuracy: 0.8021 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4011 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4012 - accuracy: 0.8021 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4012 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4010 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4012 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4010 - accuracy: 0.8021 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4010 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4008 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4011 - accuracy: 0.8021 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4009 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4009 - accuracy: 0.8021 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4008 - accuracy: 0.8073 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4008 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4012 - accuracy: 0.8021 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4008 - accuracy: 0.8056 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4010 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4008 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4009 - accuracy: 0.8021 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4009 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4006 - accuracy: 0.8073 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4007 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4008 - accuracy: 0.8056 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4006 - accuracy: 0.8056 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4005 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4005 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4007 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4004 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4004 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7396\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4006 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4006 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4004 - accuracy: 0.8021 - val_loss: 0.5124 - val_accuracy: 0.7396\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4003 - accuracy: 0.8090 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4007 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4005 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4004 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4004 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.4006 - accuracy: 0.8073 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4003 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7396\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4005 - accuracy: 0.8073 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4002 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4003 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4001 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4004 - accuracy: 0.8073 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4003 - accuracy: 0.8090 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4001 - accuracy: 0.8090 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4001 - accuracy: 0.8090 - val_loss: 0.5124 - val_accuracy: 0.7396\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4000 - accuracy: 0.8073 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4000 - accuracy: 0.8073 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4001 - accuracy: 0.8090 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4001 - accuracy: 0.8073 - val_loss: 0.5124 - val_accuracy: 0.7396\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4001 - accuracy: 0.8108 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4000 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7396\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.3999 - accuracy: 0.8108 - val_loss: 0.5124 - val_accuracy: 0.7396\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3998 - accuracy: 0.8090 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3999 - accuracy: 0.8090 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.3998 - accuracy: 0.8108 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.3998 - accuracy: 0.8090 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.3999 - accuracy: 0.8073 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3998 - accuracy: 0.8108 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.3999 - accuracy: 0.8090 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3996 - accuracy: 0.8108 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.3998 - accuracy: 0.8108 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.3997 - accuracy: 0.8142 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3996 - accuracy: 0.8108 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3997 - accuracy: 0.8108 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3993 - accuracy: 0.8090 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3995 - accuracy: 0.8073 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3994 - accuracy: 0.8108 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3996 - accuracy: 0.8073 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.3996 - accuracy: 0.8090 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.3995 - accuracy: 0.8125 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.3997 - accuracy: 0.8090 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.3997 - accuracy: 0.8090 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.3995 - accuracy: 0.8073 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.3992 - accuracy: 0.8090 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.3992 - accuracy: 0.8125 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.3992 - accuracy: 0.8108 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.3994 - accuracy: 0.8090 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3992 - accuracy: 0.8108 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3991 - accuracy: 0.8090 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3992 - accuracy: 0.8125 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3993 - accuracy: 0.8108 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3990 - accuracy: 0.8108 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3990 - accuracy: 0.8108 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3990 - accuracy: 0.8125 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3991 - accuracy: 0.8142 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3990 - accuracy: 0.8108 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3988 - accuracy: 0.8142 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.3991 - accuracy: 0.8142 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.3989 - accuracy: 0.8160 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.3986 - accuracy: 0.8160 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.3988 - accuracy: 0.8177 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3988 - accuracy: 0.8073 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3988 - accuracy: 0.8125 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3987 - accuracy: 0.8177 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3989 - accuracy: 0.8125 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3987 - accuracy: 0.8160 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3987 - accuracy: 0.8177 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.3987 - accuracy: 0.8142 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3986 - accuracy: 0.8177 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3987 - accuracy: 0.8142 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3986 - accuracy: 0.8160 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3986 - accuracy: 0.8142 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3985 - accuracy: 0.8177 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3985 - accuracy: 0.8177 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3984 - accuracy: 0.8142 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.3983 - accuracy: 0.8125 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.3982 - accuracy: 0.8160 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3985 - accuracy: 0.8194 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.3984 - accuracy: 0.8177 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3984 - accuracy: 0.8177 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3983 - accuracy: 0.8212 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3982 - accuracy: 0.8160 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3982 - accuracy: 0.8177 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3982 - accuracy: 0.8142 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3983 - accuracy: 0.8160 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3980 - accuracy: 0.8177 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3980 - accuracy: 0.8194 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3984 - accuracy: 0.8160 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3982 - accuracy: 0.8194 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3982 - accuracy: 0.8194 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3981 - accuracy: 0.8160 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.3981 - accuracy: 0.8194 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3980 - accuracy: 0.8177 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3980 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.3981 - accuracy: 0.8194 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.3979 - accuracy: 0.8160 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.3981 - accuracy: 0.8194 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.3979 - accuracy: 0.8194 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.3980 - accuracy: 0.8160 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.3979 - accuracy: 0.8177 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3979 - accuracy: 0.8160 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3980 - accuracy: 0.8177 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.3979 - accuracy: 0.8160 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.3978 - accuracy: 0.8177 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3977 - accuracy: 0.8194 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.3979 - accuracy: 0.8212 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.3976 - accuracy: 0.8177 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.3977 - accuracy: 0.8142 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.3977 - accuracy: 0.8177 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.3977 - accuracy: 0.8142 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.3975 - accuracy: 0.8194 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.3976 - accuracy: 0.8177 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.3976 - accuracy: 0.8212 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.3976 - accuracy: 0.8194 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.3977 - accuracy: 0.8177 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.3974 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.3976 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.3976 - accuracy: 0.8177 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.3975 - accuracy: 0.8194 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.3975 - accuracy: 0.8142 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.3975 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.3975 - accuracy: 0.8212 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.3975 - accuracy: 0.8177 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.3974 - accuracy: 0.8194 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.3974 - accuracy: 0.8194 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.3974 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.3973 - accuracy: 0.8194 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.3972 - accuracy: 0.8212 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3973 - accuracy: 0.8194 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3974 - accuracy: 0.8212 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.3971 - accuracy: 0.8160 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3970 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3973 - accuracy: 0.8160 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3973 - accuracy: 0.8212 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3971 - accuracy: 0.8212 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3971 - accuracy: 0.8212 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3971 - accuracy: 0.8229 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3970 - accuracy: 0.8247 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3968 - accuracy: 0.8229 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3968 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3968 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3969 - accuracy: 0.8229 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3968 - accuracy: 0.8212 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.3968 - accuracy: 0.8229 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.3969 - accuracy: 0.8212 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3968 - accuracy: 0.8212 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3967 - accuracy: 0.8212 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3967 - accuracy: 0.8229 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3969 - accuracy: 0.8212 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3968 - accuracy: 0.8194 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3967 - accuracy: 0.8160 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3968 - accuracy: 0.8194 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3966 - accuracy: 0.8177 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.3966 - accuracy: 0.8212 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3966 - accuracy: 0.8194 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3966 - accuracy: 0.8212 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.3965 - accuracy: 0.8229 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3965 - accuracy: 0.8212 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.3966 - accuracy: 0.8177 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.3964 - accuracy: 0.8212 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.3967 - accuracy: 0.8229 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3965 - accuracy: 0.8247 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3966 - accuracy: 0.8229 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3966 - accuracy: 0.8194 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3966 - accuracy: 0.8212 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.3964 - accuracy: 0.8229 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3963 - accuracy: 0.8212 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3964 - accuracy: 0.8212 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3964 - accuracy: 0.8212 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3964 - accuracy: 0.8212 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3964 - accuracy: 0.8229 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3964 - accuracy: 0.8212 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3961 - accuracy: 0.8247 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3963 - accuracy: 0.8194 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.3960 - accuracy: 0.8194 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3961 - accuracy: 0.8229 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.3961 - accuracy: 0.8194 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.3960 - accuracy: 0.8194 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3961 - accuracy: 0.8212 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3960 - accuracy: 0.8229 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3959 - accuracy: 0.8247 - val_loss: 0.5118 - val_accuracy: 0.7396\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 16ms/step\n",
      "\n",
      "roc-auc is 0.825\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "# print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
