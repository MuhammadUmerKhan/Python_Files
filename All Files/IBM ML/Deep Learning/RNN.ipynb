{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21748c05-52d4-49c1-997a-5b72a1685c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install tensorflow_hub\n",
    "!pip install tensorflow --upgrade\n",
    "!mamba install -qy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aabaa209-a315-4540-ba14-0de73a61b962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf. __version__)\n",
    "import skillsnetwork\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding,Masking,LSTM, GRU, Conv1D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, SimpleRNN\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from sklearn.metrics import accuracy_score,precision_recall_fscore_support\n",
    "# import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "np.random.seed(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c9f4fc-fa82-44e5-b986-a0dfb7601cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\DATA SCIENCE\\Python_Files\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ecef169-4650-4592-88f7-47e4ab67153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(y_true, y_pred):\n",
    "    model_accuracy = accuracy_score(y_true, y_pred)\n",
    "    model_precision, model_recall, model_f1,_ = precision_recall_fscore_support(y_true, y_pred,average=\"weighted\")\n",
    "    model_results = {\"accuracy\":model_accuracy,\n",
    "                     \"precision\":model_precision,\n",
    "                     \"recall\" :model_recall,\n",
    "                     \"f1\":model_f1}\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a92135-5ab6-4a28-806c-dc2128717f49",
   "metadata": {},
   "source": [
    "## RNN Fundamentals\n",
    "\n",
    "RNNs fall in the category of neural networks that maintain some kind of **state**. They can process sequential data of arbitrary length. By doing so, they overcome certain limitations faced by classical neural networks. Classical NNs only accept fixed-length vectors as input and output fixed-length vectors. RNNs operate over sequences of vectors. Classical NNs aren't built to consider the sequential nature of some data. RNNs work with sequential data forms like language, video frames, time series, and so on.\n",
    "\n",
    "The RNN layer uses a for-loop to iterate over the time-steps of a sequence, and maintains an internal state that encodes information about all time-steps that have been observed so far. The Keras RNN API has built-in `keras.layers.RNN` and `keras.layers.LSTM` layers that make it easy to quickly build RNN models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4a026ce-e290-4fe3-9996-60d1520668f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7af76d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>7470</td>\n",
       "      <td>obliteration</td>\n",
       "      <td>Merica!</td>\n",
       "      <td>@Eganator2000 There aren't many Obliteration s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>7691</td>\n",
       "      <td>panic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just had a panic attack bc I don't have enough...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1242</td>\n",
       "      <td>blood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Omron HEM-712C Automatic Blood Pressure Monito...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>10862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Officials say a quarantine is in place at an A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>10409</td>\n",
       "      <td>whirlwind</td>\n",
       "      <td>Stamford &amp; Cork (&amp; Shropshire)</td>\n",
       "      <td>I moved to England five years ago today. What ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       keyword                        location  \\\n",
       "2644   3796   destruction                             NaN   \n",
       "2227   3185        deluge                             NaN   \n",
       "5448   7769        police                              UK   \n",
       "132     191    aftershock                             NaN   \n",
       "6845   9810        trauma           Montgomery County, MD   \n",
       "...     ...           ...                             ...   \n",
       "5226   7470  obliteration                         Merica!   \n",
       "5390   7691         panic                             NaN   \n",
       "860    1242         blood                             NaN   \n",
       "7603  10862           NaN                             NaN   \n",
       "7270  10409     whirlwind  Stamford & Cork (& Shropshire)   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  \n",
       "...                                                 ...     ...  \n",
       "5226  @Eganator2000 There aren't many Obliteration s...       0  \n",
       "5390  just had a panic attack bc I don't have enough...       0  \n",
       "860   Omron HEM-712C Automatic Blood Pressure Monito...       0  \n",
       "7603  Officials say a quarantine is in place at an A...       1  \n",
       "7270  I moved to England five years ago today. What ...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20bc9602",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df_shuffled['text'].to_numpy(), train_df_shuffled['target'].to_numpy(), test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abc6d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=None, \n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    ngrams=None,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c546b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_length= 10000\n",
    "max_length = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a47d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = tf.keras.layers.Embedding(input_dim=max_vocab_length,\n",
    "                             output_dim=128,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99dca3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer = layers.LSTM(units=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53d53128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\DATA SCIENCE\\Python_Files\\.venv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\DATA SCIENCE\\Python_Files\\.venv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\DATA SCIENCE\\Python_Files\\.venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\DATA SCIENCE\\Python_Files\\.venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                               input_shape=[],\n",
    "                               dtype = tf.string,\n",
    "                               trainable=False,\n",
    "                               name=\"pretrained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a91b56",
   "metadata": {},
   "source": [
    "The `encoder_layer` will take as input variable length English text and the output is a 512 dimensional vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4e50bc",
   "metadata": {},
   "source": [
    "We will add a Dense layer with unit 1 to create a simple binary text classifier on top of any TF-Hub module. Next, we will compile and fit it using 20 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc865cda",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\", input_shape=[], dtype=tf.string, trainable=True)\n",
    "\n",
    "# Define your Sequential model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=[], dtype=tf.string),  # Input layer for string inputs\n",
    "    encoder_layer,  # TensorFlow Hub layer wrapped in Lambda layer\n",
    "    layers.Dense(1, activation=\"sigmoid\")  # Output layer\n",
    "], name=\"model_pretrained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=\"adam\",\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c88ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train,\n",
    "              y=y_train,\n",
    "              epochs=20,\n",
    "              validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65fe1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_results(y_true=y_test,\n",
    "                  y_pred=tf.squeeze(tf.round(model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c0bed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
